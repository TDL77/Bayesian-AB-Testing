{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0ed381c7",
   "metadata": {},
   "source": [
    "# Приложение: проверка статистических гипотез"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3725791f",
   "metadata": {},
   "source": [
    "* *[Введение](#Введение)*  \n",
    "* *[Проверка статистической гипотезы](#Проверка-статистической-гипотезы)*  \n",
    "* *[Сравнение средних в группах](#Сравнение-средних-в-группах)*\n",
    "* *[Особенности интерпретации](#Особенности-интерпретации)*\n",
    "* *[Заключение](#Заключение)*\n",
    "* *[Ссылки](#Ссылки)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06bf6f59",
   "metadata": {},
   "source": [
    "# Введение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba34e09f",
   "metadata": {},
   "source": [
    "Для анализа А/Б-тестов используют метод проверки статистических гипотез [[StTest](https://en.wikipedia.org/wiki/Statistical_hypothesis_testing)]. Чаще всего в таком подходе предполагают, что между вариантами нет разницы, после чего смотрят, насколько такое предположение объясняет экспериментальные данные. Если вероятность получить данные мала, то считается, что предположение можно отвергнуть и между группами есть значимая разница.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7ca48ea",
   "metadata": {},
   "source": [
    "Вначале описывается терминология и приводится пример проверки статистической гипотезы. Далее рассматривает сравнение средних двух распределений. Затем обсуждаются особенности интерпретации этого метода."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "416085ce",
   "metadata": {},
   "source": [
    "# Проверка статистической гипотезы"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a57a4e",
   "metadata": {},
   "source": [
    "Есть экспериментальные данные $data$. Есть гипотеза $H$ об этих данных. Есть случайная величина $T$, распределение которой $P_{T}(x | H)$ в предположении $H$ известно - ее называют \"статистическим тестом\". По фактическим данным считается \"тестовая статистика\"  $x_{data}$ [[TestStat](https://en.wikipedia.org/wiki/Test_statistic)]. Считается вероятность получить \"фактическое или более экстремальное\" значение \"тестовой статистики\". В зависимости от контекста $p = P_{T}(x \\ge x_{data} | H)$, $p = P_{T}(x \\le x_{data} | H)$ или $p = P_{T}(|x - x_{data}| \\ge 0 | H)$ [[TailedTests](https://en.wikipedia.org/wiki/One-_and_two-tailed_tests)]. Эту вероятность называют \"p-значением\" [[PVal](https://en.wikipedia.org/wiki/P-value)]. Если вероятность \"достаточно мала\", гипотезу $H$ \"отвергают\", если \"не достаточно мала\" - \"принимают\".  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b720f01c",
   "metadata": {},
   "source": [
    "Обсуждение такого подхода приводится в разделе \"Особенности интерпретации\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6db4f81a",
   "metadata": {},
   "source": [
    "В качестве примера можно рассмотреть проверку равенста вероятностей выпадения орла и решки по нескольким броскам монеты [[FairCoin](https://en.wikipedia.org/wiki/Checking_whether_a_coin_is_fair)]. Ситуация следующая:\n",
    "- данные: в 100 бросках монетки в 60 случаях выпал орел.  \n",
    "- гипотеза: вероятность выпадения орла 0.5   \n",
    "- случайная величина с известным распределением: вероятность k успехов в N попытках при вероятности $p$ успеха в одной попытке можно моделировать биномиальным распределением $Binom(p; N, k)$  \n",
    "- тестовая статистика: число успехов k=60 в общих попытках N=100\n",
    "- p-значение: вероятность получить 60 или больше успехов в 100 попытках $p = \\sum_{i \\ge 60}Binom(0.5; i, 100) = 1 - CDF_{Binom}(0.5, 60, 100)$\n",
    "- \"достаточно малую\" вероятность обычно выбирают на уровне 5%, т.е. если $p < 0.05$, то гипотезу $H$ считают неверной.  \n",
    "\n",
    "Ниже приведен график распределения тестовой статистики $Binom(0.5; 100, k)$, выделены \"фактические или более экстремальные\" значения $k$, проведены расчеты p-значения. P-значение оказывается равным 0.018. Это меньше 0.05, что дает основания считать гипотезу о вероятности выпадения орла 50\\% неверной.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9bb0f98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a99296",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 100\n",
    "s = 60\n",
    "p = 0.5\n",
    "alpha = 0.05\n",
    "\n",
    "x = np.arange(0, N+1)\n",
    "y = stats.binom.pmf(p=p, k=x, n=N)\n",
    "col = ['blue' if x < s else 'red' for x in x]\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Bar(x=x, y=y, marker_color=col))\n",
    "fig.update_layout(\n",
    "    title=f\"Probability of X heads in N={N} coin flips for a fair coin\",\n",
    "    height=450, width=800\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "pval = 1 - stats.binom.cdf(p=p, k=s, n=N)\n",
    "print(f\"p value = P(s >= {s} | H) = {pval:.3f}\")\n",
    "print(f\"H {'can' if pval < alpha else 'can not'} be rejected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f5fa1e",
   "metadata": {},
   "source": [
    "Даже если гипотеза верна, в эксперименте можно получить такие данные, что нужно принять решение об отклонении гипотезы. Вероятность получить данные по которым нужно принять решение \"отвергнуть гипотезу\" при условии, что гипотеза верна, называют вероятностью ошибки первого рода и обозначают $\\alpha$. Эту величину также называют \"статистической значимостью\". Величина $1-\\alpha$ характеризует вероятность принять корректное решение оставить гипотезу, при условии, что она верна. Вероятность получить данные, по которым нужно \"принять гипотезу\" при условии, что она не верна, называют вероятностью ошибки второго рода и обозначают $\\beta$. Величину $1-\\beta$ называют статистической мощностью [[StErrors](https://en.wikipedia.org/wiki/Type_I_and_type_II_errors), [StSign](https://en.wikipedia.org/wiki/Statistical_significance), [StPower](https://en.wikipedia.org/wiki/Power_of_a_test)]. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "035bfe9e",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "\\mbox{Статистическая значимость и ошибка первого рода: }& P(\\mbox{Решение отклонить }H | H) = \\alpha,\n",
    "\\\\\n",
    "\\mbox{Корректное решение оставить H: }& P(\\mbox{Решение принять }H | H) = 1 - \\alpha .\n",
    "\\\\\n",
    "\\\\\n",
    "\\mbox{Ошибка второго рода: }& P(\\mbox{Решение принять }H | \\neg H) = \\beta, \n",
    "\\\\\n",
    "\\mbox{Статистическая мощность: }& P(\\mbox{Решение отклонить }H | \\neg H) = 1 - \\beta .\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bea7a3e4",
   "metadata": {},
   "source": [
    "Статистическая значимость и мощность не полностью определяют вероятность выполнения гипотезы $H$. Остается неизвестным, верна в реальности гипотеза $H$ или нет. Подробнее см. раздел \"Особенности интерпретации\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "463f6a5d",
   "metadata": {},
   "source": [
    "# Сравнение средних в группах"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8fc285",
   "metadata": {},
   "source": [
    "Метод проверки статистических гипотез применяется в А/Б-тестах для сравнения групп.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32fc0714",
   "metadata": {},
   "source": [
    "Группы можно сравнивать по разным метриками. Ниже рассматривается сравнение средних.\n",
    "Т.е. по сэмлам из двух групп нужно оценить средние в распределениях и выбрать вариант с \"лучшим\" средним."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b7f0814",
   "metadata": {},
   "source": [
    "Для сравнения групп смотрят на выборочные средние $\\mu_{A_n}$ и $\\mu_{B_n}$. Проверяют гипотезу что, группы не отличаются - нулевую гипотезу $H_0$ [[HNull](https://en.wikipedia.org/wiki/Null_hypothesis)]. У выборочных средних среднее совпадает со средним исходного распределения, стандартное отклонение определяется стандартной ошибкой среднего. Если выборка \"достаточно большая\", то в силу центральной предельной теоремы их распределение приближенно можно считать нормальным.  \n",
    "\n",
    "\n",
    "$$\n",
    "\\mu_{A_n} = \\frac{1}{N_A} \\sum_i A_i,\n",
    "\\\\\n",
    "E[\\mu_{A_n}] = E[A],\n",
    "\\quad\n",
    "s_{\\mu_{A_n}} = \\frac{\\sigma_A}{\\sqrt{N_A}} \\approx \\frac{s_A}{\\sqrt{N_A}},\n",
    "\\quad\n",
    "s^2_{A} = \\frac{1}{N_A - 1} \\sum_i (A_i - E[A])^2,  \n",
    "\\\\\n",
    "\\mu_{A_n} \\sim Norm(E[A], s_{\\mu_{A_n}}) .\n",
    "$$\n",
    "\n",
    "Разность нормальных распределений также нормальное распределение. Поэтому разность выборочных средних также можно приближенно считать распределенной нормально \n",
    "\n",
    "$$\n",
    "\\mu_{\\Delta} = \\mu_{A_n} - \\mu_{B_n},\n",
    "\\\\\n",
    "E[\\mu_{\\Delta}] = E[\\mu_{A_n}] - E[\\mu_{B_n}] = E[A] - E[B],\n",
    "\\quad\n",
    "\\sigma_{\\Delta} \\approx s_{\\Delta} = \\sqrt{s_{\\mu_{A_n}}^2 + s_{\\mu_{B_n}}^2},\n",
    "\\\\\n",
    "\\mu_{\\Delta} \\sim Norm(E[\\mu_{\\Delta}], \\sigma_{\\Delta}).\n",
    "\\\\\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd7510f6",
   "metadata": {},
   "source": [
    "В качестве \"случайной величины, распределение которой в предположении нулевой гипотезы известно\", выбирают "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23fff778",
   "metadata": {},
   "source": [
    "$$\n",
    "t = \\frac{\\mu_{\\Delta}}{s_{\\Delta}}. \n",
    "$$\n",
    "\n",
    "Если верна нулевая гипотеза, т.е. между группами нет разницы, то $E[\\mu_{\\Delta}] = 0$, а $s_{\\Delta}$ можно оценить из сэмплов. При \"достаточно большом\" размере выборки приближенно ее можно считать распределенной нормально \n",
    "\n",
    "$$\n",
    "t \\sim Norm(0, 1).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a17176d",
   "metadata": {},
   "source": [
    "*Когда $\\mu_{\\Delta}$ и $s_{\\Delta}$ считаются по данным из нормального распределениея, величина t будет иметь t-распределение.* \n",
    "Более точным приближением может быть $t$-распределение [[TDist](https://en.wikipedia.org/wiki/Student%27s_t-distribution)]. Поэтому подход называют $t$-тестом [[TTest](https://en.wikipedia.org/wiki/Student's_t-test)]. В случае разных дисперсий приближенно используют приближение Уэлча [[WelchTTest](https://en.wikipedia.org/wiki/Welch%27s_t-test)]. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f1c464",
   "metadata": {},
   "source": [
    "На конкретных данных пример выглядит следующим образом. Допустим, есть две монетки с разными вероятностями выпадения орла (две серии Бернулли). Нужно выбрать монетку с большей вероятностью. Пусть $n_A, n_B, s_A, s_B$ - количество бросков и орлов в группах $A$ и $B$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faa1d93c",
   "metadata": {},
   "source": [
    "При проведении тестов для контроля за уровнями статистической значимости и мощности размер выборки расчитывают заранее. Выбирают статистическую значимость $\\alpha$, мощность $\\beta$, базовую конверсию, минимальную величину эффекта, по этим значениям рассчитывают размер выборки $N$ в каждой группе. Для сравнения конверсий с помощью t-теста при $\\alpha = 0.05$, $\\beta = 0.2$, базовой конверсии $p=0.3$, минимальном размере эффекта $\\Delta = 0.05$ размер каждой группы должен быть $\\sim 15000$ [[MillerABSize](https://www.evanmiller.org/ab-testing/sample-size.html)]. Возможный способ расчета и обсуждение см. в разделе \"Особенности интерпретации\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c7cf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha = 0.05\n",
    "\n",
    "p_a_exact = 0.3\n",
    "p_b_exact = 0.32\n",
    "\n",
    "n = 15000\n",
    "sa = stats.binom.rvs(n, p_a_exact)\n",
    "sb = stats.binom.rvs(n, p_b_exact)\n",
    "\n",
    "p_a = sa/n\n",
    "a_stderr = np.sqrt(p_a * (1 - p_a) / n)\n",
    "\n",
    "p_b = sb/n\n",
    "b_stderr = np.sqrt(p_b * (1 - p_b) / n)\n",
    "\n",
    "x=np.linspace(0, 1, 1000)\n",
    "\n",
    "col_a = 'red'\n",
    "col_b = 'blue'\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=[p_a], y=[stats.norm.pdf(p_a, p_a, a_stderr)],\n",
    "                         name='A', marker_color=col_a, mode='markers'))\n",
    "fig.add_trace(go.Scatter(x=x, y=stats.norm.pdf(x, p_a, a_stderr),\n",
    "                         name='CLT A', line_color=col_a, line_dash='dash'))\n",
    "fig.add_trace(go.Scatter(x=[p_b], y=[stats.norm.pdf(p_b, p_b, b_stderr)],\n",
    "                         name='B', line_color=col_b, mode='markers'))\n",
    "fig.add_trace(go.Scatter(x=x, y=stats.norm.pdf(x, p_b, b_stderr),\n",
    "                         name='CLT B', marker_color=col_b, line_dash='dash'))\n",
    "fig.update_layout(\n",
    "    title='Assumed CLT-like Means Distributions',\n",
    "    xaxis_range=[0.2, 0.5],\n",
    "    height=450, width=800\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "\n",
    "#todo: use one-sided test?\n",
    "diff = p_b - p_a\n",
    "diff_stderr = np.sqrt(a_stderr**2 + b_stderr**2)\n",
    "alpha = 0.05\n",
    "x_a_l = stats.norm.ppf(alpha/2, loc=0, scale=diff_stderr)\n",
    "x_a_u = stats.norm.ppf(1-alpha/2, loc=0, scale=diff_stderr)\n",
    "diff_pval = stats.norm.cdf(0, diff, diff_stderr)\n",
    "\n",
    "x=np.linspace(-5*diff_stderr, 5*diff_stderr, 1000)\n",
    "\n",
    "col = 'rgba(0, 0, 250, 0.7)'\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=stats.norm.pdf(x, 0, diff_stderr),\n",
    "                         line_color=col, name='Diff'))\n",
    "fig.add_trace(go.Scatter(x=x[x <= x_a_l], y=stats.norm.pdf(x, 0, diff_stderr)[x <= x_a_l], \n",
    "                         fill='tozeroy',\n",
    "                         name='α/2',\n",
    "                         line_color=col, fillcolor=col))\n",
    "fig.add_trace(go.Scatter(x=x[x >= x_a_u], y=stats.norm.pdf(x, 0, diff_stderr)[x >= x_a_u], \n",
    "                         fill='tozeroy',\n",
    "                         name='1 - α/2',\n",
    "                         line_color=col, fillcolor=col))\n",
    "#fig.add_vline(p_b - p_a)\n",
    "fig.add_trace(go.Scatter(x=[p_b - p_a, p_b - p_a], y=[0, stats.norm.pdf(0, 0, diff_stderr)],\n",
    "                        line_dash='dash', mode='lines', name='(pb-pa)'))\n",
    "fig.update_layout(\n",
    "    title='Approx Means Difference Given H0 is True',\n",
    "    height=450, width=800\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "#todo: use alpha/2 instead of alpha?\n",
    "print(f\"p value = {diff_pval:.3f}\")\n",
    "print(f\"H {'can' if diff_pval < alpha else 'can not'} be rejected\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f9c83c",
   "metadata": {},
   "source": [
    "Сравнение описанного метода с $t$-тестом из SciPy [[SciPyT](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74005163",
   "metadata": {},
   "outputs": [],
   "source": [
    "def approx_ttest_conv_pval(sa, na, sb, nb):\n",
    "    pa = sa / na\n",
    "    pb = sb / nb\n",
    "    stderr_a = np.sqrt(pa * (1 - pa) / na)\n",
    "    stderr_b = np.sqrt(pb * (1 - pb) / nb)\n",
    "    diff = pb - pa\n",
    "    diff_stderr = np.sqrt(stderr_a**2 + stderr_b**2)\n",
    "    pval = stats.norm.cdf(0, diff, diff_stderr)\n",
    "    return pval\n",
    "\n",
    "def scipy_ttest_conv_pval(sa, na, sb, nb, **kwargs):\n",
    "    a = np.zeros(n)\n",
    "    a[:sa] = 1\n",
    "    b = np.zeros(n)\n",
    "    b[:sb] = 1\n",
    "    t, p = stats.ttest_ind(a, b, equal_var=False, **kwargs)\n",
    "    return p\n",
    "\n",
    "print('scipy.stats.ttest_indep p-val:', scipy_ttest_conv_pval(sa, n, sb, n, alternative='less'))\n",
    "print('approx p-val:', approx_ttest_conv_pval(sa, n, sb, n))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4bd0b24",
   "metadata": {},
   "source": [
    "$p$-значения совпадают в 3 десятичных знаках. \n",
    "Если в `stats.ttest_ind` передавать параметр `alternative='two-sided'`, p-значение будет в два раза выше."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82db3276",
   "metadata": {},
   "source": [
    "Описанный подход применим для случайных величин с произвольным распределением, для которых применима центральная предельная теорема. Для скошенных распределений может потребоваться больше данных для ее применимости. Необходимый размер выборки можно оценить с помощью теоремы Берри-Ессеена [[BerEsTheor](https://en.wikipedia.org/wiki/Berry%E2%80%93Esseen_theorem)]. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e85d2d65",
   "metadata": {},
   "source": [
    "Помимо $t$-теста есть другие тесты для сравнения распределений или их отдельных свойств: тест Колмогорова-Смирнова для распределений [[KSTest](https://en.wikipedia.org/wiki/Kolmogorov%E2%80%93Smirnov_test)], U-тест [[UTest](https://en.wikipedia.org/wiki/Mann%E2%80%93Whitney_U_test)],\n",
    "сравнение медиан [[MedianTest](https://en.wikipedia.org/wiki/Median_test)]. Они не требуют предположения о нормальных распределениях сравниваемых величин. При этом у них те же особенности интерпретации, что и у $t$-теста - см. далее."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37645185",
   "metadata": {},
   "source": [
    "# Особенности интерпретации"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e201f6a9",
   "metadata": {},
   "source": [
    "В А/Б-тесте нужно ответить на следующие вопросы:\n",
    "\n",
    "- Какой вариант лучше и насколько?\n",
    "- Каковы оценки целевой метрики в каждом варианте?\n",
    "- Насколько уверены в оценке?\n",
    "- Сколько должен продолжаться эксперимент?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32c552e3",
   "metadata": {},
   "source": [
    "Метод \"проверки статистических гипотез\" в описанном выше виде не дает на них прямого ответа."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2d8c16e",
   "metadata": {},
   "source": [
    "Для ответа на вопрос \"Какой вариант лучше?\" и \"Насколько уверены в оценке?\" подойдет вероятность разности средних больше нуля\n",
    "\n",
    "$$\n",
    "P(\\mu_A - \\mu_B > 0 | data) .\n",
    "$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "359d85a2",
   "metadata": {},
   "source": [
    "В методе проверки гипотез решение принимается на основе $p$-значения. Оно считается как вероятность получить \"фактические или более экстремальные\" данные при выполнении нулевой гипотезы $H_0$\n",
    "\n",
    "$$\n",
    "p = P(x \\ge x_{data} | H_0) = P(x \\ge x_{data} | \\mu_A = \\mu_B).\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f2779d",
   "metadata": {},
   "source": [
    "$P$-значение показывает, насколько вероятно получить данные в рамках выбранной гипотезы, но его нельзя интерпретировать как вероятность, что гипотеза $H_0$ верна или не верна [[StatTestMisinterpret](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4877414/)] $P(x \\ge x_{data} | H_0) \\ne P(H_0 | data)$. В общем случае"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cccee2f4",
   "metadata": {},
   "source": [
    "$$\n",
    "P(data | H_0) \\ne P(H_0 | data).\n",
    "$$ "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4088c75",
   "metadata": {},
   "source": [
    "Корректное выражение для оценки вероятности нулевой гипотезы на основе собранных данных можно записать с помощью соотношения Байеса"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29990245",
   "metadata": {},
   "source": [
    "$$\n",
    "P(H_0 | data) = \\frac{P(data | H_0) P(H_0)}{P(data)}\n",
    "= \\frac{P(data | H_0) P(H_0)}{P(data|H_0) P(H_0) + P(data| \\neg H_0) P(\\neg H_0) } .\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca2ab0c4",
   "metadata": {},
   "source": [
    "*Малость $p$-значения в абсолютных величинах ни о чем не говорит. Для выбора между гипотезами нужно сравнивать вероятности получить данные в рамках разных гипотез и распространенность самих гипотез [[UU]()]. $P$-значение игнорирует $P(H_0):P(\\neg H_0)$ и $P(data| \\neg H_0)$.*   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e61ffb01",
   "metadata": {},
   "source": [
    "Принятие решения без учета других гипотез будет вариантом ошибки игнорирования базового процента [[BaseRateFal](https://en.wikipedia.org/wiki/Base_rate_fallacy)]. См. пример на графике ниже"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da3c5f15",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = 10\n",
    "h = 10\n",
    "h0_w = 2.5/w\n",
    "alpha = 8/h\n",
    "beta=2/h\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=[0,0,w,w], y=[0,h,h,0], fill=\"toself\", \n",
    "                         name='Choose H1 | H1, 1-β')) #name='H1'))\n",
    "fig.add_trace(go.Scatter(x=[0,0,h0_w*w, h0_w*w], y=[0,h,h,0], fill=\"toself\", \n",
    "                         name='Choose H1 | H0, α')) #name='H0'))\n",
    "fig.add_trace(go.Scatter(x=[0,0,h0_w*w, h0_w*w], y=[0,alpha*h,alpha*h,0], fill=\"toself\", \n",
    "                         name='Choose H0 | H0, 1-α'))\n",
    "fig.add_trace(go.Scatter(x=[h0_w*w,h0_w*w,w,w], y=[0,beta*h,beta*h,0], fill=\"toself\", \n",
    "                         name='Choose H0 | H1, β'))\n",
    "fig.add_annotation(x=h0_w/2*w, y=1.1*h,\n",
    "            text=\"H0\",\n",
    "            showarrow=False)\n",
    "fig.add_annotation(x=w/2 + h0_w/2*w, y=1.1*h,\n",
    "            text=\"H1\",\n",
    "            showarrow=False)\n",
    "fig.add_annotation(x=h0_w/2*w, y=(h+alpha*h)/2,\n",
    "            text=\"Choose H1 | H0\",\n",
    "            showarrow=False)\n",
    "fig.add_annotation(x=h0_w/2*w, y=beta*h/2,\n",
    "            text=\"Choose H0 | H0\",\n",
    "            showarrow=False)\n",
    "fig.add_annotation(x=(h0_w*w + w)/2, y=(h+alpha*h)/2,\n",
    "            text=\"Choose H1 | H1\",\n",
    "            showarrow=False)\n",
    "fig.add_annotation(x=(h0_w*w + w)/2, y=beta*h/2,\n",
    "            text=\"Choose H0 | H1\",\n",
    "            showarrow=False)\n",
    "fig.update_layout(\n",
    "    height=450, width=800\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0202fc",
   "metadata": {},
   "source": [
    "$$\n",
    "P(H_0 | \\mbox{Choose }H_0) = \\frac{P(\\mbox{Choose }H_0 | H_0)}{P(\\mbox{Choose }H_0|H_0) + P(\\mbox{Choose }H_0 | H_1)} = \\frac{\\mbox{Green}}{\\mbox{Green} + \\mbox{Purple}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cedfb76",
   "metadata": {},
   "source": [
    "В реальном тесте неизвестно, верна гипотеза или нет. Поэтому интересует вероятность выбора корректного значения. Ее можно выразить через вероятности ошибок $\\alpha$ и $\\beta$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2add7dd2",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "P(\\mbox{Correct Guess}) & = P(\\mbox{Choose }H_0 | H_0) P(H_0) + P(\\mbox{Choose }H_1 | H_1)P(H_1) \n",
    "\\\\\n",
    "    & = (1 - \\alpha) P(H_0) + (1 - \\beta) P(H_1) .\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1ed333",
   "metadata": {},
   "source": [
    "Видно, что доля правильно угаданных вариантов помимо $\\alpha$ и $\\beta$ зависит также от соотношения между $P(H_0)$ и $P(H_1)$. Если $P(H_1) \\gg P(H_0)$, т.е. команда предлагает хорошие гипотезы, то $P(\\mbox{Correct Guess}) \\approx 1 - \\beta$, если же гипотезы в-основном плохие $P(H_0) \\gg P(H_1)$, то $P(\\mbox{Correct Guess}) \\approx 1 - \\alpha$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bffad81c",
   "metadata": {},
   "source": [
    "Этот эффект можно продемонстрировать на примере. Пусть есть 2 группы. В контрольной среднее значение $\\mu_A = 0.1$ фиксировано. В экспериментальной среднее либо такое же $\\mu_B = \\mu_A$, либо с улучшением на 5%  $\\mu_B = 1.05 \\mu_A$. Значение выбирается случайно. Нужно оценить, с какой вероятностью выбор будет корректным. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e4b5b9",
   "metadata": {},
   "source": [
    "При $\\alpha = 0.05$, $\\beta = 0.2$, $\\Delta = 0.05$, $\\mu_A = 0.1$ размер выборки в каждой группе $N \\approx 57000$ [[ABSample](https://www.evanmiller.org/ab-testing/sample-size.html#!10;80;5;5;1)]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42e30e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu0 = 0.1\n",
    "mu1 = mu0 * 1.05\n",
    "delta = mu1 - mu0\n",
    "\n",
    "alpha = 0.05\n",
    "beta = 0.2\n",
    "\n",
    "ph0_prob = np.arange(0.01, 1.01, 0.1)\n",
    "ph1_prob = 1 - ph0_prob\n",
    "\n",
    "#todo: vectorize?\n",
    "Nexp = 10000\n",
    "corrguess_pval = []\n",
    "corrguess_pval_theory = []\n",
    "beta_pval = []\n",
    "beta_pval_theory = []\n",
    "alpha_pval = []\n",
    "alpha_pval_theory = []\n",
    "for ph0, ph1 in zip(ph0_prob, ph1_prob):    \n",
    "    mua = np.full(shape=(ph0.size, Nexp), fill_value=mu0)\n",
    "    mub = np.random.choice(a=[mu0, mu1], p=[ph0, ph1], size=Nexp)\n",
    "    N = int((np.sqrt(2) * (stats.norm.ppf(1 - alpha/2) - stats.norm.ppf(beta)))**2 * mu0*(1-mu0) / delta**2)\n",
    "    sa = stats.binom.rvs(n=N, p=mua, size=Nexp)\n",
    "    sb = stats.binom.rvs(n=N, p=mub, size=Nexp)\n",
    "    pval = approx_ttest_conv_pval(sa, N, sb, N)\n",
    "    h0 = (mub == mu0)\n",
    "    h1 = (mub != mu0)\n",
    "    reject_h0 = (pval < alpha/2) | (pval > 1 - alpha/2)\n",
    "    keep_h0 = ~reject_h0\n",
    "    corrguess_pval_theory.append((1-alpha)*ph0 + (1-beta)*ph1)\n",
    "    corrguess_pval.append(sum(((keep_h0 & h0) | (reject_h0 & h1)))/Nexp)\n",
    "    beta_pval.append(sum((keep_h0 & h1))/sum(h1))\n",
    "    beta_pval_theory.append(beta)\n",
    "    alpha_pval.append(sum((reject_h0 & h0))/sum(h0))\n",
    "    alpha_pval_theory.append(alpha)\n",
    "    \n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=ph0_prob, y=corrguess_pval, name='Correct guesses'))\n",
    "fig.add_trace(go.Scatter(x=ph0_prob, y=corrguess_pval_theory, line_dash='dash',\n",
    "                         name='Correct guesses, theory'))\n",
    "fig.add_trace(go.Scatter(x=ph0_prob, y=beta_pval, name='β'))\n",
    "fig.add_trace(go.Scatter(x=ph0_prob, y=beta_pval_theory, line_dash='dash',\n",
    "                         name='β, theory'))\n",
    "fig.add_trace(go.Scatter(x=ph0_prob, y=alpha_pval, name='α'))\n",
    "fig.add_trace(go.Scatter(x=ph0_prob, y=alpha_pval_theory, line_dash='dash',\n",
    "                         name='α, theory'))\n",
    "fig.update_layout(\n",
    "    title='Correct Guesses and Errors Rates by p-val',\n",
    "    yaxis_title='Rate',\n",
    "    xaxis_title='P(H0)',\n",
    "    yaxis_range=[0, 1],\n",
    "    width=800, height=450\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bda33b2",
   "metadata": {},
   "source": [
    "Общее количество правильно угаданных вариантов и уровни ошибок $\\alpha$ и $\\beta$ такие, как и ожидалось. Видно, что общее количество правильно угаданных вариантов зависит от соотношения $P(H_0):P(H_1)$. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fadd7a3",
   "metadata": {},
   "source": [
    "Можно сравнить количество правильно угаданных вариантов при выборе на основе $p$-значения и вероятности вероятности $P(H_0 | data)$. Т.к. всего 2 гипотезы, то можно смотреть отношение $P(H_0 | data):P(H_1 | data)$. Если оно больше $1$, то выбирать $H_0$, если меньше - $H_1$.\n",
    "\n",
    "$$\n",
    "\\frac{P(H_0 | data)}{P(H_1 | data)} = \\frac{P(data | H_0) P(H_0)}{P(data | H_1) P(H_1)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f35eff26",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ph0_to_ph1_conv(sa, na, sb, nb, ph0, ph1, delta):\n",
    "    pa = sa / na\n",
    "    pb = sb / nb\n",
    "    stderr_a = np.sqrt(pa * (1 - pa) / na)\n",
    "    stderr_b = np.sqrt(pb * (1 - pb) / nb)\n",
    "    diff = pb - pa\n",
    "    diff_stderr = np.sqrt(stderr_a**2 + stderr_b**2)\n",
    "    return stats.norm.pdf(diff, 0, diff_stderr) / stats.norm.pdf(diff, delta, diff_stderr) * ph0 / ph1\n",
    "\n",
    "mu0 = 0.1\n",
    "mu1 = mu0 * 1.05\n",
    "delta = mu1 - mu0\n",
    "\n",
    "alpha = 0.05\n",
    "beta = 0.2\n",
    "\n",
    "#todo: vectorize?\n",
    "ph0_prob = []\n",
    "cg_prob = []\n",
    "cg_pval = []\n",
    "cg_pval_theory = []\n",
    "for ph0 in np.arange(0.01, 1.01, 0.1):\n",
    "    ph1 = 1-ph0\n",
    "    ph0_prob.append(ph0)    \n",
    "    Nexp = 10000\n",
    "    mua = np.array([mu0] * Nexp)\n",
    "    mub = np.random.choice(a=[mu0, mu1], p=[ph0, ph1], size=Nexp)\n",
    "    N = int((np.sqrt(2) * (stats.norm.ppf(1 - alpha/2) - stats.norm.ppf(beta)))**2 * mu0*(1-mu0) / delta**2)\n",
    "    sa = stats.binom.rvs(n=N, p=mua, size=Nexp)\n",
    "    sb = stats.binom.rvs(n=N, p=mub, size=Nexp)\n",
    "    pval = approx_ttest_conv_pval(sa, N, sb, N)\n",
    "    p_h0_to_h1_data = ph0_to_ph1_conv(sa=sa, na=N, sb=sb, nb=N, ph0=ph0, ph1=ph1, delta=delta)\n",
    "    #p_h0_to_h1_data_wrongdelta = ph0_to_ph1_conv(sa=sa, na=N, sb=sb, nb=N, ph0=ph0, ph1=ph1, delta=sa/N - sb/N)\n",
    "    h0_data = p_h0_to_h1_data > 1\n",
    "    h1_data = ~h0_data\n",
    "    h0 = (mub == mu0)\n",
    "    h1 = (mub != mu0)\n",
    "    reject_h0 = (pval < alpha/2) | (pval > 1 - alpha/2)\n",
    "    keep_h0 = ~reject_h0\n",
    "    cg_pval_theory.append((1-alpha)*ph0 + (1-beta)*ph1)\n",
    "    cg_pval.append(sum(((keep_h0 & h0) | (reject_h0 & h1)))/Nexp)\n",
    "    cg_prob.append(sum(((h0_data & h0) | (h1_data & h1)))/Nexp)\n",
    "    \n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=ph0_prob, y=cg_prob, name='P(H0)'))\n",
    "fig.add_trace(go.Scatter(x=ph0_prob, y=cg_pval, name='p-val'))\n",
    "fig.add_trace(go.Scatter(x=ph0_prob, y=cg_pval_theory, line_dash='dash',\n",
    "                         name='p-val theory'))\n",
    "fig.update_layout(\n",
    "    title='Correct Guesses by p-val and P(H0)',\n",
    "    yaxis_title='Prob',\n",
    "    xaxis_title='P(H0)',\n",
    "    yaxis_range=[0, 1],\n",
    "    width=800, height=450\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d699b48",
   "metadata": {},
   "source": [
    "*Выбор группы по вероятности работает лучше. Но это зависит от модели*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63b3c462",
   "metadata": {},
   "source": [
    "*Можно предположить $P(H_0):P(\\neg H_0) = 3:7$. В ситуации с заранее неизвестным значением эффекта $\\Delta$ попытки посчитать $P(data| \\neg H_0)$ будут сдвигать подход в сторону байесовского моделирования. Проще делать все в рамках этого моделирования.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab849134",
   "metadata": {},
   "source": [
    "Метод проверки гипотез формально не дает ответ на вопрос о \"величине эффекта\" и оценках \"целевой метрики в каждом варианте\". Для оценки средних вместо распределений $P(\\mu_A - \\mu_B | data)$, $P(\\mu_A | data)$, $P(\\mu_B | data)$ обычно используют доверительные интервалы [[ConfInt](https://en.wikipedia.org/wiki/Confidence_interval)]. Например, для $\\mu_A$ строятся величины $l_n$, $u_n$, такие что\n",
    "\n",
    "$$\n",
    "l_n, u_n: P(l_n < \\mu_A < u_n | data) = 1 - \\alpha .\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbd43d1",
   "metadata": {},
   "source": [
    "Для средних границы интервала $l_n$, $u_n$ строят на основе центральной предельной теоремы   \n",
    "*поправить*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54c85a9a",
   "metadata": {},
   "source": [
    "$$\n",
    "P\\left( l_n < \\frac{x_n - \\mu}{\\sigma/n} < u_n \\right) \\to \\Phi(l_n) + \\Phi(u_n) . \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "385b47e7",
   "metadata": {},
   "source": [
    "В доверительных интервалах случайные величины - границы интервала, а не сам оцениваемый параметр."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86da36bf",
   "metadata": {},
   "source": [
    "В байесовском моделировании конверсий с биномиального распределением как функцией правдоподобия и равномерным априорным распределением апостериорное распределение будет бета-распределением\n",
    "\n",
    "$$\n",
    "P(x | data) = Beta(x; \\alpha, \\beta) ,\n",
    "\\\\\n",
    "\\alpha = s + 1, \\quad \\beta = N - s + 1 .\n",
    "$$\n",
    "\n",
    "При большом количестве точек оно приближенно совпадает с нормальным  \n",
    "*уточнить*\n",
    "\n",
    "$$\n",
    "P(x | data) \\sim N\\left( x; p, \\frac{p(1-p)}{N} \\right) .\n",
    "$$\n",
    "\n",
    "Т.е. байесовское моделирование численно дает близкую оценку для интервалов. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c2a597d",
   "metadata": {},
   "source": [
    "Доверительные интервалы не гарантируют, что \"с 95% вероятностью значение $\\mu_A$ будет внутри построенного интервала.\" Частотная интерпретация доверительных итервалов - если повторить эксперимент и процедуру построения 95-процентного доверительного интервала 100 раз, примерно в 95 случаях из 100 реальное среднее будет находится внутри построенного интервала (см. график ниже).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d01d4f22",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = 0.6\n",
    "\n",
    "n_exp = 100\n",
    "N = 1000\n",
    "s = stats.binom.rvs(n=N, p=p, size=n_exp)\n",
    "p_mean = s / N\n",
    "p_stderr = np.sqrt(p_mean * (1 - p_mean) / N)\n",
    "alpha = 0.05\n",
    "x_a_l = stats.norm.ppf(alpha/2, loc=p_mean, scale=p_stderr)\n",
    "x_a_u = stats.norm.ppf(1-alpha/2, loc=p_mean, scale=p_stderr)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_hline(p)\n",
    "missed = 0\n",
    "for x, l, u in zip(range(1, N+1), x_a_l, x_a_u):\n",
    "    col = 'black'\n",
    "    if u < p or l > p:\n",
    "        col = 'blue'\n",
    "        missed += 1\n",
    "    fig.add_trace(go.Scatter(x=[x,x], y=[l, u], mode='lines+markers', \n",
    "                             line_color=col))\n",
    "fig.update_layout(\n",
    "    title='Confidence Intervals',\n",
    "    xaxis_title='Experiment #',\n",
    "    yaxis_title='p',\n",
    "    showlegend=False,\n",
    "    height=450, width=800\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "print(f\"In {n_exp} experiments, {missed} {1-alpha}-intervals failed to cover exact mean value.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2be63111",
   "metadata": {},
   "source": [
    "На графике выше видно, что по отдельно взятому доверительному интервалу, нельзя сказать, где именно в нем находится среднее и попадает ли оно в этот интервал. *С байесовским моделированием будет то же самое*. *При этом у них разная интерпретация. Но результаты одинаковые.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b49ac2ed",
   "metadata": {},
   "source": [
    "В других случаях доверительные интервалы могут отличаться от байесовских оценок [[ConfIntVsBsInt](https://bayes.wustl.edu/etj/articles/confidence.pdf)].  \n",
    "*Еще обсуждение [[CIFal](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4742505/pdf/13423_2015_Article_947.pdf)].* "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cece0f0",
   "metadata": {},
   "source": [
    "*Основные сложности с доверительными интервалами для средних - технические. Две случайных величины вместо одной. К тому же с непонятными распределениями.*  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a2b70ce",
   "metadata": {},
   "source": [
    "Для оценки \"длительности эксперимента\" размер выборки рассчитывают до эксперимента так, чтобы обеспечить уровни статистической значимости $\\alpha$ и мощности $\\beta$. Задают статистическую значимость, мощность, базовую величину и изменение эффекта, по этим значениям рассчитывают размер выборки $N$ в каждой группе.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efb91d49",
   "metadata": {},
   "source": [
    "Для $t$-тестов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6e83967",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = 0\n",
    "scale = 0.2\n",
    "delta = 0.5\n",
    "\n",
    "x = np.arange(-3, 3, 0.01)\n",
    "y0 = stats.norm.pdf(x, loc=mu, scale=scale)\n",
    "y1 = stats.norm.pdf(x, loc=mu+delta, scale=scale)\n",
    "\n",
    "a = 0.05\n",
    "#x_a = mu + 1.96 * scale\n",
    "x_a = stats.norm.ppf(1-alpha/2, loc=mu, scale=scale)\n",
    "\n",
    "col0 = 'rgba(250, 0, 0, 0.7)'\n",
    "col1 = 'rgba(0, 0, 250, 0.7)'\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=y1, line_color=col1, name='H1'))\n",
    "fig.add_trace(go.Scatter(x=x[x<x_a], y=y1[x<x_a], \n",
    "                         fill='tozeroy', \n",
    "                         line_color=col1, fillcolor=col1,\n",
    "                         name='β'))\n",
    "fig.add_vline(x_a)\n",
    "fig.add_trace(go.Scatter(x=x, y=y0, line_color=col0, name='H0'))\n",
    "fig.add_trace(go.Scatter(x=x[x>=x_a], y=y0[x>=x_a], \n",
    "                         fill='tozeroy', \n",
    "                         line_color=col0, fillcolor=col0,\n",
    "                         name='α/2'))\n",
    "fig.update_layout(\n",
    "    xaxis_range=(-2, 2),\n",
    "    height=450, width=800\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5320d9c9",
   "metadata": {},
   "source": [
    "Оценка размера выборки делается из соображений вида:\n",
    "\n",
    "$$\n",
    "CDF_{H_0}(x_{\\alpha}) = 1 - \\alpha\n",
    "\\\\\n",
    "CDF_{H_{\\Delta}}(\\Delta - x_{\\alpha}) = \\beta\n",
    "\\\\\n",
    "\\\\\n",
    "\\begin{cases}\n",
    "\\Phi \\left( \\frac{x_{\\alpha} - \\mu_{H_0}}{\\sigma_{H_0}} \\right) = 1 - \\alpha\n",
    "\\\\\n",
    "\\Phi \\left( \\frac{x_{\\alpha} - \\mu_{H_\\Delta}}{\\sigma_{H_{\\Delta}}} \\right) = \\beta \n",
    "\\end{cases}\n",
    "\\Rightarrow\n",
    "\\mu_{H_0} + \\sigma_{H_0} \\Phi^{-1}(1 - \\alpha) = \\mu_{H_\\Delta} + \\sigma_{H_{\\Delta}}\\Phi^{-1}(\\beta)\n",
    "\\\\\n",
    "\\mu_{H_0} = 0, \n",
    "\\quad \n",
    "\\mu_{H_\\Delta} = \\Delta,\n",
    "\\quad\n",
    "\\sigma_{H_0} = \\sigma_{H_{\\Delta}} \\approx \\sqrt{2}\\frac{s}{\\sqrt{N}}\n",
    "\\\\\n",
    "N = \\left[ \\frac{s}{\\Delta} \\sqrt{2} \\left( \\Phi^{-1}(1 - \\alpha) - \\Phi^{-1}(\\beta) \\right) \\right]^2\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a46f5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def approx_t_sample_size(stderr, delta, alpha, beta):\n",
    "    c = np.sqrt(2) * (stats.norm.ppf(1 - alpha) - stats.norm.ppf(beta))\n",
    "    return np.ceil((c * stderr / delta)**2).astype(int)\n",
    "\n",
    "p = 0.1\n",
    "p_stderr = np.sqrt(p * (1-p))\n",
    "approx_t_sample_size(stderr=p_stderr, delta=0.005, alpha=0.025, beta=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e089f52",
   "metadata": {},
   "source": [
    "При $(1 - \\alpha) = 0.975$, $\\beta = 0.2$ приближенно [[RuleOfThumbSample](https://en.wikipedia.org/wiki/Power_of_a_test#Rule_of_thumb)]:\n",
    "\n",
    "$$\n",
    "N = 16 \\frac{s^2}{\\Delta^2} . \n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "323dcfc8",
   "metadata": {},
   "source": [
    "Проблема такого подхода в том, что размер эффекта $\\Delta$ неизвестен. Если $\\mu_B \\gt \\mu_A + \\Delta$, то $\\beta$ будет меньше заданного (на графике выше средние будут правее максимума правого пика $H_1$). При этом будет переоценивается размер сэмпла. Если $\\mu_B \\le \\mu_A + \\Delta$, то $\\beta$ будет выше заданного. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b66da6f3",
   "metadata": {},
   "source": [
    "*Можно оценить размер эффекта по части данных, после чего задать величину эффекта. Например, собрать по 100 точек, после чего выбрать размер эффекта на нижней границе доверительного интервала разности.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4778e26",
   "metadata": {},
   "source": [
    "*Возможным вариантом было бы формулировать гипотезы в виде $H_0: |\\mu_A - \\mu_B| \\le \\Delta$. Но это приближает подход к байесовскому моделированию.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb72874",
   "metadata": {},
   "source": [
    "Для выполнения гарантий по $\\alpha$ и $\\beta$ требуется принимать решение об эксперименте по выборке не менее определенного размера. При принятии решений по выборке меньшего размера гарантии на $\\alpha$ и $\\beta$ будут отозваны - это называют \"проблемой подглядывания\" [[MillerHowNotTo](https://www.evanmiller.org/how-not-to-run-an-ab-test.html)]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "080ca3f0",
   "metadata": {},
   "source": [
    "Выше при моделировании числа корректно угаданных вариантов было показано, что описанный способ оценки размера выборки действительно дает заданные значения $\\alpha$ и $\\beta$ когда есть только 2 варианта. Оценка специфична для $t$-теста. Для других тестов оценки должны делаться из других соображений.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20613173",
   "metadata": {},
   "source": [
    "# Заключение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91147230",
   "metadata": {},
   "source": [
    "Приведен обзор метода проверки статистических гипотез. Рассмотрено использование $t$-тестов для сравнения средних в группах.\n",
    "\n",
    "Принятие решения о выборе варианта на основе $p$-значения не дает ответа на вопрос какая группа лучше и какая в этом уверенность. Является вариантом ошибки базового процента.\n",
    "\n",
    "При сравнении средних для оценки значений метрик и эффекта можно использовать доверительные интервалы на основе центральной предельной теоремы. Для конверсий при больших размерах выборки интервалы численно будут близки к байесовским интервалам наибольшей плотности вероятности. Но будут отличаться по интерпретации.  \n",
    "\n",
    "Для оценки длительности эксперимента размер выборки оценивается так, чтобы \"ошибки первого и второго рода\" не превышали заданных уровней. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ede3360c",
   "metadata": {},
   "source": [
    "# Благодарности"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9e21ece",
   "metadata": {},
   "source": [
    "# Ссылки"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dde5fd2",
   "metadata": {},
   "source": [
    "[[StTest](https://en.wikipedia.org/wiki/Statistical_hypothesis_testing)] - Statistical_hypothesis_testing  \n",
    "[[TestStat](https://en.wikipedia.org/wiki/Test_statistic)] -   \n",
    "[[TailedTests](https://en.wikipedia.org/wiki/One-_and_two-tailed_tests)] -   \n",
    "[[PVal](https://en.wikipedia.org/wiki/P-value)] - P-value  \n",
    "[[FairCoin](https://en.wikipedia.org/wiki/Checking_whether_a_coin_is_fair)] -  \n",
    "[[StErrors](https://en.wikipedia.org/wiki/Type_I_and_type_II_errors)] - Type_I_and_type_II_errors  \n",
    "[[StSign](https://en.wikipedia.org/wiki/Statistical_significance)] - Statistical_significance  \n",
    "[[StPower](https://en.wikipedia.org/wiki/Power_of_a_test)] - Power_of_a_test  \n",
    "[[HNull](https://en.wikipedia.org/wiki/Null_hypothesis)] - Null_hypothesis  \n",
    "[[ZScore](https://en.wikipedia.org/wiki/Standard_score)] - Standard_score  \n",
    "[[ZTest](https://en.wikipedia.org/wiki/Z-test)] - Z-test  \n",
    "[[TDist](https://en.wikipedia.org/wiki/Student%27s_t-distribution)] -    \n",
    "[[TTest](https://en.wikipedia.org/wiki/Student's_t-test)] -    \n",
    "[[WelchTTest](https://en.wikipedia.org/wiki/Welch%27s_t-test)] -  \n",
    "[[MillerABSize](https://www.evanmiller.org/ab-testing/sample-size.html)] -  \n",
    "[[BerEsTheor](https://en.wikipedia.org/wiki/Berry%E2%80%93Esseen_theorem)] -  \n",
    "[[KSTest](https://en.wikipedia.org/wiki/Kolmogorov%E2%80%93Smirnov_test)] -   \n",
    "[[UTest](https://en.wikipedia.org/wiki/Mann%E2%80%93Whitney_U_test)] -  \n",
    "[[MedianTest](https://en.wikipedia.org/wiki/Median_test)] -   \n",
    "[[StatTestMisinterpret](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4877414/)] Statistical tests, P values, confidence intervals, and power: a guide to misinterpretations   \n",
    "[[UU]()] - Understanding Uncertainty  \n",
    "[[BaseRateFal](https://en.wikipedia.org/wiki/Base_rate_fallacy)] -  \n",
    "[[ConfInt](https://en.wikipedia.org/wiki/Confidence_interval)] -  \n",
    "[[ConfIntVsBsInt](https://bayes.wustl.edu/etj/articles/confidence.pdf)] -  \n",
    "[[CIFal](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4742505/pdf/13423_2015_Article_947.pdf)] -   \n",
    "[[RuleOfThumbSample](https://en.wikipedia.org/wiki/Power_of_a_test#Rule_of_thumb)] -  \n",
    "[[MillerHowNotTo](https://www.evanmiller.org/how-not-to-run-an-ab-test.html)] -  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67628f0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc28765",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb06fc62",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cfd40bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu0 = 0.1\n",
    "mu1 = mu0 * 1.15\n",
    "\n",
    "alpha = 0.05\n",
    "beta = 0.2\n",
    "#ph0 = 0.1\n",
    "#ph1 = 1-ph0\n",
    "\n",
    "Nexp = 50000\n",
    "mua = np.array([mu0] * Nexp)\n",
    "mub = stats.uniform.rvs(loc=mu0*1.1, scale=mu1-mu0, size=Nexp)\n",
    "\n",
    "Nest = 1000\n",
    "sa = stats.binom.rvs(n=Nest, p=mua, size=Nexp)\n",
    "sb = stats.binom.rvs(n=Nest, p=mub, size=Nexp)\n",
    "mu_data_a_est = sa / Nest\n",
    "mu_data_b_est = sb / Nest\n",
    "diff_est = np.abs(mu_data_b_est - mu_data_a_est)\n",
    "diff_est[diff_est < mu0 * 0.05] = mu0*0.05\n",
    "stderr_est = np.sqrt(mu_data_a_est * (1 - mu_data_a_est))\n",
    "print(diff_est)\n",
    "\n",
    "N = approx_t_sample_size(stderr=stderr_est, delta=diff_est, alpha=alpha/2, beta=beta)\n",
    "print(N)\n",
    "\n",
    "#N = (np.sqrt(2) * (stats.norm.ppf(1 - alpha/2) - stats.norm.ppf(beta)))**2\n",
    "sa = stats.binom.rvs(n=N, p=mua, size=Nexp)\n",
    "sb = stats.binom.rvs(n=N, p=mub, size=Nexp)\n",
    "\n",
    "mu_data_a = sa / N\n",
    "mu_data_b = sb / N\n",
    "mu_stderr_a = np.sqrt(mu_data_a * (1 - mu_data_a) / N)\n",
    "mu_stderr_b = np.sqrt(mu_data_b * (1 - mu_data_b) / N)\n",
    "\n",
    "diff = mu_data_b - mu_data_a\n",
    "diff_stderr = np.sqrt(mu_stderr_a**2 + mu_stderr_b**2)\n",
    "pval = stats.norm.cdf(0, diff, diff_stderr)\n",
    "\n",
    "h0 = (mub < mu0*1.103)\n",
    "h1 = (mub >= mu0*1.103)\n",
    "reject_h0 = (pval < alpha/2) | (pval > 1 - alpha/2)\n",
    "keep_h0 = ~reject_h0\n",
    "\n",
    "print(f\"PH0:PH1: {ph0:.2f}:{ph1:.2f}\")\n",
    "print()\n",
    "\n",
    "correct_guesses = ((keep_h0 & h0) | (reject_h0 & h1))\n",
    "#print(f\"Correct guesses (1-alpha)P(H0) + (1-beta)P(H1)\") \n",
    "#print(f\"Theory {(1-alpha)*ph0 + (1-beta)*ph1:.3f} \\t Fact {sum(correct_guesses)}/{Nexp}, {sum(correct_guesses)/Nexp:.3f}\")\n",
    "print()\n",
    "\n",
    "alpha_exp = (reject_h0 & h0)\n",
    "print(f\"alpha = P(Reject H0 | H0)\") \n",
    "print(f\"Theory {alpha} \\t Fact {sum(alpha_exp)}/{sum(h0)}, {sum(alpha_exp)/sum(h0):.3f}\")\n",
    "print()\n",
    "\n",
    "beta_exp = (keep_h0 & h1)\n",
    "print(f\"beta = P(Keep H0 | H1)\") \n",
    "print(f\"Theory {beta} \\t Fact {sum(beta_exp)}/{sum(h1)}, {sum(beta_exp)/sum(h1):.3f}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb0038bc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7be5b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "ph0 = np.arange(0.01, 1.01, 0.1)\n",
    "ph0.size\n",
    "ph1 = 1 - ph0\n",
    "Nexp = 10000\n",
    "mua = np.full(shape=(ph0.size, Nexp), fill_value=mu0)\n",
    "#mua.shape\n",
    "mub = np.random.choice(a=[mu0, mu1], p=[ph0, ph1], size=Nexp)#size=mua.shape)\n",
    "#mub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc3494a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def approx_ttest_pval(sa, na, sb, nb):\n",
    "    mu_data_a = sa / N\n",
    "    mu_data_b = sb / N\n",
    "    mu_stderr_a = np.sqrt(mu_data_a * (1 - mu_data_a) / N)\n",
    "    mu_stderr_b = np.sqrt(mu_data_b * (1 - mu_data_b) / N)\n",
    "    diff = mu_data_b - mu_data_a\n",
    "    diff_stderr = np.sqrt(mu_stderr_a**2 + mu_stderr_b**2)\n",
    "    pval = stats.norm.cdf(0, diff, diff_stderr)\n",
    "    return pval\n",
    "\n",
    "mu0 = 0.1\n",
    "mu1 = mu0 * 1.05\n",
    "delta = mu1 - mu0\n",
    "\n",
    "alpha = 0.05\n",
    "beta = 0.2\n",
    "\n",
    "ph0_prob = np.arange(0.01, 1.01, 0.1)\n",
    "ph1_prob = 1 - ph0_prob\n",
    "\n",
    "#todo: vectorize?\n",
    "Nexp = 10000\n",
    "corrguess_pval = []\n",
    "corrguess_pval_theory = []\n",
    "beta_pval = []\n",
    "beta_pval_theory = []\n",
    "alpha_pval = []\n",
    "alpha_pval_theory = []\n",
    "for ph0, ph1 in zip(ph0_prob, ph1_prob):    \n",
    "    mua = np.full(shape=(ph0.size, Nexp), fill_value=mu0)\n",
    "    mub = np.random.choice(a=[mu0, mu1], p=[ph0, ph1], size=Nexp)\n",
    "    N = int((np.sqrt(2) * (stats.norm.ppf(1 - alpha/2) - stats.norm.ppf(beta)))**2 * mu0*(1-mu0) / delta**2)\n",
    "    sa = stats.binom.rvs(n=N, p=mua, size=Nexp)\n",
    "    sb = stats.binom.rvs(n=N, p=mub, size=Nexp)\n",
    "    pval = approx_ttest_pval(sa, N, sb, N)\n",
    "    h0 = (mub == mu0)\n",
    "    h1 = (mub != mu0)\n",
    "    reject_h0 = (pval < alpha/2) | (pval > 1 - alpha/2)\n",
    "    keep_h0 = ~reject_h0\n",
    "    corrguess_pval_theory.append((1-alpha)*ph0 + (1-beta)*ph1)\n",
    "    corrguess_pval.append(sum(((keep_h0 & h0) | (reject_h0 & h1)))/Nexp)\n",
    "    beta_pval.append(sum((keep_h0 & h1))/sum(h1))\n",
    "    beta_pval_theory.append(beta)\n",
    "    alpha_pval.append(sum((reject_h0 & h0))/sum(h0))\n",
    "    alpha_pval_theory.append(alpha)\n",
    "    \n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=ph0_prob, y=corrguess_pval, name='Correct guesses'))\n",
    "fig.add_trace(go.Scatter(x=ph0_prob, y=corrguess_pval_theory, line_dash='dash',\n",
    "                         name='Correct guesses, theory'))\n",
    "fig.add_trace(go.Scatter(x=ph0_prob, y=beta_pval, name='β'))\n",
    "fig.add_trace(go.Scatter(x=ph0_prob, y=beta_pval_theory, line_dash='dash',\n",
    "                         name='β, theory'))\n",
    "fig.add_trace(go.Scatter(x=ph0_prob, y=alpha_pval, name='α'))\n",
    "fig.add_trace(go.Scatter(x=ph0_prob, y=alpha_pval_theory, line_dash='dash',\n",
    "                         name='α, theory'))\n",
    "fig.update_layout(\n",
    "    title='Correct Guesses and Errors Rates by p-val',\n",
    "    yaxis_title='Prob',\n",
    "    xaxis_title='P(H0)',\n",
    "    yaxis_range=[0, 1],\n",
    "    width=800, height=450\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d86c8c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu0 = 0.1\n",
    "mu1 = mu0 * 1.05\n",
    "delta = mu1 - mu0\n",
    "\n",
    "alpha = 0.05\n",
    "beta = 0.2\n",
    "\n",
    "#todo: vectorize?\n",
    "ph0_prob = []\n",
    "cg_prob = []\n",
    "cg_pval = []\n",
    "cg_pval_theory = []\n",
    "beta_pval = []\n",
    "beta_pval_theory = []\n",
    "alpha_pval = []\n",
    "alpha_pval_theory = []\n",
    "for ph0 in np.arange(0.01, 1.01, 0.1):\n",
    "    #ph0 = 0.3\n",
    "    ph1 = 1-ph0\n",
    "    ph0_prob.append(ph0)\n",
    "    \n",
    "    Nexp = 10000\n",
    "    mua = np.array([mu0] * Nexp)\n",
    "    mub = np.random.choice(a=[mu0, mu1], p=[ph0, ph1], size=Nexp)\n",
    "\n",
    "    #N = 57000\n",
    "    #N = 57000\n",
    "    N = int((np.sqrt(2) * (stats.norm.ppf(1 - alpha/2) - stats.norm.ppf(beta)))**2 * mu0*(1-mu0) / delta**2)\n",
    "    sa = stats.binom.rvs(n=N, p=mua, size=Nexp)\n",
    "    sb = stats.binom.rvs(n=N, p=mub, size=Nexp)\n",
    "\n",
    "    mu_data_a = sa / N\n",
    "    mu_data_b = sb / N\n",
    "    mu_stderr_a = np.sqrt(mu_data_a * (1 - mu_data_a) / N)\n",
    "    mu_stderr_b = np.sqrt(mu_data_b * (1 - mu_data_b) / N)\n",
    "\n",
    "    diff = mu_data_b - mu_data_a\n",
    "    diff_stderr = np.sqrt(mu_stderr_a**2 + mu_stderr_b**2)\n",
    "    pval = stats.norm.cdf(0, diff, diff_stderr)\n",
    "\n",
    "    p_h0_to_h1_data = stats.norm.pdf(diff, 0, diff_stderr) / stats.norm.pdf(diff, delta, diff_stderr) * ph0 / ph1\n",
    "    h0_data = p_h0_to_h1_data > 1\n",
    "    h1_data = ~h0_data\n",
    "\n",
    "    h0 = (mub == mu0)\n",
    "    h1 = (mub != mu0)\n",
    "    reject_h0 = (pval < alpha/2) | (pval > 1 - alpha/2)\n",
    "    keep_h0 = ~reject_h0\n",
    "\n",
    "    cg_pval_theory.append((1-alpha)*ph0 + (1-beta)*ph1)\n",
    "    cg_pval.append(sum(((keep_h0 & h0) | (reject_h0 & h1)))/Nexp)\n",
    "    cg_prob.append(sum(((h0_data & h0) | (h1_data & h1)))/Nexp)\n",
    "    beta_pval.append(sum((keep_h0 & h1))/sum(h1))\n",
    "    beta_pval_theory.append(beta)\n",
    "    alpha_pval.append(sum((reject_h0 & h0))/sum(h0))\n",
    "    alpha_pval_theory.append(alpha)\n",
    "    #todo: add alpha & beta?\n",
    "    \n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=ph0_prob, y=cg_prob, name='P(H0)'))\n",
    "fig.add_trace(go.Scatter(x=ph0_prob, y=cg_pval, name='p-val'))\n",
    "fig.add_trace(go.Scatter(x=ph0_prob, y=cg_pval_theory, line_dash='dash',\n",
    "                         name='p-val theory'))\n",
    "fig.add_trace(go.Scatter(x=ph0_prob, y=beta_pval, name='beta p-val'))\n",
    "fig.add_trace(go.Scatter(x=ph0_prob, y=beta_pval_theory, line_dash='dash',\n",
    "                         name='beta theory'))\n",
    "fig.add_trace(go.Scatter(x=ph0_prob, y=alpha_pval, name='alpha p-val'))\n",
    "fig.add_trace(go.Scatter(x=ph0_prob, y=alpha_pval_theory, line_dash='dash',\n",
    "                         name='alpha theory'))\n",
    "fig.update_layout(\n",
    "    title='Correct Guesses by p-val and P(H0) and Errors Rates by p-val',\n",
    "    yaxis_title='Prob',\n",
    "    xaxis_title='P(H0)',\n",
    "    yaxis_range=[0, 1],\n",
    "    width=800, height=450\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c06acad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd5cff38",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu0 = 0.1\n",
    "mu1 = mu0 * 1.05\n",
    "\n",
    "alpha = 0.05\n",
    "beta = 0.2\n",
    "ph0 = 0.1\n",
    "ph1 = 1-ph0\n",
    "\n",
    "Nexp = 2000\n",
    "mua = np.array([mu0] * Nexp)\n",
    "mub = np.random.choice(a=[mu0, mu1], p=[ph0, ph1], size=Nexp)\n",
    "\n",
    "N = 57000\n",
    "#N = (np.sqrt(2) * (stats.norm.ppf(1 - alpha/2) - stats.norm.ppf(beta)))**2\n",
    "sa = stats.binom.rvs(n=N, p=mua, size=Nexp)\n",
    "sb = stats.binom.rvs(n=N, p=mub, size=Nexp)\n",
    "\n",
    "mu_data_a = sa / N\n",
    "mu_data_b = sb / N\n",
    "mu_stderr_a = np.sqrt(mu_data_a * (1 - mu_data_a) / N)\n",
    "mu_stderr_b = np.sqrt(mu_data_b * (1 - mu_data_b) / N)\n",
    "\n",
    "diff = mu_data_b - mu_data_a\n",
    "diff_stderr = np.sqrt(mu_stderr_a**2 + mu_stderr_b**2)\n",
    "pval = stats.norm.cdf(0, diff, diff_stderr)\n",
    "\n",
    "h0 = (mub == mu0)\n",
    "h1 = (mub != mu0)\n",
    "reject_h0 = (pval < alpha/2) | (pval > 1 - alpha/2)\n",
    "keep_h0 = ~reject_h0\n",
    "\n",
    "print(f\"PH0:PH1: {ph0:.2f}:{ph1:.2f}\")\n",
    "print()\n",
    "\n",
    "correct_guesses = ((keep_h0 & h0) | (reject_h0 & h1))\n",
    "print(f\"Correct guesses (1-alpha)P(H0) + (1-beta)P(H1)\") \n",
    "print(f\"Theory {(1-alpha)*ph0 + (1-beta)*ph1:.3f} \\t Fact {sum(correct_guesses)}/{Nexp}, {sum(correct_guesses)/Nexp:.3f}\")\n",
    "print()\n",
    "\n",
    "alpha_exp = (reject_h0 & h0)\n",
    "print(f\"alpha = P(Reject H0 | H0)\") \n",
    "print(f\"Theory {alpha} \\t Fact {sum(alpha_exp)}/{sum(h0)}, {sum(alpha_exp)/sum(h0):.3f}\")\n",
    "print()\n",
    "\n",
    "beta_exp = (keep_h0 & h1)\n",
    "print(f\"beta = P(Keep H0 | H1)\") \n",
    "print(f\"Theory {beta} \\t Fact {sum(beta_exp)}/{sum(h1)}, {sum(beta_exp)/sum(h1):.3f}\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779557a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eaaa46b0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1e95c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4501b3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5041227a",
   "metadata": {},
   "source": [
    "\\begin{align}\n",
    "P(\\mbox{H верна}) =& P(\\mbox{H верна} | \\mbox{Решение принять H}) P(\\mbox{Решение принять H}) \n",
    "\\\\\n",
    "& + P(\\mbox{H верна} | \\mbox{Решение отклонить H}) P(\\mbox{Решение отклонить H}) .\n",
    "\\end{align}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
