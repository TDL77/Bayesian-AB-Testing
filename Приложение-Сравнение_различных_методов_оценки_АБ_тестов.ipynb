{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Приложение: сравнение различных методов оценки А/Б-тестов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Приведен обзор методов для анализа А/Б-тестов*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Введение](#Введение)\n",
    "* [Оценки среднего и дисперсии на основе сэмпла](#Оценки-среднего-и-дисперсии-на-основе-сэмпла)\n",
    "* Ресэмплинг\n",
    "* [Метод максимального правдоподобия](#Метод-максимального-правдоподобия)\n",
    "* Доверительные интервалы\n",
    "* Проверка статистических гипотез\n",
    "* Байесовское моделирование\n",
    "* [Количество правильно угаданных вариантов](#Количество-правильно-угаданных-вариантов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Введение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В ч.1 обсуждался байесовским подход к оценке А/Б-тестов.  \n",
    "Было показано, как в рамках этого подхода ответить на вопросы\n",
    "- Какой вариант лучше и насколько?\n",
    "- Каковы оценки целевой метрики в каждом варианте?\n",
    "- Насколько уверены в оценке?\n",
    "- Сколько должен продолжаться эксперимент?\n",
    "\n",
    "Полезно сравнить байесовское моделирование с другими подходами.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Оценки среднего и дисперсии на основе сэмпла"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Закон больших чисел  \n",
    "https://en.wikipedia.org/wiki/Law_of_large_numbers  \n",
    "https://en.wikipedia.org/wiki/Estimator\n",
    "\n",
    "Среднее в выборке сходится к среднему в распределении."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(7)\n",
    "\n",
    "import scipy.stats as stats\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "#todo: update scipy; make venv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_exact = 0.7\n",
    "\n",
    "n = np.arange(10, 5000, 100)\n",
    "k = stats.binom.rvs(n, p_exact)\n",
    "p_samp = k/n\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=n, y=p_samp, name='p sample'))\n",
    "fig.add_trace(go.Scatter(x=[0, np.max(n)], y=[p_exact, p_exact],\n",
    "                         mode='lines',\n",
    "                         line_dash='dash', line_color='black', name='p exact'))\n",
    "fig.update_layout(\n",
    "    title='Exact and Sample Mean for Binomial Distribution',\n",
    "    xaxis_title='Sample Size',\n",
    "    yaxis_title='p',\n",
    "    yaxis_range=[0, 1],\n",
    "    xaxis_range=[0, np.max(n)],\n",
    "    height=550\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для дисперсии нужны поправки к значению в сэмпле чтобы получить несмещенную оценку  \n",
    "https://en.wikipedia.org/wiki/Unbiased_estimation_of_standard_deviation  \n",
    "Без дополнительных предположений о форме распределения дисперсия не говорит о площади распределения в области (xmean +- 3sigma)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Позволяет получить точечные оценки.  \n",
    "Можно выбрать группу с большим средним.  \n",
    "Но остается вопрос, с какой вероятностью одна группа лучше другой.  \n",
    "Для этого требуются дополнительные предположения о форме распределении.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Повторное сэмплирование данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Еще один вариант закона больших чисел говорит, что по мере набора данных частоты возможных значений в сэмле будут приближаться к их вероятности. Это является основой для частотной интерпретации вероятности."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также на этом основании имеющийся сэмпл данных можно считать приближением к точному распределению."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*What Teachers Should Know about the Bootstrap: Resampling in the Undergraduate Statistics Curriculum*  \n",
    "https://arxiv.org/abs/1411.5279  \n",
    "https://arxiv.org/pdf/1411.5279.pdf  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Бутстрап:  \n",
    "https://projecteuclid.org/journals/annals-of-statistics/volume-7/issue-1/Bootstrap-Methods-Another-Look-at-the-Jackknife/10.1214/aos/1176344552.full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно оценить неопределенность средних значений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_exact = 0.7\n",
    "\n",
    "n = 5000\n",
    "k = stats.binom.rvs(n, p_exact)\n",
    "p_sample = k/n\n",
    "p_sample\n",
    "\n",
    "#print(k, n)\n",
    "\n",
    "dt = np.zeros(n)\n",
    "dt[0:k] = 1\n",
    "\n",
    "#np.unique(dt, return_counts=True)\n",
    "\n",
    "n_bs = 1000\n",
    "bs = np.random.choice(dt, (n, n_bs))\n",
    "\n",
    "means = bs.mean(axis=1)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(x=means, histnorm='probability density',\n",
    "                           name='Means Diff',\n",
    "                           opacity=0.3))\n",
    "fig.add_vline(x=p_sample, line_dash='dash')\n",
    "fig.add_vline(x=p_exact)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_exact_a = 0.7\n",
    "p_exact_b = 0.65\n",
    "\n",
    "n = 5000\n",
    "k_a = stats.binom.rvs(n, p_exact_a)\n",
    "p_sample_a = k_a/n\n",
    "dt_a = np.zeros(n)\n",
    "dt_a[0:k_a] = 1\n",
    "\n",
    "k_b = stats.binom.rvs(n, p_exact_b)\n",
    "p_sample_b = k_b/n\n",
    "dt_b = np.zeros(n)\n",
    "dt_b[0:k_b] = 1\n",
    "\n",
    "n_bs = 1000\n",
    "bs_a = np.random.choice(dt_a, (n_bs, n))\n",
    "means_a = bs_a.mean(axis=1)\n",
    "\n",
    "bs_b = np.random.choice(dt_b, (n_bs, n))\n",
    "means_b = bs_b.mean(axis=1)\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(x=means_a, histnorm='probability density',\n",
    "                           name='A',\n",
    "                           opacity=0.3))\n",
    "fig.add_vline(x=p_sample_a, line_dash='dash')\n",
    "fig.add_vline(x=p_exact_a)\n",
    "fig.add_trace(go.Histogram(x=means_b, histnorm='probability density',\n",
    "                           name='B',\n",
    "                           opacity=0.3))\n",
    "fig.add_vline(x=p_sample_b, line_dash='dash')\n",
    "fig.add_vline(x=p_exact_b)\n",
    "fig.update_layout(title='Means Bootstrap Dists',\n",
    "                  xaxis_title='p',\n",
    "                  yaxis_title='Prob Density',\n",
    "                  hovermode=\"x\",\n",
    "                  height=550,\n",
    "                  barmode='overlay')\n",
    "fig.show()\n",
    "\n",
    "print(f'E[A] > E[B]: {np.sum(means_a > means_b) / len(means_a)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_means_comparison_single_experiment(n_points, data_a, data_b):\n",
    "    n = n_points\n",
    "    ka = data_a\n",
    "    kb = data_b\n",
    "    dt_a = np.zeros(n_points)\n",
    "    dt_a[0:k_a] = 1\n",
    "    dt_b = np.zeros(n_points)\n",
    "    dt_b[0:k_b] = 1\n",
    "    n_bs = 1000\n",
    "    bs_a = np.random.choice(dt_a, (n_bs, n))\n",
    "    means_a = bs_a.mean(axis=1)\n",
    "    bs_b = np.random.choice(dt_b, (n_bs, n))\n",
    "    means_b = bs_b.mean(axis=1)\n",
    "    p_ea_gt_eb = np.sum(means_a > means_b) / len(means_a)\n",
    "    res = None\n",
    "    if p_ea_gt_eb >= 0.95:\n",
    "        res = 'A'\n",
    "    elif (1 - p_ea_gt_eb) >= 0.95:\n",
    "        res = 'B'\n",
    "    return res\n",
    "    \n",
    "def bootstrap_means_comparison(n_points, data_a, data_b):\n",
    "    means_cmp = np.empty_like(data_a, dtype=object)\n",
    "    for i, (ka, kb) in enumerate(zip(data_a, data_b)):\n",
    "        means_cmp[i] = bootstrap_means_comparison_single_experiment(n_points, ka, kb)\n",
    "    return means_cmp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вычислительно может быть затратно.  \n",
    "Есть пара трюков для ускорения вычислений.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пуассоновский бутстрап:  \n",
    "https://www.unofficialgoogledatascience.com/2015/08/an-introduction-to-poisson-bootstrap26.html  \n",
    "\n",
    "Сэмплировать из выборки [x1, x2, ..., xn] с повторением все равно, что генерировать набор\n",
    "мультиномиальных коэффициетов x ~ Multinomial(n, 1/n). \n",
    "\n",
    "Для больших n предлагается заменить Multinomial(n, 1/n) на n сэмплов из биномиального распределение Binom(n, 1/n). \n",
    "Количество точек в каждом векторе при этом перестает быть одинаковым.  \n",
    "\n",
    "Еще один шаг - заменить биномиальное распределение Binom(n, 1/n) на распределение Пуассона Poisson(1).  \n",
    "Сэмплировать из него."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Байесовский бутстрап:  \n",
    "https://gdmarmerola.github.io/the-bayesian-bootstrap/ - примеры  \n",
    "https://projecteuclid.org/journalArticle/Download?urlId=10.1214%2Faos%2F1176345338 - оригинальный текст  \n",
    "https://www.sumsar.net/blog/2015/04/the-non-parametric-bootstrap-as-a-bayesian-model/  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Есть данные x_1, ..., x_n.  \n",
    "Сгенерировать (n-1) точку u_1, ..., u_{n-1} из равномерного распределениея U(0,1);\n",
    "Отсортировать их;  \n",
    "Дополнить точками [0, ... , 1]  \n",
    "Посчитать разности g_i = u_i - u_i-1, i>=1.  \n",
    "Использовать g_i как вероятности для [x1, ..., x_n].   \n",
    "Среднее  \n",
    "m = sum g_i x_i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Есть отличия в интерпретации от обычного бутстрапа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ограничения?  \n",
    "Бутстрап несколько хуже работает для непрерывных величин.  \n",
    "При малых размерах исходных данных.  \n",
    "Если часть данных мало представлена (исходное распределение скошено, в выборке мало значений из хвоста).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Метод максимального правдоподобия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предполагается аналитическое распределение для данных - (функция правдоподобия).  \n",
    "Значения параметров выбирается такие, которые будут максимизировать эту функцию при имеющихся данных.  \n",
    "\n",
    "https://en.wikipedia.org/wiki/Maximum_likelihood_estimation#Asymptotics  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для некоторых моделей можно проверси аналитические вычисления.  \n",
    "Для биномиального распределения максимум правдоподобия совпадет со средним в сэмпле.  \n",
    "Для нормального - со средним и дисперсией в сэмле. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В байесовском подходе параметры интерпретируются как случайные величины с распределением.  \n",
    "В методе максимального правдоподобия - считаются неизвестной постоянной величиной.\n",
    "\n",
    "Оценка параметров этим методом совпадет с максимум апостериорного распределения, если априорное распределение равномерное\n",
    "\n",
    "https://en.wikipedia.org/wiki/Maximum_a_posteriori_estimation  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выбрана модель и оценены параметры, дальше можно сравнивать эти распределения.  \n",
    "Если есть возможность посчитать средние по параметрам аналитически, то можно выбрать группу с большим средним.  \n",
    "Метод формально говорит о полной уверенности."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку вместо распределения параметров используется точечная оценка, метод будет давать завышенную уверенность по сравнению со сравнением апостериорных распределений в байесовском подходе.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Доверительные интервалы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проверка статистических гипотез"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для анализа А/Б-тестов иногда используют метод статистических гипотез. \n",
    "Общая идея - предположить, что между группами нет разницы, после чего посчитать, насколько такое предположение объясняет экспериментальные данные. Если вероятность получить данные мала, то считается, что предположение можно отвергнуть, т.е. между группами есть значимая разница.  \n",
    "\n",
    "Для вычисления вероятности получить данные в рамках предположения об эквивалентности групп существует многообразие статистических тестов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Минимальный пример проверки статистической гипотезы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Есть экспериментальные данные $data$.  \n",
    "Есть гипотеза $H$ об этих данных или их свойствах.  \n",
    "Есть случайная величина $Test$, распределение которой $P_{Test|H}(x)$ в предположении $H$ известно.  \n",
    "По фактическим данным считается \"тестовая статистика\"  $x_{fact}$ .   \n",
    "Считаем вероятность получить \"фактическое или более экстремальное\" значение \"тестовой статистики\" $p = P_{Test|H}(x \\ge x_{fact} )$ или $p = P_{Test|H}(x \\le x_{fact} )$ . Т.е. $p = CDF_{Test|H}(x_{fact})$ или $p = 1 - CDF_{Test|H}(x_{fact})$ .  \n",
    "Если вероятность мала, то гипотезу $H$ считают неверной."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример:\n",
    "- данные: в 1000 бросках монетки в 700 случаях выпал орел.  \n",
    "- гипотеза: вероятность выпадения орла 0.5   \n",
    "- случайная величина с известным распределением: вероятность k успехов в N попытках при вероятности $p$ успеха в одной попытке задается биномиальным распределением $Binom(p; N, k)$  \n",
    "- тестовая статистика: число успехов k=700 в общих попытках N=1000\n",
    "- p-значение: вероятность получить 700 или больше успехов в 1000 попытках $\\sum_{i \\ge 700}Binom(0.5; 1000, i)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полезно сравнить с байесовским подходом.  \n",
    "Данные те же.  \n",
    "Случайная величина с известным распределением - функция правдоподобия.  \n",
    "Гипотеза - конкретное значение параметров.  \n",
    "Тестовая статистика - аргумент в функции правдоподобия x_fact = f(data).   \n",
    "p-значение: sum x L(x >= x_fact | H)  \n",
    "Аналога априорного распределения нет.  \n",
    "Иначе устроена интерпретация: в проверке стат. гипотез решение принимают по функции правдоподобия, в байесовском подходе пересчитывают в вероятность.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сложность с интерпретацией $p$-значения.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для оценки параметров проверка статистических гипотез обычно не используется.   \n",
    "Используется метод максимального правдоподобия или другие предположения.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для оценки интервалов параметров используются \"доверительные интервалы\".  \n",
    "Формально неопределенности в параметрах нет.  \n",
    "Сложности с интерпретацией доверительных интервалов:  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все давно сделано:  \n",
    "https://michael-franke.github.io/BDACM_2018/scripts/01_estimation_pValues.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Перестановочный тест:**  \n",
    "https://en.wikipedia.org/wiki/Permutation_test  \n",
    "\n",
    "Есть данные из двух групп.\n",
    "Считаем среднее в каждой группе.\n",
    "Считаем разницу.\n",
    "\n",
    "Далее вопрос: насколько вероятно получить такую разницу если группы одинаковы?\n",
    "\n",
    "Для ответа предполагаем, что группы значения пришли из общего распределения.\n",
    "Из общего распределения сэмплим n_a значений, считаем среднее, потом n_b, также считаем среднее, считаем разницу между средними. \n",
    "Это повторяется по всем возможным комбинациям или пока не надоест. \n",
    "Строится распределение разностей средних.  \n",
    "Определяется, где на этом распределении фактическое значение.  \n",
    "Если оно \"достаточно экстремально\", группы объявляются разными.  \n",
    "\n",
    "К перестановочным тестам применяют механику $p$-значений из проверки статистических гипотез (см. далее).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_mean = 3\n",
    "b_mean = 3.1\n",
    "sigma = 1\n",
    "samp_a = stats.norm.rvs(loc=a_mean, scale=sigma, size=30)\n",
    "samp_b = stats.norm.rvs(loc=b_mean, scale=sigma, size=30)\n",
    "\n",
    "x = np.linspace(0, 5, 1000)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=stats.norm.pdf(x=x, loc=a_mean, scale=sigma)))\n",
    "fig.add_trace(go.Histogram(x=samp_a))\n",
    "fig.add_trace(go.Scatter(x=x, y=stats.norm.pdf(x=x, loc=b_mean, scale=sigma)))\n",
    "fig.add_trace(go.Histogram(x=samp_b))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_info = pd.DataFrame([\n",
    "    {'group':'A', 'a':1, 'b':1, 'sample_size':100},\n",
    "    {'group':'B', 'a':1, 'b':1.25, 'sample_size':100}])\n",
    "exp_info.set_index('group', inplace=True)\n",
    "\n",
    "exact_dist_a = stats.gamma(a=exp_info['a']['A'], scale=1/exp_info['b']['A'])\n",
    "exact_dist_b = stats.gamma(a=exp_info['a']['B'], scale=1/exp_info['b']['B'])\n",
    "exp_info['exact_mean'] = pd.Series({'A': exact_dist_a.mean(), 'B':exact_dist_b.mean()})\n",
    "display(exp_info)\n",
    "\n",
    "samp_a = exact_dist_a.rvs(size=exp_info['sample_size']['A'])\n",
    "samp_b = exact_dist_b.rvs(size=exp_info['sample_size']['B'])\n",
    "\n",
    "x = np.linspace(0, 10, 2000)\n",
    "ymax = np.max([exact_dist_a.pdf(x), exact_dist_b.pdf(x)])\n",
    "\n",
    "fig = go.Figure()\n",
    "col = 'red'\n",
    "fig.add_trace(go.Scatter(x=x, y=exact_dist_a.pdf(x), \n",
    "                         mode='lines', line_color=col,\n",
    "                         name=f\"Exact A: a={exp_info['a']['A']}, b={exp_info['b']['A']}\"))\n",
    "fig.add_trace(go.Histogram(x=samp_a, histnorm='probability density',\n",
    "                           name='Sample A',\n",
    "                           opacity=0.3, marker_color=col))\n",
    "fig.add_trace(go.Scatter(x=[exact_dist_a.mean(), exact_dist_a.mean()], y=[0, ymax], \n",
    "                         mode='lines', line_color=col, line_dash='dash',\n",
    "                         name='Exact Mean A'))\n",
    "col = 'blue'\n",
    "fig.add_trace(go.Scatter(x=x, y=exact_dist_b.pdf(x), \n",
    "                         mode='lines', line_color=col,\n",
    "                         name=f\"Exact B: a={exp_info['a']['B']}, b={exp_info['b']['B']}\"))\n",
    "fig.add_trace(go.Histogram(x=samp_b, histnorm='probability density',\n",
    "                           name='Sample B',\n",
    "                           opacity=0.3, marker_color=col))\n",
    "fig.add_trace(go.Scatter(x=[exact_dist_b.mean(), exact_dist_b.mean()], y=[0, ymax], \n",
    "                         mode='lines', line_color=col, line_dash='dash',\n",
    "                         name='Exact Mean B'))\n",
    "fig.update_layout(title='Exact Distributions and Samples',\n",
    "                  xaxis_title='x',\n",
    "                  yaxis_title='Prob Density',\n",
    "                  hovermode=\"x\",\n",
    "                  height=550,\n",
    "                  barmode='overlay')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled = np.concatenate([samp_a, samp_b])\n",
    "\n",
    "n_resample = 10000\n",
    "means_diff = np.empty(n_resample)\n",
    "\n",
    "for i in range(n_resample):\n",
    "    tmp = np.random.permutation(pooled)\n",
    "    tmp_a = tmp[0:len(samp_a)]\n",
    "    tmp_b = tmp[len(samp_a):]\n",
    "    mean_diff = tmp_a.mean() - tmp_b.mean()\n",
    "    means_diff[i] = mean_diff\n",
    "\n",
    "#means_diff\n",
    "diff_mean_fact = samp_a.mean() - samp_b.mean()\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(x=means_diff, histnorm='probability density',\n",
    "                           name='Means Diff',\n",
    "                           opacity=0.3, marker_color=col))\n",
    "fig.add_vline(x=diff_mean_fact)\n",
    "fig.show()\n",
    "\n",
    "pval = np.sum(means_diff[means_diff > diff_mean_fact]) / len(means_diff)\n",
    "print(pval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Количество правильно угаданных вариантов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Две группы.  \n",
    "Пусть сравниваются конверсии.  \n",
    "Т.е. загадываются параметры двух пуассоновских процессов.  \n",
    "Фиксируется количество наблюдений N.  \n",
    "Для фиксированного количества наблюдений генерируется k пар параметров pa, pb.  \n",
    "Для каждой пары генерируется число успехов ka, kb.  \n",
    "Числа "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_points = np.array([10, 100, 1000, 5000, 10000])\n",
    "n_points = 100\n",
    "k_experiments = 1000\n",
    "\n",
    "pa = np.full(k, 0.1)\n",
    "#https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.uniform.html\n",
    "pb = stats.uniform.rvs(loc=0.9*pa, scale=0.2*pa, size=k) #unif[loc, loc+scale]\n",
    "\n",
    "sa = stats.binom.rvs(n=n_points, p=pa)\n",
    "sb = stats.binom.rvs(n=n_points, p=pb)\n",
    "\n",
    "e = {}\n",
    "e['n_points'] = n_points\n",
    "e['pa_exact'] = pa\n",
    "e['pb_exact'] = pb\n",
    "e['data_a'] = sa\n",
    "e['data_b'] = sb\n",
    "\n",
    "#exact comparison\n",
    "def exact_cmp(pa, pb):\n",
    "    exact_cmp = np.empty_like(pa, dtype=object)\n",
    "    exact_cmp[pa > pb] = 'A'\n",
    "    exact_cmp[pb > pa] = 'B'\n",
    "    return exact_cmp\n",
    "\n",
    "e['exact_cmp'] = exact_cmp(pa, pb)\n",
    "#e['exact_cmp']\n",
    "\n",
    "#means_cmp: a if means_a > means_b else b\n",
    "def means_comparison(n_points, data_a, data_b):\n",
    "    means_cmp = np.empty_like(data_a, dtype=object)\n",
    "    means_cmp[data_a > data_b] = 'A'\n",
    "    means_cmp[data_b > data_a] = 'B'\n",
    "    return means_cmp\n",
    "\n",
    "e['means'] = means_comparison(n_points, sa, sb)\n",
    "#e['means']\n",
    "\n",
    "e['exact_cmp']\n",
    "\n",
    "def method_stat(name, n_points, exact, method):\n",
    "    s = {\n",
    "        'name': name,\n",
    "        'n_points': n_points,\n",
    "        'experiments': len(exact),\n",
    "        'correct': np.sum(exact == method),\n",
    "        'not_sure': len(exact) - np.count_nonzero(method),\n",
    "        'incorrect': np.count_nonzero(e['means']) - np.sum(exact == method)\n",
    "    }\n",
    "    return s\n",
    "\n",
    "e['means_stat'] = method_stat('means', n_points, e['exact_cmp'], e['means'])\n",
    "e['means_stat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "e['bootstrap_means'] = bootstrap_means_comparison(n_points, sa, sb)\n",
    "e['bootstrap_means']\n",
    "\n",
    "e['bootstrap_means_stat'] = method_stat('bootstrap_means', n_points, e['exact_cmp'], e['bootstrap_means'])\n",
    "e['bootstrap_means_stat']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Алгоритм оценки А/Б-тестов на основе проверки статистических гипотез"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Общая идея:\n",
    "\n",
    "Сформулировать нулевую гипотезу.\n",
    "Выбрать уровень стат. значимости и мощности.\n",
    "\n",
    "* Популяция\n",
    "* Распределяем в 2 выборки\n",
    "* Получаем 2 набора данных\n",
    "* Считаем среднее и стандартное отклонение в каждом варианте\n",
    "* считаем стандартную ошибку среднего для каждого варианта\n",
    "* Предполагаем, что среднее по популяции каждого варианта находится вблизи среднего, посчитанного по выборке. \n",
    "* На основании центральной предельной теоремы сумма большого количества значений из одного распределения имеет нормальное распределение; среднее по выборке - сумма большого количества величин из одинакового распределения. На этом основании объявляем, что реальное среднее для каждого из вариантов распределено нормально вокруг среднего из выборки со стандартной ошибкой среднего [как это согласуется с частотной интерпретацей?] \n",
    "* Переходят к распределению для разницы двух величин: средние вычитаются, стандартные отклонения sqrt(s1^2 + s2^2).\n",
    "* считают p-значение. Проверяют, достаточно ли оно мало для объявления стат. значимости.\n",
    "\n",
    "\n",
    "Напоминалка:\n",
    "https://towardsdatascience.com/the-math-behind-a-b-testing-with-example-code-part-1-of-2-7be752e1d06f\n",
    "\n",
    "\n",
    "Вопросы: 2 категории - концептуальные и механика применения.\n",
    "\n",
    "* Как интерпретировать доверительный интервал и стат. значимость?\n",
    "* Как считается мощность? Особенно если распредления не симметричные?\n",
    "* Вариантов больше 2 (групповые поправки)\n",
    "* Подглядывания (и гарантии на значимость и мощность в этом случае)\n",
    "* Оценка размера выборки если дисперсия не связана со средним?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Статистические тесты, доверительные интервалы, проверка статистических гипотез."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Статистические тесты**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Картинки про типы тестов:  \n",
    "https://blog.statsols.com/types-of-statistical-tests  \n",
    "\n",
    "https://duckduckgo.com/?q=how+to+choose+statistical+test&t=ffab&iar=images&iax=images&ia=images  \n",
    "\n",
    "https://www.google.com/search?q=how+to+choose+statistical+test&source=lnms&tbm=isch&sa=X&ved=2ahUKEwip1s-rjuP3AhWIr4sKHY2HCHQQ_AUoAXoECAEQAw&biw=1280&bih=603&dpr=1.5 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Доверительный интервал**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Проверка статистических гипотез**\n",
    "\n",
    "Проверка гипотез: https://en.wikipedia.org/wiki/Statistical_hypothesis_testing \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t-тест и центральная предельная теорема"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Откуда берется t-тест**  \n",
    "\n",
    "См. https://en.wikipedia.org/wiki/Student%27s_t-test и https://en.wikipedia.org/wiki/Student's_t-distribution .  \n",
    "\n",
    "$$\n",
    "\\frac{X - \\mu}{S/\\sqrt{n}}\n",
    "$$\n",
    "X - sample mean, S - Bessel-corrected sample variance.\n",
    "\n",
    "При больших N t-распределение почти совпадает с нормальным."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t-критерий:\n",
    "\n",
    "$P(\\frac{X - \\mu}{S/\\sqrt{n}} | \\mu, \\sigma) = t(...)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Центральная предельная теорема**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"central_limit_theorem_and_t_test.png\" alt=\"central_limit_theorem_and_t_test\" width=\"600\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Используемые предположения**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какой вариант лучше?**\n",
    "\n",
    "Нужно $P(p_A > p_B)$.\n",
    "\n",
    "Статистическая гипотеза: $p_A = p_B$.  \n",
    "p-значение: $P(data | p_A = p_B) = p$\n",
    "\n",
    "Дальше обычно говорят, что если $p$ мало, то $p_A \\ne p_B$.\n",
    "\n",
    "Как связано p-значение с нужной вероятностью $P(p_A > p_B)$?\n",
    "\n",
    "Сложности:  \n",
    "Из того, что $P(data | p_A = p_B)$ мало не следует, что $p_A \\ne p_B$.  \n",
    "Чтобы перейти от $P(data | p_A = p_B)$ к $P(p_A = p_B | data)$ нужно соотношение Байеса.  \n",
    "Но дальше все равно непонятно, как $P(p_A = p_B | data)$ соотносится с $P(p_A > p_B)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Каковы оценки метрики в каждой группе?**\n",
    "\n",
    "Нужны оценки плотности вероятности P(p_A), P(p_B).\n",
    "\n",
    "Есть средние в выборках.  \n",
    "\n",
    "Для оценки неопределенности предлагается считать доверительные интервалы.  \n",
    "Считаются в предположении, что выполняется центральная предельная теорема.  \n",
    "$$\n",
    "P(p_A) = N(p_{A, mean}, \\sigma_A)\n",
    "\\\\\n",
    "P(p_B) = N(p_{B, mean}, \\sigma_B)\n",
    "$$\n",
    "Доверительные интервалы дают оценки:  \n",
    "$$\n",
    "P(p_A \\in [p_{A, mean} - 2\\sigma_A, p_{A, mean} + 2\\sigma_A]) = \\alpha\n",
    "\\\\\n",
    "P(p_B \\in [p_{B, mean} - 2\\sigma_B, p_{B, mean} + 2\\sigma_B]) = \\alpha\n",
    "$$\n",
    "\n",
    "\n",
    "Кажется, что такие оценки занижают неопределенность.  \n",
    "Не обязательно, что среднее равно именно среднему в выборке, может быть в окрестностях.  \n",
    "\n",
    "Нужно смотреть модель\n",
    "\n",
    "$$\n",
    "P(mu, sigma | data) \\\\\n",
    "P(data | mu, sigma) = N(mu, sigma) \\\\\n",
    "mu - \\mbox{нормальное распределение вокруг среднего значения в выборке} \\\\\n",
    "sigma - \\mbox{широкое нормальное распределение с центром на стандартной ошибке среднего для выборки}\n",
    "$$\n",
    "\n",
    "Или сравнить с бета-распределением.\n",
    "\n",
    "Можно проверить, посэмлировав распределение.   \n",
    "Если нормальное приближение делает завышенную по уверенности оценку, то при повторном применении этого приближения\n",
    "не получится заявленная вероятность попадания среднего в доверительный интервал.\n",
    "\n",
    "Фиксируется p.  \n",
    "Сэмплируется.  \n",
    "Считается N(mu, sigma).  \n",
    "Проверяется попадание попадание p в определенный доверительный интервал.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нормальное или t-распределение можно рассматривать как оценку распределения P(mu | data).  \n",
    "При этом приходится отказаться от претензий на установление реального среднего.  \n",
    "И иметь дело с теми же проблемами, что и для любых других моделей - насколько адекватны предположения,\n",
    "насколько адекватны прогнозы.  \n",
    "Одна из проблем - распределение не ограничено интервалом [0,1] и есть ненулевая плотность вероятности за границами области."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t-критерий:\n",
    "\n",
    "$P(\\frac{X - \\mu}{S/\\sqrt{n}} | \\mu, \\sigma) = t(...)$\n",
    "\n",
    "Нужно\n",
    "\n",
    "$P(\\mu, \\sigma | X)$\n",
    "\n",
    "Скорее всего можно предположить фиксированное $\\sigma$.\n",
    "\n",
    "Дальше\n",
    "\n",
    "$$\n",
    "P(\\mu, \\sigma | X) = \\frac{P(X| \\mu, \\sigma) P(\\mu, \\sigma)}{\\int d\\mu P(X| \\mu, \\sigma) P(\\mu, \\sigma)}\n",
    "$$\n",
    "\n",
    "Если приближенно считать функцию правдоподобия нормальной,\n",
    "можно задать сопряженное априорное распределение.  \n",
    "https://en.wikipedia.org/wiki/Conjugate_prior#Continuous_distributions  \n",
    "Сопряженное априорное также нормальное.  \n",
    "Только не очень понятно, как выбирать параметры -- чтобы не на основе сэмпла."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "prior_conv = 0.3\n",
    "\n",
    "a_total = 100\n",
    "a_conv = a_total * prior_conv\n",
    "\n",
    "#x = np.linspace(0, 1, 1001)\n",
    "x = np.linspace(0, a_total, 10000)\n",
    "fig = go.Figure()\n",
    "\n",
    "# Norm\n",
    "mu = a_conv\n",
    "var = a_total * prior_conv * (1 - prior_conv)\n",
    "sigma = np.sqrt(var)\n",
    "stderrmean = sigma / np.sqrt(a_total)\n",
    "print(mu, stderrmean)\n",
    "\n",
    "fig.add_trace(go.Scatter(x=x, y=stats.norm.pdf(x, loc=mu, scale=stderrmean), mode='lines',\n",
    "                         name=f\"<br>total = {a_total}, conv = {a_conv}<br>mu={mu}, stderrmean={stderrmean}\"))\n",
    "\n",
    "\n",
    "#Uniform prior\n",
    "# beta_prior = 1\n",
    "# alpha_prior = 1\n",
    "\n",
    "# alpha_post = alpha_prior + a_conv\n",
    "# beta_post = beta_prior + (a_total - a_conv)\n",
    "# fig.add_trace(go.Scatter(x=x, y=stats.beta.pdf(x, alpha_post, beta_post), mode='lines',\n",
    "#                          name=f\"<br>A: total = {a_total}, conv = {a_conv}<br>alpha_prior={alpha_prior}, beta_prior={beta_prior},<br>alpha_post={alpha_post}, beta_post={beta_post}\"))\n",
    "\n",
    "\n",
    "\n",
    "fig.update_layout(title='Posterior and Prior Distributions',\n",
    "                  xaxis_title='p',\n",
    "                  yaxis_title='Prob Density',\n",
    "                  hovermode=\"x\",\n",
    "                  height=550)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "prior_conv = 0.4\n",
    "\n",
    "a_total = 10\n",
    "a_conv = a_total * prior_conv\n",
    "\n",
    "x = np.linspace(0, 1, 1001)\n",
    "fig = go.Figure()\n",
    "\n",
    "# Norm\n",
    "## mu = 1 * a_conv + 0 * (a_total - a_conv)\n",
    "## mu_c = 1 * (a_conv / a_total) + 0 * (a_total - a_conv) / a_total = a_conv / a_total\n",
    "## std_c = sqrt( ( (1 - mu_c)^2 * a_conv + (0 - mu_c)^2 * (a_total - a_conv) ) / a_total )\n",
    "##       = sqrt( (1 - mu_c)^2 mu_c + mu_c^2 (1 - mu_c) )\n",
    "##       = sqrt( mu_c (1 - mu_c) )\n",
    "\n",
    "mu_c = a_conv / a_total\n",
    "sigma_c = np.sqrt(mu_c * (1 - mu_c))\n",
    "stderrmean_c = sigma_c / np.sqrt(a_total)\n",
    "print(mu_c, stderrmean_c)\n",
    "\n",
    "fig.add_trace(go.Scatter(x=x, y=stats.norm.pdf(x, loc=mu_c, scale=stderrmean_c), mode='lines',\n",
    "                         name=f\"<br>total = {a_total}, conv = {a_conv}<br>mu={mu}, stderrmean={stderrmean}\"))\n",
    "\n",
    "\n",
    "#Uniform prior\n",
    "beta_prior = 1\n",
    "alpha_prior = 1\n",
    "\n",
    "alpha_post = alpha_prior + a_conv\n",
    "beta_post = beta_prior + (a_total - a_conv)\n",
    "fig.add_trace(go.Scatter(x=x, y=stats.beta.pdf(x, alpha_post, beta_post), mode='lines',\n",
    "                         name=f\"<br>A: total = {a_total}, conv = {a_conv}<br>alpha_prior={alpha_prior}, beta_prior={beta_prior},<br>alpha_post={alpha_post}, beta_post={beta_post}\"))\n",
    "\n",
    "\n",
    "\n",
    "fig.update_layout(title='Posterior and Prior Distributions',\n",
    "                  xaxis_title='p',\n",
    "                  yaxis_title='Prob Density',\n",
    "                  hovermode=\"x\",\n",
    "                  height=550)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Насколько один вариант лучше другого?**\n",
    "\n",
    "Нужно $P(p_A/p_B)$ или $P(p_A - p_B)$.  \n",
    "Распределение $P(p_A/p_B)$ обычно не считают - ограничиваются отношением средних в выборках $p_A/p_B$.  \n",
    "\n",
    "Cчитают $P(p_A - p_B)$.  \n",
    "С учетом предположений о нормальном распределении $p_A, p_B$\n",
    "$$\n",
    "P(p_A - p_B) = N(p_A - p_B; s_{AB}) \n",
    "\\\\\n",
    "s_{AB} = \\sqrt{s_A^2 / N_1 + s_B^2 / N_2} * \\sqrt{N_1 + N_2} \\quad \\mbox{(или что-то вроде)}\n",
    "$$\n",
    "(См. https://mathworld.wolfram.com/NormalDifferenceDistribution.html, https://math.stackexchange.com/questions/917276/distribution-of-the-difference-of-two-normal-random-variables, https://en.wikipedia.org/wiki/Sum_of_normally_distributed_random_variables, https://en.wikipedia.org/wiki/Normal_distribution#Operations_on_normal_deviates)\n",
    "\n",
    "При этом предположения о нормальном распределении $p_A, p_B$ излишне оптимистичны.  \n",
    "Поэтому оценка разности также будет занижена.  \n",
    "\n",
    "Можно попробовать проверить сэмплированием."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "prior_conv = 0.4\n",
    "\n",
    "a_total = 1000\n",
    "a_conv = a_total * prior_conv\n",
    "\n",
    "b_total = 1000\n",
    "b_conv = b_total * prior_conv * 1.1\n",
    "\n",
    "x = np.linspace(-1, 1, 1001)\n",
    "fig = go.Figure()\n",
    "\n",
    "# Norm\n",
    "mu_a = a_conv / a_total \n",
    "stderrmean_a = np.sqrt(mu_a * (1 - mu_a)) / np.sqrt(a_total)\n",
    "print(mu_a, stderrmean_a)\n",
    "\n",
    "mu_b = b_conv / b_total \n",
    "stderrmean_b = np.sqrt(mu_b * (1 - mu_b)) / np.sqrt(b_total)\n",
    "print(mu_b, stderrmean_b)\n",
    "\n",
    "mu_diff = mu_b - mu_a\n",
    "stderrmean_diff = np.sqrt(stderrmean_a**2 + stderrmean_b**2)\n",
    "print(mu_diff, stderrmean_diff)\n",
    "\n",
    "fig.add_trace(go.Scatter(x=x, y=stats.norm.pdf(x, loc=mu_diff, scale=stderrmean_diff), mode='lines',\n",
    "                         name=f\"Normal Diff\"))\n",
    "\n",
    "\n",
    "#Beta\n",
    "beta_prior = 1\n",
    "alpha_prior = 1\n",
    "alpha_post_a = alpha_prior + a_conv\n",
    "beta_post_a = beta_prior + (a_total - a_conv)\n",
    "n_post_sample = 50000\n",
    "post_sample_a = np.random.beta(alpha_post_a, beta_post_a, n_post_sample)\n",
    "alpha_post_b = alpha_prior + b_conv\n",
    "beta_post_b = beta_prior + (b_total - b_conv)\n",
    "post_sample_b = np.random.beta(alpha_post_b, beta_post_b, n_post_sample)\n",
    "post_sample_diff = post_sample_b - post_sample_a\n",
    "\n",
    "\n",
    "fig.add_trace(go.Histogram(x=post_sample_diff, histnorm='probability density', \n",
    "                           name='B-A', marker_color='red',\n",
    "                           opacity=0.6))\n",
    "\n",
    "\n",
    "fig.update_layout(title='P(B-A)',\n",
    "                  xaxis_title='p',\n",
    "                  yaxis_title='Prob Density',\n",
    "                  hovermode=\"x\",\n",
    "                  height=550)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какой вариант лучше?**\n",
    "\n",
    "Нужно $P(p_A > p_B)$.\n",
    "\n",
    "Обычно пытаются проверять статистические гипотезы.  \n",
    "Предполагают $p_A = p_B$ и считают, какова вероятность получить имеющиеся средние: $P(p_{mu,A}, p_{mu,B} | p_A = p_B)$.\n",
    "\n",
    "Для t-тестов вместо статистических гипотез можно посчитать понятное значение $P(p_B > p_A)$ с помощью\n",
    "кумулятивной функции распределения нормального распределения.\n",
    "\n",
    "$$\n",
    "P(p_A > p_B) = \\mbox{norm.diff.cdf(x=0)}\n",
    "\\\\\n",
    "P(p_B > p_A) = 1 - \\mbox{norm.diff.cdf(x=0)}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-0.5, 0.5, 1001)\n",
    "fig = go.Figure()\n",
    "# fig.add_trace(go.Scatter(x=x, y=stats.norm.pdf(x, loc=mu_diff, scale=stderrmean_diff), mode='lines',\n",
    "#                          name=f\"Normal Diff\"))\n",
    "fig.add_trace(go.Scatter(x=x, y=stats.norm.cdf(x, loc=mu_diff, scale=stderrmean_diff), mode='lines',\n",
    "                         name=f\"Normal Diff Accumulated\"))\n",
    "fig.update_layout(title='P(B-A) Accumulated',\n",
    "                  xaxis_title='p',\n",
    "                  yaxis_title='Prob Density',\n",
    "                  hovermode=\"x\",\n",
    "                  xaxis_range=[-0.1, 0.1],\n",
    "                  height=550)\n",
    "\n",
    "fig.show()\n",
    "\n",
    "\n",
    "pa_gt_pb_norm = stats.norm.cdf(x=0, loc=mu_diff, scale=stderrmean_diff)\n",
    "pb_gt_pa_norm = 1 - pa_gt_pb_norm\n",
    "print(f\"P(pa > pb) = {pa_gt_pb_norm}, P(pb > pa) = {pb_gt_pa_norm}\")\n",
    "\n",
    "#diff = B - A\n",
    "pb_gt_pa_diff = len(post_sample_diff[post_sample_diff > 0]) / len(post_sample_diff)\n",
    "pa_gt_pb_diff = 1 - pb_gt_pa_diff\n",
    "print(f\"P(pa > pb) = {pa_gt_pb_diff}, P(pb > pa) = {pb_gt_pa_diff}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Проверка статистической гипотезы $p_A = p_B$**\n",
    "\n",
    "Во-первых, вопрос о $p_A = p_B$ - это не тот вопрос, на который нужно отвечать.  \n",
    "Нужно $P(p_A > p_B)$ -- см. выше.  \n",
    "\n",
    "Во-вторых, способ проверки гипотезы вызывает вопросы.  \n",
    "Предполагают $p_A = p_B$ и считают, какова вероятность получить имеющиеся средние: $P(p_{mu,A}, p_{mu,B} | p_A = p_B)$.\n",
    "\n",
    "Выбирают уровень значимости $\\alpha$.  \n",
    "Обычно $\\alpha = 0.95$.  \n",
    "Находят симметричный относительно центра интервал, внутри которого лежит $\\alpha$ плотности вероятности.  \n",
    "Для $\\alpha = 0.95$ это [mu_diff - 2 s_diff, mu_diff + 2 s_diff].  \n",
    "По распределению разности проверяют, лежит ли точка 0 в интервале [mu_diff - 2 s_diff, mu_diff + 2 s_diff].  \n",
    "Если попадает, то гипотеза не отвергается.  \n",
    "Если не попадает, то отвергается.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Сколько должен продолжаться эксперимент?**  \n",
    "\n",
    "Для конверсий дисперсия связана со средним.  \n",
    "Можно задаться величиной эффекта.  \n",
    "Оценить, как будут выглядеть распределения средних.  \n",
    "На этом основании оценить, сколько нужно наблюдений для детектирования эффекта с определенной вероятностью.  \n",
    "\n",
    "\n",
    "Если дисперсия заранее неизвестна, то возникают проблемы с оценкой длительности.  \n",
    "Не ясно, чему равна стандартная ошибка среднего.\n",
    "\n",
    "\n",
    "Еще есть проблема подглядывания.  \n",
    "Оценку длительности предлагается фиксировать до начала эксперимента.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Как работают оценки длительности?**\n",
    "\n",
    "Один из калькуляторов: https://www.evanmiller.org/ab-testing/sample-size.html .\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "prior_conv = 0.4\n",
    "\n",
    "a_total = 1000\n",
    "a_conv = a_total * prior_conv\n",
    "\n",
    "b_total = a_total\n",
    "b_conv = b_total * prior_conv * 1.05\n",
    "\n",
    "x = np.linspace(0, 1, 1001)\n",
    "fig = go.Figure()\n",
    "\n",
    "# Norm\n",
    "## mu = 1 * a_conv + 0 * (a_total - a_conv)\n",
    "## mu_c = 1 * (a_conv / a_total) + 0 * (a_total - a_conv) / a_total = a_conv / a_total\n",
    "## std_c = sqrt( ( (1 - mu_c)^2 * a_conv + (0 - mu_c)^2 * (a_total - a_conv) ) / a_total )\n",
    "##       = sqrt( (1 - mu_c)^2 mu_c + mu_c^2 (1 - mu_c) )\n",
    "##       = sqrt( mu_c (1 - mu_c) )\n",
    "\n",
    "mu_ca = a_conv / a_total\n",
    "sigma_ca = np.sqrt(mu_ca * (1 - mu_ca))\n",
    "stderrmean_ca = sigma_ca / np.sqrt(a_total)\n",
    "print(mu_ca, stderrmean_ca)\n",
    "\n",
    "fig.add_trace(go.Scatter(x=x, y=stats.norm.pdf(x, loc=mu_ca, scale=stderrmean_ca), mode='lines',\n",
    "                         name=f\"<br>total = {a_total}, conv = {a_conv}<br>mu={mu_ca}, stderrmean={stderrmean_ca}\"))\n",
    "\n",
    "mu_cb = b_conv / b_total\n",
    "sigma_cb = np.sqrt(mu_cb * (1 - mu_cb))\n",
    "stderrmean_cb = sigma_cb / np.sqrt(b_total)\n",
    "print(mu_cb, stderrmean_cb)\n",
    "\n",
    "fig.add_trace(go.Scatter(x=x, y=stats.norm.pdf(x, loc=mu_cb, scale=stderrmean_cb), mode='lines',\n",
    "                         name=f\"<br>total = {b_total}, conv = {b_conv}<br>mu={mu_cb}, stderrmean={stderrmean_cb}\"))\n",
    "\n",
    "fig.add_vline(x=mu_cb)\n",
    "\n",
    "fig.update_layout(title='Posterior and Prior Distributions',\n",
    "                  xaxis_title='p',\n",
    "                  yaxis_title='Prob Density',\n",
    "                  hovermode=\"x\",\n",
    "                  height=550)\n",
    "\n",
    "fig.show()\n",
    "\n",
    "pval = 1 - stats.norm.cdf(x=mu_cb, loc=mu_ca, scale=stderrmean_ca)\n",
    "print(pval)\n",
    "\n",
    "\n",
    "def pval(prior_conv, exp_effect, N):\n",
    "    a_total = N\n",
    "    a_conv = a_total * prior_conv\n",
    "    b_total = a_total\n",
    "    b_conv = b_total * prior_conv * exp_effect\n",
    "    mu_ca = a_conv / a_total\n",
    "    sigma_ca = np.sqrt(mu_ca * (1 - mu_ca))\n",
    "    stderrmean_ca = sigma_ca / np.sqrt(a_total)\n",
    "    mu_cb = b_conv / b_total\n",
    "    pval = 1 - stats.norm.cdf(x=mu_cb, loc=mu_ca, scale=stderrmean_ca)\n",
    "    return pval\n",
    "\n",
    "\n",
    "N = np.linspace(100, 10000)\n",
    "y = np.array([pval(prior_conv, 1.05, Ni) for Ni in N])\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=N, y=y, mode='lines'))\n",
    "fig.add_hline(y=0.05)\n",
    "fig.update_layout(title='p-val',\n",
    "                  xaxis_title='N',\n",
    "                  yaxis_title='p-val',\n",
    "                  hovermode=\"x\",\n",
    "                  height=550)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "prior_conv = 0.4\n",
    "\n",
    "a_total = 100\n",
    "a_conv = a_total * prior_conv\n",
    "\n",
    "b_total = 100\n",
    "b_conv = b_total * prior_conv * 1.1\n",
    "\n",
    "x = np.linspace(-1, 1, 1001)\n",
    "fig = go.Figure()\n",
    "\n",
    "# Norm\n",
    "mu_a = a_conv / a_total \n",
    "stderrmean_a = np.sqrt(mu_a * (1 - mu_a)) / np.sqrt(a_total)\n",
    "print(mu_a, stderrmean_a)\n",
    "\n",
    "mu_b = b_conv / b_total \n",
    "stderrmean_b = np.sqrt(mu_b * (1 - mu_b)) / np.sqrt(b_total)\n",
    "print(mu_b, stderrmean_b)\n",
    "\n",
    "mu_diff = mu_b - mu_a\n",
    "stderrmean_diff = np.sqrt(stderrmean_a**2 + stderrmean_b**2)\n",
    "print(mu_diff, stderrmean_diff)\n",
    "\n",
    "fig.add_trace(go.Scatter(x=x, y=stats.norm.pdf(x, loc=mu_diff, scale=stderrmean_diff), mode='lines',\n",
    "                         name=f\"100\"))\n",
    "\n",
    "\n",
    "a_total = 500\n",
    "a_conv = a_total * prior_conv\n",
    "\n",
    "b_total = 500\n",
    "b_conv = b_total * prior_conv * 1.1\n",
    "\n",
    "# Norm\n",
    "mu_a = a_conv / a_total \n",
    "stderrmean_a = np.sqrt(mu_a * (1 - mu_a)) / np.sqrt(a_total)\n",
    "print(mu_a, stderrmean_a)\n",
    "\n",
    "mu_b = b_conv / b_total \n",
    "stderrmean_b = np.sqrt(mu_b * (1 - mu_b)) / np.sqrt(b_total)\n",
    "print(mu_b, stderrmean_b)\n",
    "\n",
    "mu_diff = mu_b - mu_a\n",
    "stderrmean_diff = np.sqrt(stderrmean_a**2 + stderrmean_b**2)\n",
    "print(mu_diff, stderrmean_diff)\n",
    "\n",
    "fig.add_trace(go.Scatter(x=x, y=stats.norm.pdf(x, loc=mu_diff, scale=stderrmean_diff), mode='lines',\n",
    "                         name=f\"{a_total}\"))\n",
    "fig.add_vline(x=0)\n",
    "fig.update_layout(title='P(B-A)',\n",
    "                  xaxis_title='p',\n",
    "                  yaxis_title='Prob Density',\n",
    "                  hovermode=\"x\",\n",
    "                  height=550)\n",
    "\n",
    "fig.show()\n",
    "\n",
    "\n",
    "def pval(prior_conv, exp_effect, N):\n",
    "    a_total = N\n",
    "    a_conv = a_total * prior_conv\n",
    "    b_total = a_total\n",
    "    b_conv = b_total * prior_conv * exp_effect\n",
    "    mu_a = a_conv / a_total \n",
    "    stderrmean_a = np.sqrt(mu_a * (1 - mu_a)) / np.sqrt(a_total)\n",
    "    mu_b = b_conv / b_total \n",
    "    stderrmean_b = np.sqrt(mu_b * (1 - mu_b)) / np.sqrt(b_total)\n",
    "    mu_diff = mu_b - mu_a\n",
    "    stderrmean_diff = np.sqrt(stderrmean_a**2 + stderrmean_b**2)\n",
    "    if mu_diff > 0:\n",
    "        pval = stats.norm.cdf(x=0, loc=mu_diff, scale=stderrmean_diff)\n",
    "    else:\n",
    "        pval = None\n",
    "    return pval\n",
    "\n",
    "N = np.linspace(100, 10000)\n",
    "y = np.array([pval(prior_conv, 1.05, Ni) for Ni in N])\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=N, y=y, mode='lines'))\n",
    "fig.add_hline(y=0.05)\n",
    "fig.update_layout(title='p-val',\n",
    "                  xaxis_title='N',\n",
    "                  yaxis_title='p-val',\n",
    "                  hovermode=\"x\",\n",
    "                  height=550)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ссылки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотреть:\n",
    "\n",
    "J. Kruschke  \n",
    "https://www.medicine.mcgill.ca/epidemiology/Joseph/courses/EPIB-682/Kruschke2013.pdf  \n",
    "https://www.youtube.com/watch?v=fhw1j1Ru2i0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
