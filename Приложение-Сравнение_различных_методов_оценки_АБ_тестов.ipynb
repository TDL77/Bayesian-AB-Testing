{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Приложение: сравнение различных методов оценки А/Б-тестов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Приведен обзор методов для анализа А/Б-тестов*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [Введение](#Введение)\n",
    "* [Оценки среднего и дисперсии на основе сэмпла](#Оценки-среднего-и-дисперсии-на-основе-сэмпла)\n",
    "* [Бутстрап](#Бутстрап)\n",
    "* [Метод максимального правдоподобия](#Метод-максимального-правдоподобия)\n",
    "* Проверка статистических гипотез\n",
    "* [Байесовское моделирование](#Байесовское-моделирование)\n",
    "* [Количество правильно угаданных вариантов](#Количество-правильно-угаданных-вариантов)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Введение"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В ч.1 обсуждался байесовским подход к оценке А/Б-тестов.  \n",
    "Было показано, как в рамках этого подхода ответить на вопросы\n",
    "- Какой вариант лучше и насколько?\n",
    "- Каковы оценки целевой метрики в каждом варианте?\n",
    "- Насколько уверены в оценке?\n",
    "- Сколько должен продолжаться эксперимент?\n",
    "\n",
    "Полезно сравнить байесовское моделирование с другими подходами.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Сравнение средних в сэмплах"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Закон больших чисел  \n",
    "https://en.wikipedia.org/wiki/Law_of_large_numbers  \n",
    "\n",
    "Среднее в сэмпле - состоятельная и несмещенная оценка среднего в распределении  \n",
    "https://en.wikipedia.org/wiki/Estimator\n",
    "\n",
    "Среднее в выборке сходится к среднему в распределении."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(7)\n",
    "\n",
    "import scipy.stats as stats\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "#todo: update scipy; make venv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_a_exact = 0.7\n",
    "p_b_exact = 0.6\n",
    "\n",
    "n = np.arange(10, 5000, 100)\n",
    "k_a = stats.binom.rvs(n, p_a_exact)\n",
    "k_b = stats.binom.rvs(n, p_b_exact)\n",
    "p_a_samp = k_a/n\n",
    "p_b_samp = k_b/n\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=n, y=p_a_samp, name='A: p sample'))\n",
    "fig.add_trace(go.Scatter(x=[0, np.max(n)], y=[p_a_exact, p_a_exact],\n",
    "                         mode='lines',\n",
    "                         line_dash='dash', line_color='black', name='A: p exact'))\n",
    "fig.add_trace(go.Scatter(x=n, y=p_b_samp, name='B: p sample'))\n",
    "fig.add_trace(go.Scatter(x=[0, np.max(n)], y=[p_b_exact, p_b_exact],\n",
    "                         mode='lines',\n",
    "                         line_dash='dash', line_color='black', name='B: p exact'))\n",
    "fig.update_layout(\n",
    "    title='Exact and Sample Means for Binomial Distribution',\n",
    "    xaxis_title='Sample Size',\n",
    "    yaxis_title='p',\n",
    "    yaxis_range=[0, 1],\n",
    "    xaxis_range=[0, np.max(n)],\n",
    "    height=550\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Позволяет получить точечные оценки.  \n",
    "Можно выбрать группу с большим средним.  \n",
    "Но остается вопрос, с какой вероятностью одна группа лучше другой.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_groups_binomial(sa, na, sb, nb):\n",
    "    pa = sa / na\n",
    "    pb = sb / nb\n",
    "    if pa > pb:\n",
    "        res = 'A'\n",
    "    elif pa < pb:\n",
    "        res = 'B'\n",
    "    else:\n",
    "        res = None\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_a_exact = 0.7\n",
    "p_b_exact = 0.75\n",
    "\n",
    "n = 1000\n",
    "sa = stats.binom.rvs(n, p_a_exact)\n",
    "sb = stats.binom.rvs(n, p_b_exact)\n",
    "\n",
    "print(f'pa_exact={p_a_exact}, pb_exact={p_b_exact}')\n",
    "print(f'n={n}, sa={sa}, sb={sb}')\n",
    "print(f'Exact best group: {\"A\" if p_a_exact > p_b_exact else \"B\" if p_b_exact > p_a_exact else None}')\n",
    "print(f'Group selected by means comparison: {compare_groups_binomial(sa, n, sb, n)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "|Метод |Оценки целевой метрики | Какая группа лучше | Насколько лучше | Сколько продолжать эксперимент|  \n",
    "|----|---|---|----|----|\n",
    "|Сравнение средних| |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_methods = pd.DataFrame(columns=[\n",
    "    'Метод', \n",
    "    'Оценки целевой метрики', \n",
    "    'Критерий выбора группы', \n",
    "    'Оценка длительности'\n",
    "])\n",
    "df_methods = pd.concat([df_methods, pd.DataFrame([{\n",
    "    'Метод': 'Сравнение средних', \n",
    "    'Оценки целевой метрики': 'Точечные оценки средних', \n",
    "    'Критерий выбора группы': 'Где \"лучше\" среднее', \n",
    "    'Оценка длительности': 'Не рассчитывается; можно договориться о \"достаточно большой\" выборке'\n",
    "}])], ignore_index=True)\n",
    "df_methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Стандартная ошибка среднего и интервал с помощью неравенства Чебышева"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Посчитать средние и дисперсии в каждой группе\n",
    "* Посчитать стандартные ошибки средних\n",
    "* С помощью неравенства Чебышева оценить интервал возможных значений\n",
    "* Построить разность средних и дисперсию разности средних\n",
    "* Посчитать, с какой вероятностью можно получить 0 или более экстремальное значение."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно построить стандартную ошибку среднего.   \n",
    "https://en.wikipedia.org/wiki/Standard_error#Derivation\n",
    "\n",
    "$$\n",
    "D[{\\bar{x}}] = \\frac{\\sigma^2}{n}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Оценку дисперсии также можно построить по сэмлу.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С помощью неравенства Чебышева можно оценить вероятность отклонения случайной величины от среднего.\n",
    "Часто используют для оценки отклонения на несколько стандартных отклонений.    \n",
    "https://en.wikipedia.org/wiki/Chebyshev%27s_inequality\n",
    "\n",
    "$$\n",
    "P(|X - \\mu| \\ge k \\sigma) \\le \\frac{1}{k^2}\n",
    "$$\n",
    "\n",
    "При $k=5$\n",
    "\n",
    "$$\n",
    "P(|X - \\mu| \\ge 5 \\sigma) \\le \\frac{1}{25} = 0.04\n",
    "$$\n",
    "\n",
    "Одностороннее неравенство Чебышева:  \n",
    "https://en.wikipedia.org/wiki/Chebyshev%27s_inequality#Cantelli's_inequality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для дисперсии нужны поправки к значению в сэмпле чтобы получить несмещенную оценку  \n",
    "https://en.wikipedia.org/wiki/Unbiased_estimation_of_standard_deviation  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Среднее разности случайных величин:  \n",
    "https://en.wikipedia.org/wiki/Expected_value#Properties\n",
    "\n",
    "$$\n",
    "E[X - Y] = E[X] - E[Y]\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Дисперсия разности случайных величин:  \n",
    "https://en.wikipedia.org/wiki/Standard_deviation#Identities_and_mathematical_properties  \n",
    "https://en.wikipedia.org/wiki/Covariance\n",
    "\n",
    "$$\n",
    "D[X - Y] = D[X] + D[Y] - 2cov[X,Y]\n",
    "$$\n",
    "\n",
    "Формально величины X и Y ожидаются независимыми.  \n",
    "Если отключить одну группу, на другую это не повлияет.  \n",
    "Для независимых величин $cov[X,Y] = 0$.  \n",
    "\n",
    "На практике можно оставить это слагаемое."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(для конверсий $\\tilde{p}_A$ похоже на биномиальное распределение, но отнесенное к n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "A = [1, 0, 1, 0, 0, ... , 1]\n",
    "\\\\\n",
    "s_A, n_A\n",
    "\\\\\n",
    "E_A \\equiv p_A = s_A / n_A\n",
    "\\\\\n",
    "D_A = p_A (1 - p_A)\n",
    "\\\\\n",
    "\\tilde{p}_A = \\frac{1}{n} \\left( \\tilde{A} + \\tilde{A} + \\dots + \\tilde{A} \\right)\n",
    "\\\\\n",
    "E[\\tilde{p}_A] = E_A = p_A\n",
    "\\\\\n",
    "D[\\tilde{p}_A] = \\frac{D_A}{n_A}\n",
    "\\\\\n",
    "\\Delta = \\tilde{p}_A - \\tilde{p}_B\n",
    "\\\\\n",
    "E_{\\Delta} = E[\\tilde{p}_A - \\tilde{p}_B] = E[\\tilde{p}_A] - E[\\tilde{p}_B] = p_A - p_B\n",
    "\\\\\n",
    "D_{\\Delta} = D[\\tilde{p}_A - \\tilde{p}_B] = D[\\tilde{p}_A] + D[\\tilde{p}_B]\n",
    "\\\\\n",
    "\\sigma_{\\Delta} = \\sqrt{D[p_A] + D[p_B]}\n",
    "\\\\\n",
    "P(|0 - E_{\\Delta}| \\ge k \\sigma_{\\Delta}) \\le \\frac{1}{k^2}\n",
    "\\\\\n",
    "P \\left( \\frac{|E_{\\Delta}|}{\\sigma_{\\Delta}} \\ge k \\right) \\le \\frac{1}{k^2}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "вопрос интерпретации вероятности.  \n",
    "и доверительных интервалов вокруг средних значений.  \n",
    "вводится новая случайная величина - сумма N наблюдений.  \n",
    "делаются утверждения о ее распределении.  \n",
    "как это соотносится с исходными вопросами?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Стоит обратить внимание, что приведенные методы не делают предположений о форме распределений тестируемых величин. Единственное, что требуется - существование конечных средних и дисперсий. Чаще всего эти предположения можно считать выполненными. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def std_err_mean_binom(s, n):\n",
    "    p = s / n\n",
    "    return np.sqrt(p * (1 - p) / n)\n",
    "\n",
    "def compare_groups_binomial(sa, na, sb, nb):\n",
    "    pa = sa / na\n",
    "    pb = sb / nb\n",
    "    std_err_mean_a = std_err_mean_binom(sa, na)\n",
    "    std_err_mean_b = std_err_mean_binom(sb, nb)\n",
    "    mean_diff = pb - pa\n",
    "    std_err_mean_diff = np.sqrt(std_err_mean_a**2 + std_err_mean_b**2)\n",
    "    k = np.abs(mean_diff) / std_err_mean_diff\n",
    "    if pa > pb and k >= 5:\n",
    "        res = 'A'\n",
    "    elif pa < pb and k >= 5:\n",
    "        res = 'B'\n",
    "    else:\n",
    "        res = None\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_a_exact = 0.7\n",
    "p_b_exact = 0.75\n",
    "\n",
    "n = 1000\n",
    "sa = stats.binom.rvs(n, p_a_exact)\n",
    "sb = stats.binom.rvs(n, p_b_exact)\n",
    "\n",
    "print(f'pa_exact={p_a_exact}, pb_exact={p_b_exact}')\n",
    "print(f'n={n}, sa={sa}, sb={sb}')\n",
    "print(f'Exact best group: {\"A\" if p_a_exact > p_b_exact else \"B\" if p_b_exact > p_a_exact else None}')\n",
    "print(f'Group selected by means comparison: {compare_groups_binomial(sa, n, sb, n)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Оценки разности средних с учетом центральной предельной теоремы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Бутстрап"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Еще один вариант закона больших чисел говорит, что по мере набора данных частоты возможных значений в сэмле будут приближаться к их вероятности. Это является основой для частотной интерпретации вероятности."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Также на этом основании имеющийся сэмпл данных можно считать приближением к точному распределению."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Общее название - методы повторной выборки данных или ресэмплинг.  \n",
    "Один из методов - метод складного ножа (Jackknife).   \n",
    "Еще один популярный метод - бутстрап.  \n",
    "Далее обсуждается только последний."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Бутстрап:  \n",
    "https://projecteuclid.org/journals/annals-of-statistics/volume-7/issue-1/Bootstrap-Methods-Another-Look-at-the-Jackknife/10.1214/aos/1176344552.full"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*What Teachers Should Know about the Bootstrap: Resampling in the Undergraduate Statistics Curriculum*  \n",
    "https://arxiv.org/abs/1411.5279  \n",
    "https://arxiv.org/pdf/1411.5279.pdf  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Можно оценить неопределенность средних значений."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_means_rawdata(dt, k_bootstrap):\n",
    "    bs = np.random.choice(dt, size=(k_bootstrap, n), replace=True)\n",
    "    means = bs.mean(axis=1)\n",
    "    return means\n",
    "\n",
    "def bootstrap_means_binomial(s, n, k_bootstrap):\n",
    "    p = s/n\n",
    "    bs = stats.binom.rvs(n, p, size=k_bootstrap)\n",
    "    means = bs / n\n",
    "    return means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_exact_a = 0.7\n",
    "p_exact_b = 0.65\n",
    "\n",
    "n = 5000\n",
    "s_a = stats.binom.rvs(n, p_exact_a)\n",
    "s_b = stats.binom.rvs(n, p_exact_b)\n",
    "p_sample_a = s_a/n\n",
    "p_sample_b = s_b/n\n",
    "\n",
    "k_bootstrap = 30000\n",
    "means_a = bootstrap_means_binomial(s_a, n, k_bootstrap)\n",
    "means_b = bootstrap_means_binomial(s_b, n, k_bootstrap)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(x=means_a, histnorm='percent',\n",
    "                           name='A',\n",
    "                           opacity=0.3))\n",
    "#fig.add_vline(x=p_sample_a, line_dash='dash')\n",
    "fig.add_vline(x=p_exact_a)\n",
    "fig.add_trace(go.Histogram(x=means_b, histnorm='percent',\n",
    "                           name='B',\n",
    "                           opacity=0.3))\n",
    "#fig.add_vline(x=p_sample_b, line_dash='dash')\n",
    "fig.add_vline(x=p_exact_b)\n",
    "# fig.add_trace(go.Scatter(x=[p_exact_b, p_exact_b], y=[0, 1], \n",
    "#                          mode='lines', line_color='black', line_dash='dash',\n",
    "#                          name='Exact Mean B'))\n",
    "fig.update_layout(title='Means Bootstrap Dists',\n",
    "                  xaxis_title='p',\n",
    "                  yaxis_title='Prob',\n",
    "                  hovermode=\"x\",\n",
    "                  height=550,\n",
    "                  barmode='overlay')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_groups_bootstrap_binomial(sa, na, sb, nb):\n",
    "    k_bootstrap = 30000\n",
    "    means_a = bootstrap_means_binomial(sa, na, k_bootstrap)\n",
    "    means_b = bootstrap_means_binomial(sb, nb, k_bootstrap)\n",
    "    p_ea_gt_eb = np.sum(means_a > means_b) / len(means_a)\n",
    "    p_level = 0.95\n",
    "    res = None\n",
    "    if p_ea_gt_eb >= p_level:\n",
    "        res = 'A'\n",
    "    elif (1 - p_ea_gt_eb) >= p_level:\n",
    "        res = 'B'\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_a_exact = 0.7\n",
    "p_b_exact = 0.67\n",
    "\n",
    "n = 1000\n",
    "sa = stats.binom.rvs(n, p_a_exact)\n",
    "sb = stats.binom.rvs(n, p_b_exact)\n",
    "\n",
    "print(f'pa_exact={p_a_exact}, pb_exact={p_b_exact}')\n",
    "print(f'n={n}, sa={sa}, sb={sb}')\n",
    "print(f'Exact best group: {\"A\" if p_a_exact > p_b_exact else \"B\" if p_b_exact > p_a_exact else None}')\n",
    "print(f'Group selected by bootstrap comparison: {compare_groups_bootstrap_binomial(sa, n, sb, n)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вычислительно может быть затратно.  \n",
    "Есть пара трюков для ускорения вычислений.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пуассоновский бутстрап:  \n",
    "https://www.unofficialgoogledatascience.com/2015/08/an-introduction-to-poisson-bootstrap26.html  \n",
    "\n",
    "Сэмплировать из выборки [x1, x2, ..., xn] с повторением все равно, что генерировать набор\n",
    "мультиномиальных коэффициетов x ~ Multinomial(n, 1/n). Для больших n предлагается заменить Multinomial(n, 1/n) на n сэмплов из биномиального распределение Binom(n, 1/n). Количество точек в каждом векторе при этом перестает быть одинаковым. Еще один шаг - заменить биномиальное распределение Binom(n, 1/n) на распределение Пуассона Poisson(1). Сэмплировать из него. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Байесовский бутстрап:  \n",
    "https://gdmarmerola.github.io/the-bayesian-bootstrap/ - примеры  \n",
    "https://projecteuclid.org/journalArticle/Download?urlId=10.1214%2Faos%2F1176345338 - оригинальный текст  \n",
    "https://www.sumsar.net/blog/2015/04/the-non-parametric-bootstrap-as-a-bayesian-model/  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Есть данные x_1, ..., x_n.  \n",
    "Сгенерировать (n-1) точку u_1, ..., u_{n-1} из равномерного распределениея U(0,1);\n",
    "Отсортировать их;  \n",
    "Дополнить точками [0, ... , 1]  \n",
    "Посчитать разности g_i = u_i - u_i-1, i>=1.  \n",
    "Использовать g_i как вероятности для [x1, ..., x_n].   \n",
    "Среднее  \n",
    "m = sum g_i x_i"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Есть отличия в интерпретации от обычного бутстрапа."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ограничения?  \n",
    "Бутстрап несколько хуже работает для непрерывных величин.  \n",
    "При малых размерах исходных данных.  \n",
    "Если часть данных мало представлена (исходное распределение скошено, в выборке мало значений из хвоста).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Метод максимального правдоподобия"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предполагается аналитическое распределение для данных - (функция правдоподобия).  \n",
    "Значения параметров выбирается такие, которые будут максимизировать эту функцию при имеющихся данных.  \n",
    "\n",
    "https://en.wikipedia.org/wiki/Maximum_likelihood_estimation#Asymptotics  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для некоторых моделей можно проверси аналитические вычисления.  \n",
    "Для биномиального распределения максимум правдоподобия совпадет со средним в сэмпле.  \n",
    "Для нормального - со средним и дисперсией в сэмле. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В байесовском подходе параметры интерпретируются как случайные величины с распределением.  \n",
    "В методе максимального правдоподобия - считаются неизвестной постоянной величиной.\n",
    "\n",
    "Оценка параметров этим методом совпадет с максимум апостериорного распределения, если априорное распределение равномерное\n",
    "\n",
    "https://en.wikipedia.org/wiki/Maximum_a_posteriori_estimation  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выбрана модель и оценены параметры, дальше можно сравнивать эти распределения.  \n",
    "Если есть возможность посчитать средние по параметрам аналитически, то можно выбрать группу с большим средним.  \n",
    "Метод формально говорит о полной уверенности."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Поскольку вместо распределения параметров используется точечная оценка, метод будет давать завышенную уверенность по сравнению со сравнением апостериорных распределений в байесовском подходе.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Доверительные интервалы** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Проверка статистических гипотез"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для анализа А/Б-тестов иногда используют метод статистических гипотез. \n",
    "Общая идея - предположить, что между группами нет разницы, после чего посчитать, насколько такое предположение объясняет экспериментальные данные. Если вероятность получить данные мала, то считается, что предположение можно отвергнуть, т.е. между группами есть значимая разница.  \n",
    "\n",
    "Для вычисления вероятности получить данные в рамках предположения об эквивалентности групп существует многообразие статистических тестов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Минимальный пример проверки статистической гипотезы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Есть экспериментальные данные $data$.  \n",
    "Есть гипотеза $H$ об этих данных или их свойствах.  \n",
    "Есть случайная величина $Test$, распределение которой $P_{Test|H}(x)$ в предположении $H$ известно.  \n",
    "По фактическим данным считается \"тестовая статистика\"  $x_{fact}$ .   \n",
    "Считаем вероятность получить \"фактическое или более экстремальное\" значение \"тестовой статистики\" $p = P_{Test|H}(x \\ge x_{fact} )$ или $p = P_{Test|H}(x \\le x_{fact} )$ . Т.е. $p = CDF_{Test|H}(x_{fact})$ или $p = 1 - CDF_{Test|H}(x_{fact})$ .  \n",
    "Если вероятность мала, то гипотезу $H$ считают неверной."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Пример:\n",
    "- данные: в 1000 бросках монетки в 700 случаях выпал орел.  \n",
    "- гипотеза: вероятность выпадения орла 0.5   \n",
    "- случайная величина с известным распределением: вероятность k успехов в N попытках при вероятности $p$ успеха в одной попытке задается биномиальным распределением $Binom(p; N, k)$  \n",
    "- тестовая статистика: число успехов k=700 в общих попытках N=1000\n",
    "- p-значение: вероятность получить 700 или больше успехов в 1000 попытках $\\sum_{i \\ge 700}Binom(0.5; 1000, i)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Полезно сравнить с байесовским подходом.  \n",
    "Данные те же.  \n",
    "Случайная величина с известным распределением - функция правдоподобия.  \n",
    "Гипотеза - конкретное значение параметров.  \n",
    "Тестовая статистика - аргумент в функции правдоподобия x_fact = f(data).   \n",
    "p-значение: sum x L(x >= x_fact | H)  \n",
    "Аналога априорного распределения нет.  \n",
    "Иначе устроена интерпретация: в проверке стат. гипотез решение принимают по функции правдоподобия, в байесовском подходе пересчитывают в вероятность.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сложность с интерпретацией $p$-значения.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для оценки параметров проверка статистических гипотез обычно не используется.   \n",
    "Используется метод максимального правдоподобия или другие предположения.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для оценки интервалов параметров используются \"доверительные интервалы\".  \n",
    "Формально неопределенности в параметрах нет.  \n",
    "Сложности с интерпретацией доверительных интервалов:  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Все давно сделано:  \n",
    "https://michael-franke.github.io/BDACM_2018/scripts/01_estimation_pValues.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тест Колмогорова-Смирнова  \n",
    "https://en.wikipedia.org/wiki/Kolmogorov%E2%80%93Smirnov_test  \n",
    "\n",
    "U-тест  \n",
    "https://en.wikipedia.org/wiki/Mann%E2%80%93Whitney_U_test  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t-тест для средних\n",
    "\n",
    "https://en.wikipedia.org/wiki/Student's_t-test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_a_exact = 0.7\n",
    "p_b_exact = 0.67\n",
    "\n",
    "n = 1000\n",
    "sa = stats.binom.rvs(n, p_a_exact)\n",
    "sb = stats.binom.rvs(n, p_b_exact)\n",
    "\n",
    "p_a = sa/n\n",
    "a_var = n * p_a * (1 - p_a)\n",
    "a_stderr = np.sqrt(a_var) / n\n",
    "\n",
    "p_b = sb/n\n",
    "b_var = n * p_b * (1 - p_b)\n",
    "b_stderr = np.sqrt(b_var) / n\n",
    "\n",
    "x=np.linspace(0, 1, 1000)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=stats.norm.pdf(x, p_a, a_stderr),\n",
    "                         name='A'))\n",
    "fig.add_trace(go.Scatter(x=x, y=stats.norm.pdf(x, p_b, b_stderr),\n",
    "                         name='B'))\n",
    "fig.update_layout(\n",
    "    title='Means Normal Dists for t-test'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ttest_means_rawdata(a, b):\n",
    "    t, p = stats.ttest_indep(a, b)\n",
    "    return p\n",
    "    \n",
    "\n",
    "def compare_groups_ttest_binomial(sa, na, sb, nb):\n",
    "    a_mean = sa/n\n",
    "    a_var = n * a_mean * (1 - a_mean)\n",
    "    a_stderr = np.sqrt(a_var) / n\n",
    "    b_mean = sb/n\n",
    "    b_var = n * b_mean * (1 - b_mean)\n",
    "    b_stderr = np.sqrt(b_var) / n\n",
    "    diff = a_mean - b_mean\n",
    "    diff_stderr = np.sqrt(a_stderr**2 + b_stderr**2)\n",
    "    pval = stats.norm.cdf(0, diff, diff_stderr)\n",
    "    p_level = 0.95\n",
    "    significant = (pval >= p_level) or (1 - pval) >= p_level\n",
    "    if not significant:\n",
    "        res = None\n",
    "    elif significant and a_mean > b_mean:\n",
    "        res = 'A'\n",
    "    elif significant and b_mean > a_mean:\n",
    "        res = 'B'\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_a_exact = 0.7\n",
    "p_b_exact = 0.67\n",
    "\n",
    "n = 1000\n",
    "sa = stats.binom.rvs(n, p_a_exact)\n",
    "sb = stats.binom.rvs(n, p_b_exact)\n",
    "\n",
    "print(f'pa_exact={p_a_exact}, pb_exact={p_b_exact}')\n",
    "print(f'n={n}, sa={sa}, sb={sb}')\n",
    "print(f'Exact best group: {\"A\" if p_a_exact > p_b_exact else \"B\" if p_b_exact > p_a_exact else None}')\n",
    "print(f'Group selected by bootstrap comparison: {compare_groups_ttest_binomial(sa, n, sb, n)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.ttest_ind.html\n",
    "#https://en.wikipedia.org/wiki/Welch%27s_t-test\n",
    "\n",
    "a = np.zeros(n)\n",
    "a[:sa] = 1\n",
    "#print(sa)\n",
    "#np.unique(a, return_counts=True)\n",
    "\n",
    "b = np.zeros(n)\n",
    "b[:sb] = 1\n",
    "\n",
    "t, p = stats.ttest_ind(a, b, equal_var=False)#, alternative='less')\n",
    "print(t,p)\n",
    "\n",
    "p_a = sa/n\n",
    "a_var = n * p_a * (1 - p_a)\n",
    "a_stderr = np.sqrt(a_var) / n\n",
    "p_b = sb/n\n",
    "b_var = n * p_b * (1 - p_b)\n",
    "b_stderr = np.sqrt(b_var) / n\n",
    "diff = p_a - p_b\n",
    "diff_stderr = np.sqrt(a_stderr**2 + b_stderr**2)\n",
    "pval = stats.norm.cdf(0, diff, diff_stderr)\n",
    "pval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Перестановочный тест"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://en.wikipedia.org/wiki/Permutation_test  \n",
    "\n",
    "Есть данные из двух групп.\n",
    "Считаем среднее в каждой группе.\n",
    "Считаем разницу.\n",
    "\n",
    "Далее вопрос: насколько вероятно получить такую разницу если группы одинаковы?\n",
    "\n",
    "Для ответа предполагаем, что группы значения пришли из общего распределения.\n",
    "Из общего распределения сэмплим n_a значений, считаем среднее, потом n_b, также считаем среднее, считаем разницу между средними. \n",
    "Это повторяется по всем возможным комбинациям или пока не надоест. \n",
    "Строится распределение разностей средних.  \n",
    "Определяется, где на этом распределении фактическое значение.  \n",
    "Если оно \"достаточно экстремально\", группы объявляются разными.  \n",
    "\n",
    "К перестановочным тестам применяют механику $p$-значений из проверки статистических гипотез (см. далее).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_mean = 3\n",
    "b_mean = 3.1\n",
    "sigma = 1\n",
    "samp_a = stats.norm.rvs(loc=a_mean, scale=sigma, size=30)\n",
    "samp_b = stats.norm.rvs(loc=b_mean, scale=sigma, size=30)\n",
    "\n",
    "x = np.linspace(0, 5, 1000)\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=stats.norm.pdf(x=x, loc=a_mean, scale=sigma)))\n",
    "fig.add_trace(go.Histogram(x=samp_a))\n",
    "fig.add_trace(go.Scatter(x=x, y=stats.norm.pdf(x=x, loc=b_mean, scale=sigma)))\n",
    "fig.add_trace(go.Histogram(x=samp_b))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp_info = pd.DataFrame([\n",
    "    {'group':'A', 'a':1, 'b':1, 'sample_size':100},\n",
    "    {'group':'B', 'a':1, 'b':1.25, 'sample_size':100}])\n",
    "exp_info.set_index('group', inplace=True)\n",
    "\n",
    "exact_dist_a = stats.gamma(a=exp_info['a']['A'], scale=1/exp_info['b']['A'])\n",
    "exact_dist_b = stats.gamma(a=exp_info['a']['B'], scale=1/exp_info['b']['B'])\n",
    "exp_info['exact_mean'] = pd.Series({'A': exact_dist_a.mean(), 'B':exact_dist_b.mean()})\n",
    "display(exp_info)\n",
    "\n",
    "samp_a = exact_dist_a.rvs(size=exp_info['sample_size']['A'])\n",
    "samp_b = exact_dist_b.rvs(size=exp_info['sample_size']['B'])\n",
    "\n",
    "x = np.linspace(0, 10, 2000)\n",
    "ymax = np.max([exact_dist_a.pdf(x), exact_dist_b.pdf(x)])\n",
    "\n",
    "fig = go.Figure()\n",
    "col = 'red'\n",
    "fig.add_trace(go.Scatter(x=x, y=exact_dist_a.pdf(x), \n",
    "                         mode='lines', line_color=col,\n",
    "                         name=f\"Exact A: a={exp_info['a']['A']}, b={exp_info['b']['A']}\"))\n",
    "fig.add_trace(go.Histogram(x=samp_a, histnorm='probability density',\n",
    "                           name='Sample A',\n",
    "                           opacity=0.3, marker_color=col))\n",
    "fig.add_trace(go.Scatter(x=[exact_dist_a.mean(), exact_dist_a.mean()], y=[0, ymax], \n",
    "                         mode='lines', line_color=col, line_dash='dash',\n",
    "                         name='Exact Mean A'))\n",
    "col = 'blue'\n",
    "fig.add_trace(go.Scatter(x=x, y=exact_dist_b.pdf(x), \n",
    "                         mode='lines', line_color=col,\n",
    "                         name=f\"Exact B: a={exp_info['a']['B']}, b={exp_info['b']['B']}\"))\n",
    "fig.add_trace(go.Histogram(x=samp_b, histnorm='probability density',\n",
    "                           name='Sample B',\n",
    "                           opacity=0.3, marker_color=col))\n",
    "fig.add_trace(go.Scatter(x=[exact_dist_b.mean(), exact_dist_b.mean()], y=[0, ymax], \n",
    "                         mode='lines', line_color=col, line_dash='dash',\n",
    "                         name='Exact Mean B'))\n",
    "fig.update_layout(title='Exact Distributions and Samples',\n",
    "                  xaxis_title='x',\n",
    "                  yaxis_title='Prob Density',\n",
    "                  hovermode=\"x\",\n",
    "                  height=550,\n",
    "                  barmode='overlay')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pooled = np.concatenate([samp_a, samp_b])\n",
    "\n",
    "n_resample = 10000\n",
    "means_diff = np.empty(n_resample)\n",
    "\n",
    "for i in range(n_resample):\n",
    "    tmp = np.random.permutation(pooled)\n",
    "    tmp_a = tmp[0:len(samp_a)]\n",
    "    tmp_b = tmp[len(samp_a):]\n",
    "    mean_diff = tmp_a.mean() - tmp_b.mean()\n",
    "    means_diff[i] = mean_diff\n",
    "\n",
    "#means_diff\n",
    "diff_mean_fact = samp_a.mean() - samp_b.mean()\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(x=means_diff, histnorm='probability density',\n",
    "                           name='Means Diff',\n",
    "                           opacity=0.3, marker_color=col))\n",
    "fig.add_vline(x=diff_mean_fact)\n",
    "fig.show()\n",
    "\n",
    "pval = np.sum(means_diff[means_diff > diff_mean_fact]) / len(means_diff)\n",
    "print(pval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Байесовское моделирование"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теория разобрана в предыдущих частях."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Основная идея - предположить аналитический вид распределения (\"модель\"). С помощью соотношения Байеса построить плотность вероятности параметров модели.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def posterior_binom_beta(sa, n, alpha=1, beta=1):\n",
    "    alpha_post = alpha + sa\n",
    "    beta_post = beta + (n - sa)\n",
    "    return stats.beta(alpha_post, beta_post)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pa_exact = 0.7\n",
    "pb_exact = 0.65\n",
    "\n",
    "n = 1000\n",
    "sa = stats.binom.rvs(n, pa_exact)\n",
    "sb = stats.binom.rvs(n, pb_exact)\n",
    "\n",
    "post_dist_a = posterior_binom_beta(sa, n)\n",
    "post_dist_b = posterior_binom_beta(sb, n)\n",
    "\n",
    "x = np.linspace(0, 1, 1000)\n",
    "ymax = np.max([post_dist_a.pdf(x), post_dist_b.pdf(x)])\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=post_dist_a.pdf(x), name='A'))\n",
    "fig.add_trace(go.Scatter(x=[pa_exact, pa_exact], y=[0, ymax], \n",
    "                         mode='lines', line_dash='dash', line_color='black', \n",
    "                         name='A: p exact'))\n",
    "fig.add_trace(go.Scatter(x=x, y=post_dist_b.pdf(x), name='B'))\n",
    "fig.add_trace(go.Scatter(x=[pb_exact, pb_exact], y=[0, ymax],\n",
    "                         mode='lines', line_dash='dash', line_color='black', \n",
    "                         name='B: p exact'))\n",
    "fig.update_layout(title='Posterior',\n",
    "                  xaxis_title='p',\n",
    "                  yaxis_title='Prob',\n",
    "                  xaxis_range=[0.5, 1],\n",
    "                  hovermode=\"x\",\n",
    "                  height=550,\n",
    "                  barmode='overlay')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_groups_bayes_binomial(sa, na, sb, nb):\n",
    "    n_post_sample = 30000\n",
    "    c_level = 0.95\n",
    "    post_a = posterior_binom_beta(sa, na)\n",
    "    post_b = posterior_binom_beta(sb, nb)\n",
    "    post_samp_a = post_a.rvs(n_post_sample)\n",
    "    post_samp_b = post_b.rvs(n_post_sample)\n",
    "    pa_gt_pb = np.sum(post_samp_a > post_samp_b) / len(post_samp_a)\n",
    "    res = None\n",
    "    if pa_gt_pb >= c_level:\n",
    "        res = 'A'\n",
    "    elif pa_gt_pb <= (1 - c_level):\n",
    "        res = 'B'\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_a_exact = 0.7\n",
    "p_b_exact = 0.67\n",
    "\n",
    "n = 1000\n",
    "sa = stats.binom.rvs(n, p_a_exact)\n",
    "sb = stats.binom.rvs(n, p_b_exact)\n",
    "\n",
    "print(f'pa_exact={p_a_exact}, pb_exact={p_b_exact}')\n",
    "print(f'n={n}, sa={sa}, sb={sb}')\n",
    "print(f'Exact best group: {\"A\" if p_a_exact > p_b_exact else \"B\" if p_b_exact > p_a_exact else None}')\n",
    "print(f'Group selected by bayesian comparison: {compare_groups_bayes_binomial(sa, n, sb, n)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Количество правильно угаданных вариантов"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Две группы.  \n",
    "Пусть сравниваются конверсии.  \n",
    "Т.е. загадываются параметры двух пуассоновских процессов.  \n",
    "Фиксируется количество наблюдений N.  \n",
    "Для фиксированного количества наблюдений генерируется k пар параметров pa, pb.  \n",
    "Для каждой пары генерируется число успехов ka, kb.  \n",
    "Числа "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Генерация данных для эксперимента"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_binomial_experiments(n_points, k_experiments, pa_base=0.1):\n",
    "    pa = np.full(k_experiments, pa_base)\n",
    "    pb = stats.uniform.rvs(loc=0.9*pa, scale=0.2*pa) #unif[loc, loc+scale]\n",
    "    sa = stats.binom.rvs(n=n_points, p=pa, size=k_experiments)\n",
    "    sb = stats.binom.rvs(n=n_points, p=pb, size=k_experiments)\n",
    "    e = {\n",
    "        'exp_type': 'binomial',\n",
    "        'k_experiments': k_experiments,\n",
    "        'n_points': n_points,\n",
    "        'pa_exact': pa,\n",
    "        'pb_exact': pb,\n",
    "        'sa': sa,\n",
    "        'sb': sb\n",
    "    }\n",
    "    return e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравнение экспериментов и подсчет количества правильно угаданных вариантов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_experiments_binomial_exact(exps):\n",
    "    s = np.empty_like(exps['pa_exact'], dtype=object)\n",
    "    s[exps['pa_exact'] > exps['pb_exact']] = 'A'\n",
    "    s[exps['pb_exact'] > exps['pa_exact']] = 'B'\n",
    "    res = {\n",
    "        'comparison_type': 'exact',\n",
    "        'selected': s\n",
    "    }\n",
    "    return res\n",
    "\n",
    "def compare_experiments(exps, method_name, method_fn):\n",
    "    s = np.empty(k_experiments, dtype=object)\n",
    "    n = exps['n_points']\n",
    "    for i, (sa, sb) in enumerate(zip(exps['sa'], exps['sb'])):\n",
    "        s[i] = method_fn(sa=sa, na=n, sb=sb, nb=n)\n",
    "    res = {\n",
    "        'comparison_type': method_name,\n",
    "        'selected': s\n",
    "    }\n",
    "    return res\n",
    "\n",
    "def method_guesses(method, exact, n_points):\n",
    "    e = exact['selected']\n",
    "    m = method['selected']\n",
    "    s = {\n",
    "        'name': method['comparison_type'],\n",
    "        'n_points': n_points,\n",
    "        'experiments': len(e),\n",
    "        'correct': np.sum(e == m),\n",
    "        'not_sure': len(e) - np.count_nonzero(m),\n",
    "        'incorrect': np.count_nonzero(m) - np.sum(e == m)\n",
    "    }\n",
    "    return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Подсчет очков:\n",
    "\n",
    "for each experiment:\n",
    "    score_exact = N * max(pa, pb) \n",
    "    score_method = N * p_selected; p_selected = p_a if 'A', p_b if 'B', (pa + pb)/2 if None.\n",
    "\n",
    "    score_method_accum += score_method / score_exact\n",
    "    \n",
    "Такой способ подсчета очков неоптимален для сомневающихся алгоритмов.  \n",
    "Но не важно."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def method_score(exps, method_selected):\n",
    "    m_a = np.zeros_like(exps['pa_exact'])\n",
    "    m_a[method_selected == 'A'] = 1\n",
    "    m_a[method_selected == None] = 0.5 #todo: rewrite; should be elementwise is None\n",
    "    m_b = np.zeros_like(exps['pb_exact'])\n",
    "    m_b[method_selected == 'B'] = 1\n",
    "    m_b[method_selected == None] = 0.5 #todo: rewrite should be elementwise is None\n",
    "    selected = m_a * exps['pa_exact'] + m_b * exps['pb_exact']\n",
    "    exact = np.maximum(exps['pa_exact'], exps['pb_exact'])\n",
    "    score = np.divide(selected, exact)\n",
    "    return np.sum(score) / len(score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сравнение "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_points = np.array([10, 100, 1000, 5000, 10000, 50000, 100000, 500000, 1000000])\n",
    "#n_points = 100000\n",
    "k_experiments = 100\n",
    "pa_base = 0.1\n",
    "\n",
    "comparisons = {\n",
    "    'means': compare_groups_binomial,\n",
    "    'bootstrap': compare_groups_bootstrap_binomial,\n",
    "    'bayes': compare_groups_bayes_binomial,\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(columns=['name', 'n_points', 'experiments', \n",
    "                           'correct', 'not_sure', 'incorrect', 'score'])\n",
    "\n",
    "for n in n_points:\n",
    "    exps = gen_binomial_experiments(n, k_experiments, pa_base)\n",
    "    cmp_exact = compare_experiments_binomial_exact(exps)\n",
    "    for k, v in comparisons.items():\n",
    "        cmp = compare_experiments(exps, method_name=k, method_fn=v)\n",
    "        stat = method_guesses(method=cmp, exact=cmp_exact, n_points=n)\n",
    "        stat['score'] = method_score(exps, cmp['selected'])\n",
    "        df = pd.concat([df, pd.DataFrame([stat])], ignore_index=True)\n",
    "\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(df, x='n_points', y='correct', color='name', markers='markers', log_x=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(df, x='n_points', y='score', color='name', markers='markers', log_x=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*При большом количестве точек решения бутстрапа и байесовского моделирования совпадают.*  \n",
    "*Бета-распределение и биномиальное распределение переходят в нормальное *\n",
    "$$\n",
    "N(p, \\frac{p(1-p)}{n}) ?\n",
    "$$\n",
    "\n",
    "Бета:  https://en.wikipedia.org/wiki/Beta_distribution#Special_and_limiting_cases  \n",
    "Биномиальное: https://en.wikipedia.org/wiki/Binomial_distribution#Normal_approximation  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Алгоритм оценки А/Б-тестов на основе проверки статистических гипотез"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Общая идея:\n",
    "\n",
    "Сформулировать нулевую гипотезу.\n",
    "Выбрать уровень стат. значимости и мощности.\n",
    "\n",
    "* Популяция\n",
    "* Распределяем в 2 выборки\n",
    "* Получаем 2 набора данных\n",
    "* Считаем среднее и стандартное отклонение в каждом варианте\n",
    "* считаем стандартную ошибку среднего для каждого варианта\n",
    "* Предполагаем, что среднее по популяции каждого варианта находится вблизи среднего, посчитанного по выборке. \n",
    "* На основании центральной предельной теоремы сумма большого количества значений из одного распределения имеет нормальное распределение; среднее по выборке - сумма большого количества величин из одинакового распределения. На этом основании объявляем, что реальное среднее для каждого из вариантов распределено нормально вокруг среднего из выборки со стандартной ошибкой среднего [как это согласуется с частотной интерпретацей?] \n",
    "* Переходят к распределению для разницы двух величин: средние вычитаются, стандартные отклонения sqrt(s1^2 + s2^2).\n",
    "* считают p-значение. Проверяют, достаточно ли оно мало для объявления стат. значимости.\n",
    "\n",
    "\n",
    "Напоминалка:\n",
    "https://towardsdatascience.com/the-math-behind-a-b-testing-with-example-code-part-1-of-2-7be752e1d06f\n",
    "\n",
    "\n",
    "Вопросы: 2 категории - концептуальные и механика применения.\n",
    "\n",
    "* Как интерпретировать доверительный интервал и стат. значимость?\n",
    "* Как считается мощность? Особенно если распредления не симметричные?\n",
    "* Вариантов больше 2 (групповые поправки)\n",
    "* Подглядывания (и гарантии на значимость и мощность в этом случае)\n",
    "* Оценка размера выборки если дисперсия не связана со средним?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Статистические тесты, доверительные интервалы, проверка статистических гипотез."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Статистические тесты**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Картинки про типы тестов:  \n",
    "https://blog.statsols.com/types-of-statistical-tests  \n",
    "\n",
    "https://duckduckgo.com/?q=how+to+choose+statistical+test&t=ffab&iar=images&iax=images&ia=images  \n",
    "\n",
    "https://www.google.com/search?q=how+to+choose+statistical+test&source=lnms&tbm=isch&sa=X&ved=2ahUKEwip1s-rjuP3AhWIr4sKHY2HCHQQ_AUoAXoECAEQAw&biw=1280&bih=603&dpr=1.5 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Доверительный интервал**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Проверка статистических гипотез**\n",
    "\n",
    "Проверка гипотез: https://en.wikipedia.org/wiki/Statistical_hypothesis_testing \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### t-тест и центральная предельная теорема"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Откуда берется t-тест**  \n",
    "\n",
    "См. https://en.wikipedia.org/wiki/Student%27s_t-test и https://en.wikipedia.org/wiki/Student's_t-distribution .  \n",
    "\n",
    "$$\n",
    "\\frac{X - \\mu}{S/\\sqrt{n}}\n",
    "$$\n",
    "X - sample mean, S - Bessel-corrected sample variance.\n",
    "\n",
    "При больших N t-распределение почти совпадает с нормальным."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t-критерий:\n",
    "\n",
    "$P(\\frac{X - \\mu}{S/\\sqrt{n}} | \\mu, \\sigma) = t(...)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Центральная предельная теорема**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"central_limit_theorem_and_t_test.png\" alt=\"central_limit_theorem_and_t_test\" width=\"600\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Используемые предположения**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какой вариант лучше?**\n",
    "\n",
    "Нужно $P(p_A > p_B)$.\n",
    "\n",
    "Статистическая гипотеза: $p_A = p_B$.  \n",
    "p-значение: $P(data | p_A = p_B) = p$\n",
    "\n",
    "Дальше обычно говорят, что если $p$ мало, то $p_A \\ne p_B$.\n",
    "\n",
    "Как связано p-значение с нужной вероятностью $P(p_A > p_B)$?\n",
    "\n",
    "Сложности:  \n",
    "Из того, что $P(data | p_A = p_B)$ мало не следует, что $p_A \\ne p_B$.  \n",
    "Чтобы перейти от $P(data | p_A = p_B)$ к $P(p_A = p_B | data)$ нужно соотношение Байеса.  \n",
    "Но дальше все равно непонятно, как $P(p_A = p_B | data)$ соотносится с $P(p_A > p_B)$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Каковы оценки метрики в каждой группе?**\n",
    "\n",
    "Нужны оценки плотности вероятности P(p_A), P(p_B).\n",
    "\n",
    "Есть средние в выборках.  \n",
    "\n",
    "Для оценки неопределенности предлагается считать доверительные интервалы.  \n",
    "Считаются в предположении, что выполняется центральная предельная теорема.  \n",
    "$$\n",
    "P(p_A) = N(p_{A, mean}, \\sigma_A)\n",
    "\\\\\n",
    "P(p_B) = N(p_{B, mean}, \\sigma_B)\n",
    "$$\n",
    "Доверительные интервалы дают оценки:  \n",
    "$$\n",
    "P(p_A \\in [p_{A, mean} - 2\\sigma_A, p_{A, mean} + 2\\sigma_A]) = \\alpha\n",
    "\\\\\n",
    "P(p_B \\in [p_{B, mean} - 2\\sigma_B, p_{B, mean} + 2\\sigma_B]) = \\alpha\n",
    "$$\n",
    "\n",
    "\n",
    "Кажется, что такие оценки занижают неопределенность.  \n",
    "Не обязательно, что среднее равно именно среднему в выборке, может быть в окрестностях.  \n",
    "\n",
    "Нужно смотреть модель\n",
    "\n",
    "$$\n",
    "P(mu, sigma | data) \\\\\n",
    "P(data | mu, sigma) = N(mu, sigma) \\\\\n",
    "mu - \\mbox{нормальное распределение вокруг среднего значения в выборке} \\\\\n",
    "sigma - \\mbox{широкое нормальное распределение с центром на стандартной ошибке среднего для выборки}\n",
    "$$\n",
    "\n",
    "Или сравнить с бета-распределением.\n",
    "\n",
    "Можно проверить, посэмлировав распределение.   \n",
    "Если нормальное приближение делает завышенную по уверенности оценку, то при повторном применении этого приближения\n",
    "не получится заявленная вероятность попадания среднего в доверительный интервал.\n",
    "\n",
    "Фиксируется p.  \n",
    "Сэмплируется.  \n",
    "Считается N(mu, sigma).  \n",
    "Проверяется попадание попадание p в определенный доверительный интервал.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нормальное или t-распределение можно рассматривать как оценку распределения P(mu | data).  \n",
    "При этом приходится отказаться от претензий на установление реального среднего.  \n",
    "И иметь дело с теми же проблемами, что и для любых других моделей - насколько адекватны предположения,\n",
    "насколько адекватны прогнозы.  \n",
    "Одна из проблем - распределение не ограничено интервалом [0,1] и есть ненулевая плотность вероятности за границами области."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "t-критерий:\n",
    "\n",
    "$P(\\frac{X - \\mu}{S/\\sqrt{n}} | \\mu, \\sigma) = t(...)$\n",
    "\n",
    "Нужно\n",
    "\n",
    "$P(\\mu, \\sigma | X)$\n",
    "\n",
    "Скорее всего можно предположить фиксированное $\\sigma$.\n",
    "\n",
    "Дальше\n",
    "\n",
    "$$\n",
    "P(\\mu, \\sigma | X) = \\frac{P(X| \\mu, \\sigma) P(\\mu, \\sigma)}{\\int d\\mu P(X| \\mu, \\sigma) P(\\mu, \\sigma)}\n",
    "$$\n",
    "\n",
    "Если приближенно считать функцию правдоподобия нормальной,\n",
    "можно задать сопряженное априорное распределение.  \n",
    "https://en.wikipedia.org/wiki/Conjugate_prior#Continuous_distributions  \n",
    "Сопряженное априорное также нормальное.  \n",
    "Только не очень понятно, как выбирать параметры -- чтобы не на основе сэмпла."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "prior_conv = 0.3\n",
    "\n",
    "a_total = 100\n",
    "a_conv = a_total * prior_conv\n",
    "\n",
    "#x = np.linspace(0, 1, 1001)\n",
    "x = np.linspace(0, a_total, 10000)\n",
    "fig = go.Figure()\n",
    "\n",
    "# Norm\n",
    "mu = a_conv\n",
    "var = a_total * prior_conv * (1 - prior_conv)\n",
    "sigma = np.sqrt(var)\n",
    "stderrmean = sigma / np.sqrt(a_total)\n",
    "print(mu, stderrmean)\n",
    "\n",
    "fig.add_trace(go.Scatter(x=x, y=stats.norm.pdf(x, loc=mu, scale=stderrmean), mode='lines',\n",
    "                         name=f\"<br>total = {a_total}, conv = {a_conv}<br>mu={mu}, stderrmean={stderrmean}\"))\n",
    "\n",
    "\n",
    "#Uniform prior\n",
    "# beta_prior = 1\n",
    "# alpha_prior = 1\n",
    "\n",
    "# alpha_post = alpha_prior + a_conv\n",
    "# beta_post = beta_prior + (a_total - a_conv)\n",
    "# fig.add_trace(go.Scatter(x=x, y=stats.beta.pdf(x, alpha_post, beta_post), mode='lines',\n",
    "#                          name=f\"<br>A: total = {a_total}, conv = {a_conv}<br>alpha_prior={alpha_prior}, beta_prior={beta_prior},<br>alpha_post={alpha_post}, beta_post={beta_post}\"))\n",
    "\n",
    "\n",
    "\n",
    "fig.update_layout(title='Posterior and Prior Distributions',\n",
    "                  xaxis_title='p',\n",
    "                  yaxis_title='Prob Density',\n",
    "                  hovermode=\"x\",\n",
    "                  height=550)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "prior_conv = 0.4\n",
    "\n",
    "a_total = 10\n",
    "a_conv = a_total * prior_conv\n",
    "\n",
    "x = np.linspace(0, 1, 1001)\n",
    "fig = go.Figure()\n",
    "\n",
    "# Norm\n",
    "## mu = 1 * a_conv + 0 * (a_total - a_conv)\n",
    "## mu_c = 1 * (a_conv / a_total) + 0 * (a_total - a_conv) / a_total = a_conv / a_total\n",
    "## std_c = sqrt( ( (1 - mu_c)^2 * a_conv + (0 - mu_c)^2 * (a_total - a_conv) ) / a_total )\n",
    "##       = sqrt( (1 - mu_c)^2 mu_c + mu_c^2 (1 - mu_c) )\n",
    "##       = sqrt( mu_c (1 - mu_c) )\n",
    "\n",
    "mu_c = a_conv / a_total\n",
    "sigma_c = np.sqrt(mu_c * (1 - mu_c))\n",
    "stderrmean_c = sigma_c / np.sqrt(a_total)\n",
    "print(mu_c, stderrmean_c)\n",
    "\n",
    "fig.add_trace(go.Scatter(x=x, y=stats.norm.pdf(x, loc=mu_c, scale=stderrmean_c), mode='lines',\n",
    "                         name=f\"<br>total = {a_total}, conv = {a_conv}<br>mu={mu}, stderrmean={stderrmean}\"))\n",
    "\n",
    "\n",
    "#Uniform prior\n",
    "beta_prior = 1\n",
    "alpha_prior = 1\n",
    "\n",
    "alpha_post = alpha_prior + a_conv\n",
    "beta_post = beta_prior + (a_total - a_conv)\n",
    "fig.add_trace(go.Scatter(x=x, y=stats.beta.pdf(x, alpha_post, beta_post), mode='lines',\n",
    "                         name=f\"<br>A: total = {a_total}, conv = {a_conv}<br>alpha_prior={alpha_prior}, beta_prior={beta_prior},<br>alpha_post={alpha_post}, beta_post={beta_post}\"))\n",
    "\n",
    "\n",
    "\n",
    "fig.update_layout(title='Posterior and Prior Distributions',\n",
    "                  xaxis_title='p',\n",
    "                  yaxis_title='Prob Density',\n",
    "                  hovermode=\"x\",\n",
    "                  height=550)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Насколько один вариант лучше другого?**\n",
    "\n",
    "Нужно $P(p_A/p_B)$ или $P(p_A - p_B)$.  \n",
    "Распределение $P(p_A/p_B)$ обычно не считают - ограничиваются отношением средних в выборках $p_A/p_B$.  \n",
    "\n",
    "Cчитают $P(p_A - p_B)$.  \n",
    "С учетом предположений о нормальном распределении $p_A, p_B$\n",
    "$$\n",
    "P(p_A - p_B) = N(p_A - p_B; s_{AB}) \n",
    "\\\\\n",
    "s_{AB} = \\sqrt{s_A^2 / N_1 + s_B^2 / N_2} * \\sqrt{N_1 + N_2} \\quad \\mbox{(или что-то вроде)}\n",
    "$$\n",
    "(См. https://mathworld.wolfram.com/NormalDifferenceDistribution.html, https://math.stackexchange.com/questions/917276/distribution-of-the-difference-of-two-normal-random-variables, https://en.wikipedia.org/wiki/Sum_of_normally_distributed_random_variables, https://en.wikipedia.org/wiki/Normal_distribution#Operations_on_normal_deviates)\n",
    "\n",
    "При этом предположения о нормальном распределении $p_A, p_B$ излишне оптимистичны.  \n",
    "Поэтому оценка разности также будет занижена.  \n",
    "\n",
    "Можно попробовать проверить сэмплированием."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "prior_conv = 0.4\n",
    "\n",
    "a_total = 1000\n",
    "a_conv = a_total * prior_conv\n",
    "\n",
    "b_total = 1000\n",
    "b_conv = b_total * prior_conv * 1.1\n",
    "\n",
    "x = np.linspace(-1, 1, 1001)\n",
    "fig = go.Figure()\n",
    "\n",
    "# Norm\n",
    "mu_a = a_conv / a_total \n",
    "stderrmean_a = np.sqrt(mu_a * (1 - mu_a)) / np.sqrt(a_total)\n",
    "print(mu_a, stderrmean_a)\n",
    "\n",
    "mu_b = b_conv / b_total \n",
    "stderrmean_b = np.sqrt(mu_b * (1 - mu_b)) / np.sqrt(b_total)\n",
    "print(mu_b, stderrmean_b)\n",
    "\n",
    "mu_diff = mu_b - mu_a\n",
    "stderrmean_diff = np.sqrt(stderrmean_a**2 + stderrmean_b**2)\n",
    "print(mu_diff, stderrmean_diff)\n",
    "\n",
    "fig.add_trace(go.Scatter(x=x, y=stats.norm.pdf(x, loc=mu_diff, scale=stderrmean_diff), mode='lines',\n",
    "                         name=f\"Normal Diff\"))\n",
    "\n",
    "\n",
    "#Beta\n",
    "beta_prior = 1\n",
    "alpha_prior = 1\n",
    "alpha_post_a = alpha_prior + a_conv\n",
    "beta_post_a = beta_prior + (a_total - a_conv)\n",
    "n_post_sample = 50000\n",
    "post_sample_a = np.random.beta(alpha_post_a, beta_post_a, n_post_sample)\n",
    "alpha_post_b = alpha_prior + b_conv\n",
    "beta_post_b = beta_prior + (b_total - b_conv)\n",
    "post_sample_b = np.random.beta(alpha_post_b, beta_post_b, n_post_sample)\n",
    "post_sample_diff = post_sample_b - post_sample_a\n",
    "\n",
    "\n",
    "fig.add_trace(go.Histogram(x=post_sample_diff, histnorm='probability density', \n",
    "                           name='B-A', marker_color='red',\n",
    "                           opacity=0.6))\n",
    "\n",
    "\n",
    "fig.update_layout(title='P(B-A)',\n",
    "                  xaxis_title='p',\n",
    "                  yaxis_title='Prob Density',\n",
    "                  hovermode=\"x\",\n",
    "                  height=550)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Какой вариант лучше?**\n",
    "\n",
    "Нужно $P(p_A > p_B)$.\n",
    "\n",
    "Обычно пытаются проверять статистические гипотезы.  \n",
    "Предполагают $p_A = p_B$ и считают, какова вероятность получить имеющиеся средние: $P(p_{mu,A}, p_{mu,B} | p_A = p_B)$.\n",
    "\n",
    "Для t-тестов вместо статистических гипотез можно посчитать понятное значение $P(p_B > p_A)$ с помощью\n",
    "кумулятивной функции распределения нормального распределения.\n",
    "\n",
    "$$\n",
    "P(p_A > p_B) = \\mbox{norm.diff.cdf(x=0)}\n",
    "\\\\\n",
    "P(p_B > p_A) = 1 - \\mbox{norm.diff.cdf(x=0)}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(-0.5, 0.5, 1001)\n",
    "fig = go.Figure()\n",
    "# fig.add_trace(go.Scatter(x=x, y=stats.norm.pdf(x, loc=mu_diff, scale=stderrmean_diff), mode='lines',\n",
    "#                          name=f\"Normal Diff\"))\n",
    "fig.add_trace(go.Scatter(x=x, y=stats.norm.cdf(x, loc=mu_diff, scale=stderrmean_diff), mode='lines',\n",
    "                         name=f\"Normal Diff Accumulated\"))\n",
    "fig.update_layout(title='P(B-A) Accumulated',\n",
    "                  xaxis_title='p',\n",
    "                  yaxis_title='Prob Density',\n",
    "                  hovermode=\"x\",\n",
    "                  xaxis_range=[-0.1, 0.1],\n",
    "                  height=550)\n",
    "\n",
    "fig.show()\n",
    "\n",
    "\n",
    "pa_gt_pb_norm = stats.norm.cdf(x=0, loc=mu_diff, scale=stderrmean_diff)\n",
    "pb_gt_pa_norm = 1 - pa_gt_pb_norm\n",
    "print(f\"P(pa > pb) = {pa_gt_pb_norm}, P(pb > pa) = {pb_gt_pa_norm}\")\n",
    "\n",
    "#diff = B - A\n",
    "pb_gt_pa_diff = len(post_sample_diff[post_sample_diff > 0]) / len(post_sample_diff)\n",
    "pa_gt_pb_diff = 1 - pb_gt_pa_diff\n",
    "print(f\"P(pa > pb) = {pa_gt_pb_diff}, P(pb > pa) = {pb_gt_pa_diff}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Проверка статистической гипотезы $p_A = p_B$**\n",
    "\n",
    "Во-первых, вопрос о $p_A = p_B$ - это не тот вопрос, на который нужно отвечать.  \n",
    "Нужно $P(p_A > p_B)$ -- см. выше.  \n",
    "\n",
    "Во-вторых, способ проверки гипотезы вызывает вопросы.  \n",
    "Предполагают $p_A = p_B$ и считают, какова вероятность получить имеющиеся средние: $P(p_{mu,A}, p_{mu,B} | p_A = p_B)$.\n",
    "\n",
    "Выбирают уровень значимости $\\alpha$.  \n",
    "Обычно $\\alpha = 0.95$.  \n",
    "Находят симметричный относительно центра интервал, внутри которого лежит $\\alpha$ плотности вероятности.  \n",
    "Для $\\alpha = 0.95$ это [mu_diff - 2 s_diff, mu_diff + 2 s_diff].  \n",
    "По распределению разности проверяют, лежит ли точка 0 в интервале [mu_diff - 2 s_diff, mu_diff + 2 s_diff].  \n",
    "Если попадает, то гипотеза не отвергается.  \n",
    "Если не попадает, то отвергается.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Сколько должен продолжаться эксперимент?**  \n",
    "\n",
    "Для конверсий дисперсия связана со средним.  \n",
    "Можно задаться величиной эффекта.  \n",
    "Оценить, как будут выглядеть распределения средних.  \n",
    "На этом основании оценить, сколько нужно наблюдений для детектирования эффекта с определенной вероятностью.  \n",
    "\n",
    "\n",
    "Если дисперсия заранее неизвестна, то возникают проблемы с оценкой длительности.  \n",
    "Не ясно, чему равна стандартная ошибка среднего.\n",
    "\n",
    "\n",
    "Еще есть проблема подглядывания.  \n",
    "Оценку длительности предлагается фиксировать до начала эксперимента.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Как работают оценки длительности?**\n",
    "\n",
    "Один из калькуляторов: https://www.evanmiller.org/ab-testing/sample-size.html .\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "prior_conv = 0.4\n",
    "\n",
    "a_total = 1000\n",
    "a_conv = a_total * prior_conv\n",
    "\n",
    "b_total = a_total\n",
    "b_conv = b_total * prior_conv * 1.05\n",
    "\n",
    "x = np.linspace(0, 1, 1001)\n",
    "fig = go.Figure()\n",
    "\n",
    "# Norm\n",
    "## mu = 1 * a_conv + 0 * (a_total - a_conv)\n",
    "## mu_c = 1 * (a_conv / a_total) + 0 * (a_total - a_conv) / a_total = a_conv / a_total\n",
    "## std_c = sqrt( ( (1 - mu_c)^2 * a_conv + (0 - mu_c)^2 * (a_total - a_conv) ) / a_total )\n",
    "##       = sqrt( (1 - mu_c)^2 mu_c + mu_c^2 (1 - mu_c) )\n",
    "##       = sqrt( mu_c (1 - mu_c) )\n",
    "\n",
    "mu_ca = a_conv / a_total\n",
    "sigma_ca = np.sqrt(mu_ca * (1 - mu_ca))\n",
    "stderrmean_ca = sigma_ca / np.sqrt(a_total)\n",
    "print(mu_ca, stderrmean_ca)\n",
    "\n",
    "fig.add_trace(go.Scatter(x=x, y=stats.norm.pdf(x, loc=mu_ca, scale=stderrmean_ca), mode='lines',\n",
    "                         name=f\"<br>total = {a_total}, conv = {a_conv}<br>mu={mu_ca}, stderrmean={stderrmean_ca}\"))\n",
    "\n",
    "mu_cb = b_conv / b_total\n",
    "sigma_cb = np.sqrt(mu_cb * (1 - mu_cb))\n",
    "stderrmean_cb = sigma_cb / np.sqrt(b_total)\n",
    "print(mu_cb, stderrmean_cb)\n",
    "\n",
    "fig.add_trace(go.Scatter(x=x, y=stats.norm.pdf(x, loc=mu_cb, scale=stderrmean_cb), mode='lines',\n",
    "                         name=f\"<br>total = {b_total}, conv = {b_conv}<br>mu={mu_cb}, stderrmean={stderrmean_cb}\"))\n",
    "\n",
    "fig.add_vline(x=mu_cb)\n",
    "\n",
    "fig.update_layout(title='Posterior and Prior Distributions',\n",
    "                  xaxis_title='p',\n",
    "                  yaxis_title='Prob Density',\n",
    "                  hovermode=\"x\",\n",
    "                  height=550)\n",
    "\n",
    "fig.show()\n",
    "\n",
    "pval = 1 - stats.norm.cdf(x=mu_cb, loc=mu_ca, scale=stderrmean_ca)\n",
    "print(pval)\n",
    "\n",
    "\n",
    "def pval(prior_conv, exp_effect, N):\n",
    "    a_total = N\n",
    "    a_conv = a_total * prior_conv\n",
    "    b_total = a_total\n",
    "    b_conv = b_total * prior_conv * exp_effect\n",
    "    mu_ca = a_conv / a_total\n",
    "    sigma_ca = np.sqrt(mu_ca * (1 - mu_ca))\n",
    "    stderrmean_ca = sigma_ca / np.sqrt(a_total)\n",
    "    mu_cb = b_conv / b_total\n",
    "    pval = 1 - stats.norm.cdf(x=mu_cb, loc=mu_ca, scale=stderrmean_ca)\n",
    "    return pval\n",
    "\n",
    "\n",
    "N = np.linspace(100, 10000)\n",
    "y = np.array([pval(prior_conv, 1.05, Ni) for Ni in N])\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=N, y=y, mode='lines'))\n",
    "fig.add_hline(y=0.05)\n",
    "fig.update_layout(title='p-val',\n",
    "                  xaxis_title='N',\n",
    "                  yaxis_title='p-val',\n",
    "                  hovermode=\"x\",\n",
    "                  height=550)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "prior_conv = 0.4\n",
    "\n",
    "a_total = 100\n",
    "a_conv = a_total * prior_conv\n",
    "\n",
    "b_total = 100\n",
    "b_conv = b_total * prior_conv * 1.1\n",
    "\n",
    "x = np.linspace(-1, 1, 1001)\n",
    "fig = go.Figure()\n",
    "\n",
    "# Norm\n",
    "mu_a = a_conv / a_total \n",
    "stderrmean_a = np.sqrt(mu_a * (1 - mu_a)) / np.sqrt(a_total)\n",
    "print(mu_a, stderrmean_a)\n",
    "\n",
    "mu_b = b_conv / b_total \n",
    "stderrmean_b = np.sqrt(mu_b * (1 - mu_b)) / np.sqrt(b_total)\n",
    "print(mu_b, stderrmean_b)\n",
    "\n",
    "mu_diff = mu_b - mu_a\n",
    "stderrmean_diff = np.sqrt(stderrmean_a**2 + stderrmean_b**2)\n",
    "print(mu_diff, stderrmean_diff)\n",
    "\n",
    "fig.add_trace(go.Scatter(x=x, y=stats.norm.pdf(x, loc=mu_diff, scale=stderrmean_diff), mode='lines',\n",
    "                         name=f\"100\"))\n",
    "\n",
    "\n",
    "a_total = 500\n",
    "a_conv = a_total * prior_conv\n",
    "\n",
    "b_total = 500\n",
    "b_conv = b_total * prior_conv * 1.1\n",
    "\n",
    "# Norm\n",
    "mu_a = a_conv / a_total \n",
    "stderrmean_a = np.sqrt(mu_a * (1 - mu_a)) / np.sqrt(a_total)\n",
    "print(mu_a, stderrmean_a)\n",
    "\n",
    "mu_b = b_conv / b_total \n",
    "stderrmean_b = np.sqrt(mu_b * (1 - mu_b)) / np.sqrt(b_total)\n",
    "print(mu_b, stderrmean_b)\n",
    "\n",
    "mu_diff = mu_b - mu_a\n",
    "stderrmean_diff = np.sqrt(stderrmean_a**2 + stderrmean_b**2)\n",
    "print(mu_diff, stderrmean_diff)\n",
    "\n",
    "fig.add_trace(go.Scatter(x=x, y=stats.norm.pdf(x, loc=mu_diff, scale=stderrmean_diff), mode='lines',\n",
    "                         name=f\"{a_total}\"))\n",
    "fig.add_vline(x=0)\n",
    "fig.update_layout(title='P(B-A)',\n",
    "                  xaxis_title='p',\n",
    "                  yaxis_title='Prob Density',\n",
    "                  hovermode=\"x\",\n",
    "                  height=550)\n",
    "\n",
    "fig.show()\n",
    "\n",
    "\n",
    "def pval(prior_conv, exp_effect, N):\n",
    "    a_total = N\n",
    "    a_conv = a_total * prior_conv\n",
    "    b_total = a_total\n",
    "    b_conv = b_total * prior_conv * exp_effect\n",
    "    mu_a = a_conv / a_total \n",
    "    stderrmean_a = np.sqrt(mu_a * (1 - mu_a)) / np.sqrt(a_total)\n",
    "    mu_b = b_conv / b_total \n",
    "    stderrmean_b = np.sqrt(mu_b * (1 - mu_b)) / np.sqrt(b_total)\n",
    "    mu_diff = mu_b - mu_a\n",
    "    stderrmean_diff = np.sqrt(stderrmean_a**2 + stderrmean_b**2)\n",
    "    if mu_diff > 0:\n",
    "        pval = stats.norm.cdf(x=0, loc=mu_diff, scale=stderrmean_diff)\n",
    "    else:\n",
    "        pval = None\n",
    "    return pval\n",
    "\n",
    "N = np.linspace(100, 10000)\n",
    "y = np.array([pval(prior_conv, 1.05, Ni) for Ni in N])\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=N, y=y, mode='lines'))\n",
    "fig.add_hline(y=0.05)\n",
    "fig.update_layout(title='p-val',\n",
    "                  xaxis_title='N',\n",
    "                  yaxis_title='p-val',\n",
    "                  hovermode=\"x\",\n",
    "                  height=550)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ссылки"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотреть:\n",
    "\n",
    "J. Kruschke  \n",
    "https://www.medicine.mcgill.ca/epidemiology/Joseph/courses/EPIB-682/Kruschke2013.pdf  \n",
    "https://www.youtube.com/watch?v=fhw1j1Ru2i0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
