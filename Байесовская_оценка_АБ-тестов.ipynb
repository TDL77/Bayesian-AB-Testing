{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b087aaa2",
   "metadata": {},
   "source": [
    "# Байесовская оценка А/Б-тестов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c84793b",
   "metadata": {},
   "source": [
    "*Сформулированы критерии оценки А/Б-тестов. Рассмотрены примеры байесовского моделирования. Байесовская оценка применена к сравнению конверсий, средних с помощью центральной предельной теоремы, выручки на пользователя, заказов на платящего, средних чеков.*\n",
    "\n",
    "&nbsp; &nbsp; *- [А/Б тесты](#А/Б-тесты)*  \n",
    "&nbsp; &nbsp; *- [Байесовское моделирование](#Байесовское-моделирование)*  \n",
    "&nbsp; &nbsp; *- [Конверсии](#Конверсии)*   \n",
    "&nbsp; &nbsp; *- [Средние](#Средние)*    \n",
    "&nbsp; &nbsp; *- [Выручка на пользователя](#Выручка-на-пользователя)*  \n",
    "&nbsp; &nbsp; *- [Заказы на платящего](#Заказы-на-платящего)*  \n",
    "&nbsp; &nbsp; *- [Средний чек](#Средний-чек)*  \n",
    "&nbsp; &nbsp; *- [Заключение](#Заключение)*  \n",
    "&nbsp; &nbsp; *- [Ссылки](#Ссылки)*  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e08f80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5e4c34",
   "metadata": {},
   "source": [
    "# А/Б тесты  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9b0098",
   "metadata": {},
   "source": [
    "В мобильные приложения и веб-сервисы вносят изменения для улучшения ключевых метрик - выручки, конверсий, вовлеченности и др. Например, при повышении цен конверсия в покупку скорее всего снизится, но итоговая прибыль может вырасти.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208d8e59",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"./figs/experiment_versions_ru.png\" alt=\"experiment_versions\" width=\"400\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cce8639",
   "metadata": {},
   "source": [
    "Точный эффект от изменений непредсказуем. Новая функциональность может ухудшать продукт. По оценкам, только около трети реализованных изменений приводят к положительным результатам [[MicroExp](https://www.microsoft.com/en-us/research/publication/online-experimentation-at-microsoft/)]. Поэтому необходимо измерять эффект от новой функциональности."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c98fdba",
   "metadata": {},
   "source": [
    "После запуска эффект не всегда может быть виден сразу (см. рисунок ниже). Если функциональность не вызвала резких изменений, ее влияние может быть незаметно на фоне случайных колебаний метрик. Кроме того, могут произойти изменения в других частях продукта, привлекаемом трафике или общей активности аудитории, которые также повлияют на целевую метрику. Например, запуск рекламной акции. Поэтому изменения метрик после релиза не всегда можно объяснять именно новой функциональностью."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a5468b",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"./figs/effect_size.png\" alt=\"effect_size\"  width=\"900\"/>\n",
    "<em>Возможный эффект от релиза. Резкие изменения могут быть заметны сразу. Падение на 30%. Слабые изменения могуть быть незаметны на фоне колебаний метрик. Улучшение на 3% эффект неочевиден.</em>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7b24bb",
   "metadata": {},
   "source": [
    "Одним из способов оценки новой функциональности является проведение А/Б-теста.\n",
    "В этом подходе запускают версию без изменений и измененные варианты сервиса параллельно, распределяют пользователей между этими вариантами и сравнивают интересующие метрики. Параллельный запуск версий позволяет снизить различия из-за факторов, не связанных с тестируемыми изменениями.\n",
    "\n",
    "В проведении АБ-тестов есть много нюансов [[TrustworthyAB]((https://www.amazon.com/gp/product/B0845Y3DJV)].\n",
    "Но общая схема примерно следующая (см. рисунок). При попадании на сайт или в приложение пользователь случайным образом определяется в одну из экспериментальных групп. В каждой группе собираются данные и вычисляются интересующие метрики.\n",
    "Полученные значения сравниваются между собой. Эксперимент прекращается, если становится понятно, что одна из групп лидирует (иногда - при прохождении определенного количества пользователей, по истечении определенного времени или нецелесообразности дальнейшего проведения). Принимается решение о дальнейших действиях - как правило, о выборе одного из вариантов для всех пользователей."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b583dcb1",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"./figs/ab_test.png\" alt=\"ab_test\" width=\"800\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796a9520",
   "metadata": {},
   "source": [
    "Причинная диаграмма [[CausalDAG](https://en.wikipedia.org/wiki/Causal_graph)].  \n",
    "Метрики определяются действиями пользователей в приложении. Действия зависят от функциональности приложения (например, какие тарифные планы доступны). Действия разных сегментов пользователей будут отличаться (новые, ранее покупавшие). Также действия будут зависеть от внешних факторов (например, сезонность).  \n",
    "\n",
    "В А/Б тесте версии запускают одновременно и случайно делят пользователей между версиями. При одновременном запуске влияние внешних факторов можно считать одинаковым. Влияние внешних факторов остается, но при сравнении данных из обеих групп за одинаковый период можно считать, что влияение на обе группы одинаково. Также пользователи делятся между группами случайно, можно считать состав сегментов одинаковым. В итоге разница метрик между группами объясняется разницей функциональности приложения.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89384924",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"./figs/causal.png\" alt=\"causal\" width=\"600\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485de2fb",
   "metadata": {},
   "source": [
    "По итогам эксперимента нужно выбрать \"лучшую\" группу и оценить эффект. Для этого понадобится оценить целевые метрики в каждой группе. Точные значения метрик в каждой группе остаются неизвестыми. Эти оценки - случайные величины. Поэтому нужно оценить распределения возможных значений метрик. По мере увеличения количества данных - т.е. по мере роста количества пользователей, принявших участие в эксперименте - неопределенность в оценках снижается. Еще один вопрос - сколько должен продолжаться эксперимент?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0695ea4",
   "metadata": {},
   "source": [
    "<div style=\"font-size: 20px\">  \n",
    "\n",
    "Вопросы А/Б-тестов:\n",
    "\n",
    "<ul>\n",
    "<li>Какая группа лучше и насколько?</li> \n",
    "<li>Сколько должен продолжаться эксперимент?</li>\n",
    "</ul>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e5e953e",
   "metadata": {},
   "source": [
    "Например, в имеющейся выборке среднее значение метрики в группе A равно a_mean, а в группе B - b_mean. При выборе варианта A для всех пользователей среднее значение метрики с вероятностью 90% будет находится в диапазоне (a_min, a_max), при выборе варианта B - с вероятностью 90% в диапазоне (b_min, b_max). По имеющимся данным группа B окажется лучше группы A с вероятностью 70%. Ожидаемое значение B/A = 1.05. Чтобы говорить о p(B) > p(A) с уверенностью 90% нужно еще около N пользователей, что займет d дней.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a02bdd78",
   "metadata": {},
   "source": [
    "Вероятность здесь и далее понимается в субъективном смысле - как мера уверенности в определенном исходе процесса с несколькими возможными исходами [[SubjProb](https://en.wikipedia.org/wiki/Probability_interpretations#Subjectivism), [UU](https://www.amazon.co.uk/Understanding-Uncertainty-Wiley-Probability-Statistics-ebook/dp/B00GYVM33Q)]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bec192",
   "metadata": {},
   "source": [
    "Картина А/Б тестов.\n",
    "\n",
    "Значения метрик в группах определяются функциональностью приложения.  \n",
    "Точные значения неизвестны.  \n",
    "На основе собранных в эксперименте данных можно строить оценки точных значений.  \n",
    "Пока данных мало, неопределенность в оценках большая.  \n",
    "По мере набора данных точность увеличивается.  \n",
    "С увеличением точности оценок растет уверенность, какая из групп лучше.  \n",
    "Когда уверенность достигает достаточного значения, эксперимент можно останавливать.  \n",
    "\n",
    "Байесовское моделирование позволяет оценить точное значение метрики по сэмлу и вероятность метрики в одной группе больше другой P(B>A)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef663589",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"./figs/ab_dynamics.png\" alt=\"ab_dynamics\" width=\"400\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd317e22",
   "metadata": {},
   "source": [
    "# Байесовское моделирование"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559d2275",
   "metadata": {},
   "source": [
    "> Вам подарили подарок. Подарок в упаковке, и не ясно, что это. \n",
    "До того, как его развернуть, вы пытаетесь угадать, что внутри."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65ac1cc",
   "metadata": {},
   "source": [
    "Эти рассуждения можно сделать количественными.  \n",
    "Нужно предположить несколько вариантов подарка и для каждого оценить вероятность $P(подарок | упаковка)$. \n",
    "Это делается с помощью соотношения Байеса.\n",
    "\n",
    "$$\n",
    "P(B | A) = \\frac{P(A | B) P(B)}{P(A)}\n",
    "$$\n",
    "\n",
    "В примере\n",
    "\n",
    "$$\n",
    "P(подарок_i | упаковка) = \\frac{P(упаковка|подарок_i) P(подарок_i)}{P(упаковка)} = \\frac{P(упаковка|подарок_i) P(подарок_i)}{\\sum_i P(упаковка|подарок_i) P(подарок_i)}\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907e29a9",
   "metadata": {},
   "source": [
    "На этом примере видны основные этапы байесовского моделирования.  \n",
    "Есть данные. Есть гипотезы, объясняющие данные.  \n",
    "Для выбора одной из гипотез нужно посчитать вероятности получить данные в рамках гипотез - правдоподобия.  \n",
    "Также нужны априорные вероятности каждой гипотезы.  \n",
    "При комбинировании априорной вероятности гипотезы и вероятности получить данные в рамках гипотезы можно получить вероятность гипотезы при условии данных.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68672877",
   "metadata": {},
   "source": [
    "> На страницу зашло 1000 человек, 100 из них нажали кнопку \"Продолжить\". Как выглядит распределение возможных значений конверсии? Вероятность конверсии каждого пользователя можно считать одинаковой, все возможные априорные значения конверсии равновероятными. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44d286c",
   "metadata": {},
   "source": [
    "Вероятность получить данные\n",
    "$$\n",
    "P(100/1000; \\theta) = Binom(100/1000; \\theta) = C^{100}_{1000} \\theta^{100} (1 - \\theta)^{1000-100}\n",
    "$$\n",
    "\n",
    "Плотность вероятности конверсий\n",
    "$$\n",
    "P(\\theta; 100/1000) \n",
    "= \\frac{P(100/1000; \\theta) P(\\theta)}{P(100/1000)}\n",
    "= \\frac{P(100/1000; \\theta) P(\\theta)}{\\int d \\theta P(100/1000; \\theta) P(\\theta)}\n",
    "$$\n",
    "\n",
    "$P(\\theta)$ равномерно $P(\\theta) = \\mbox{Unif}(0, 1) = 1$\n",
    "\n",
    "$$\n",
    "P(\\theta; 100/1000) \n",
    "= \\frac{\\theta^{100} (1 - \\theta)^{900}}{\\int d \\theta (1 - \\theta)^{900} \\theta^{100} }\n",
    "\\sim \\theta^{100} (1 - \\theta)^{900}\n",
    "= Beta(101, 901)\n",
    "$$\n",
    "\n",
    "График "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d072080",
   "metadata": {},
   "outputs": [],
   "source": [
    "ns = 100\n",
    "ntotal = 1000\n",
    "\n",
    "p_samp = ns / ntotal\n",
    "p_dist = stats.beta(a=ns+1, b=ntotal-ns+1)\n",
    "\n",
    "x = np.linspace(0, 1, 1000)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=p_dist.pdf(x), line_color='black', name='p dist'))\n",
    "fig.add_trace(go.Scatter(x=[p_samp, p_samp], y=[0, max(p_dist.pdf(x))], \n",
    "                         line_color='black', mode='lines', line_dash='dash', name='p sample'))\n",
    "fig.update_layout(title='Posterior Dist',\n",
    "                  xaxis_title='p',\n",
    "                  yaxis_title='Prob Density',\n",
    "                  xaxis_range=[0, 1],\n",
    "                  hovermode=\"x\",\n",
    "                  height=500)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2edc81",
   "metadata": {},
   "source": [
    "> На версию А страницы веб-сайта зашло 1000 человек, 100 нажали кнопку \"Продолжить\". На версию Б зашло 1000 человек, 110 нажали кнопку продолжить. С какой вероятностью конверсия страницы Б выше страницы А?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009c9229",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0d3715ce",
   "metadata": {},
   "source": [
    "Для расчета $P(model|data)$ используется связь с $P(data|model)$ - вероятностью наблюдения данных $data$ в рамках выбранной модели $model$. Связь выражается соотношением Байеса:\n",
    "\n",
    "$$\n",
    "P(model | data) = \\frac{ P(data | model) P(model) }{P(data)} .\n",
    "$$\n",
    "\n",
    "Используется следующая терминология:  \n",
    "$P(model | data)$ - апостериорное распределение вероятности,  \n",
    "$P(data | model)$ - функция правдоподобия,  \n",
    "$P(model)$ - априорное распределение вероятности,  \n",
    "$P(data)$ не имеет специального названия.  \n",
    "\n",
    "Обычно форму модели фиксируют. Меняют только параметры.  \n",
    "\n",
    "Последовательность действий при использовании байесовского подхода следующая (см. также рис. ниже).  \n",
    "Выбирается набор возможных моделей $model$ (или форма модели и область параметров для нее).  \n",
    "Для каждого набора параметров задается априорная вероятность $P(model)$.  \n",
    "Вычисляется функция правдоподобия $P(data|model)$ - вероятность получить данные в рамках выбранной модели.    \n",
    "Вычисляется апостериорная вероятность $P(model|data)$.  \n",
    "Анализируются свойства моделей и постериорных распределений.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e20d872",
   "metadata": {},
   "source": [
    "# Конверсии"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325e7da1",
   "metadata": {},
   "source": [
    "Функция правдоподобия задается биномиальным распределением.  \n",
    "\n",
    "Априорное распределение конверсий удобно задать бета-распределением. Без учета нормировочных коэффициентов зависимость от $p$ $\\mbox{Beta}(p; \\alpha, \\beta) \\propto p^{\\alpha-1}(1-p)^{\\beta-1}$. Эта зависимость сохранится для произведения правдоподобия на априорное распределение. Априорные распределения с таким свойством называют сопряженными априорными распределениями.  \n",
    "\n",
    "При $\\alpha=1, \\beta=1$ бета-распределение совпадает с однородным - можно выбирать эти значения как стартовые.   \n",
    "Либо можно подобрать на основе ожидаемого эффекта."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c61b53d",
   "metadata": {},
   "source": [
    "$$\n",
    "P(model | data) \\propto P(data | model) P(model)\n",
    "$$\n",
    "\n",
    "$$\n",
    "P(data | model) = P(n_s | p, N) \\sim \\mbox{Binom}(p, N) = C_{N}^{n_s} p^{n_s} (1-p)^{N-n_s}\n",
    "$$\n",
    "\n",
    "$$\n",
    "P(model) = P(p) \\sim \\mbox{Beta}(p; \\alpha, \\beta) = \n",
    "\\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\alpha) \\Gamma(\\beta)} p^{\\alpha-1}(1-p)^{\\beta-1}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "P(model | data) & = P(p | n_s)\n",
    "\\\\\n",
    "& \\propto \\mbox{Binom}(p, N) \\mbox{Beta}(p; \\alpha, \\beta)\n",
    "\\\\\n",
    "& \\propto C_{N}^{n_s} p^{n_s} (1-p)^{N-n_s}\n",
    "\\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\alpha) \\Gamma(\\beta)} p^{\\alpha-1}(1-p)^{\\beta-1}\n",
    "\\\\\n",
    "& \\propto p^{n_s + \\alpha - 1} (1-p)^{N - n_s + \\beta - 1}\n",
    "\\\\\n",
    "& = \\mbox{Beta}(p; \\alpha + n_s, \\beta + N - n_s)\n",
    "\\end{split}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4060da4a",
   "metadata": {},
   "source": [
    "Примеры бета-распределения на графике ниже [[BetaDist](https://en.wikipedia.org/wiki/Beta_distribution), [SciPyBeta](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.beta.html)].\n",
    "При $\\alpha = 1, \\beta=1$ распределение однородное.  \n",
    "Максимум в точке $p = (\\alpha-1) / (\\alpha + \\beta - 2)$. При увеличении $\\alpha$ и $\\beta$ распределение сужается.  \n",
    "В пределе совпадает с нормальным.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bd8a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 1, 1000)\n",
    "fig = go.Figure()\n",
    "a, b = 1, 1\n",
    "fig.add_trace(go.Scatter(x=x, y=stats.beta.pdf(x, a=a, b=b), \n",
    "                             mode='lines', line_color='black', line_dash='dash',\n",
    "                             name=f'a={a}, b={b}'))\n",
    "a, b = 1, 5\n",
    "fig.add_trace(go.Scatter(x=x, y=stats.beta.pdf(x, a=a, b=b), \n",
    "                             mode='lines', line_color='black', line_dash='solid',\n",
    "                             name=f'a={a}, b={b}'))\n",
    "a, b = 3, 5\n",
    "fig.add_trace(go.Scatter(x=x, y=stats.beta.pdf(x, a=a, b=b), \n",
    "                             mode='lines', line_color='black', line_dash='solid',\n",
    "                             name=f'a={a}, b={b}'))\n",
    "a, b = 25, 30\n",
    "fig.add_trace(go.Scatter(x=x, y=stats.beta.pdf(x, a=a, b=b), \n",
    "                             mode='lines', line_color='black', line_dash='solid',\n",
    "                             name=f'a={a}, b={b}'))\n",
    "a, b = 150, 50\n",
    "fig.add_trace(go.Scatter(x=x, y=stats.beta.pdf(x, a=a, b=b), \n",
    "                             mode='lines', line_color='black', line_dash='solid',\n",
    "                             name=f'a={a}, b={b}')) \n",
    "fig.add_trace(go.Scatter(\n",
    "    x=[0.98, 0.08, 0.32, 0.55, 0.87],\n",
    "    y=[1.35, 5.00, 2.80, 6.20, 12.0],\n",
    "    mode=\"text\",\n",
    "    name=None,\n",
    "    showlegend=False,\n",
    "    text=[\"a=1, b=1\", \"a=1, b=5\", \"a=3, b=5\", \"a=25, b=30\", \"a=150, b=50\"],\n",
    "    textposition=\"top left\"\n",
    "))\n",
    "fig.update_layout(title='Бета-распределение Beta(a, b)',\n",
    "                  xaxis_title='x',\n",
    "                  yaxis_title='Плотность вероятности',\n",
    "                  showlegend=False,\n",
    "                  xaxis_range=[0, 1],\n",
    "                  height=550)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7918681",
   "metadata": {},
   "source": [
    "Оценка параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e25350",
   "metadata": {},
   "outputs": [],
   "source": [
    "def posterior_dist_binom(ns, ntotal, a_prior=1, b_prior=1):\n",
    "    a = a_prior + ns\n",
    "    b = b_prior + (ntotal - ns) \n",
    "    return stats.beta(a=a, b=b)\n",
    "    \n",
    "def posterior_binom_approx_95pdi(post_dist):\n",
    "    lower = post_dist.ppf(0.025)\n",
    "    upper = post_dist.ppf(0.975)\n",
    "    return lower, upper\n",
    "\n",
    "def prob_pb_gt_pa(post_dist_A, post_dist_B, post_samp=100_000):\n",
    "    sa = post_dist_A.rvs(size=post_samp)\n",
    "    sb = post_dist_B.rvs(size=post_samp)\n",
    "    b_gt_a = np.sum(sb > sa)\n",
    "    return b_gt_a / post_samp\n",
    "\n",
    "p = 0.1\n",
    "nsample = 1000\n",
    "\n",
    "exact_dist = stats.bernoulli(p=p)\n",
    "data = exact_dist.rvs(nsample)\n",
    "\n",
    "post_dist = posterior_dist_binom(ns=np.sum(data), ntotal=len(data))\n",
    "\n",
    "x = np.linspace(0, 1, 1000)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=post_dist.pdf(x), line_color='black', name='Апостериорное'))\n",
    "fig.add_trace(go.Scatter(x=[np.sum(data)/len(data), np.sum(data)/len(data)], y=[0, max(post_dist.pdf(x))], \n",
    "                         line_color='black', mode='lines', line_dash='dash', name='Среднее в выборке'))\n",
    "fig.add_trace(go.Scatter(x=[exact_dist.mean(), exact_dist.mean()], y=[0, max(post_dist.pdf(x))*1.05], \n",
    "                         line_color='red', mode='lines', line_dash='dash', name='Точное p'))\n",
    "fig.update_layout(title='Апостериорное распределение',\n",
    "                  xaxis_title='p',\n",
    "                  yaxis_title='Плотность вероятности',\n",
    "                  xaxis_range=[0, 1],\n",
    "                  hovermode=\"x\",\n",
    "                  height=500)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487e3d75",
   "metadata": {},
   "source": [
    "2 группы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33eb7827",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_A = 0.1\n",
    "p_B = p_A * 1.05\n",
    "nsample = 1000\n",
    "\n",
    "exact_dist_A = stats.bernoulli(p=p_A)\n",
    "exact_dist_B = stats.bernoulli(p=p_B)\n",
    "data_A = exact_dist_A.rvs(nsample)\n",
    "data_B = exact_dist_B.rvs(nsample)\n",
    "\n",
    "post_dist_A = posterior_dist_binom(ns=np.sum(data_A), ntotal=len(data_A))\n",
    "post_dist_B = posterior_dist_binom(ns=np.sum(data_B), ntotal=len(data_B))\n",
    "\n",
    "x = np.linspace(0, 1, 1000)\n",
    "fig = go.Figure()\n",
    "#fig.add_vline(x=exact_dist.mean(), line_dash='dash', name='Exact')\n",
    "fig.add_trace(go.Scatter(x=x, y=post_dist_A.pdf(x), line_color='black', name='A'))\n",
    "fig.add_trace(go.Scatter(x=x, y=post_dist_B.pdf(x), line_color='black', opacity=0.2, name='B'))\n",
    "fig.add_trace(go.Scatter(x=[exact_dist_A.mean(), exact_dist_A.mean()], y=[0, max(post_dist_A.pdf(x))*1.05], \n",
    "                         mode='lines', line_dash='dash', line_color='black', name='Точное A'))\n",
    "fig.add_trace(go.Scatter(x=[exact_dist_B.mean(), exact_dist_B.mean()], y=[0, max(post_dist_A.pdf(x))*1.05], \n",
    "                         mode='lines', line_dash='dash', line_color='black', opacity=0.2, name='Точное B'))\n",
    "fig.update_layout(title='Апостериорные распределения',\n",
    "                  xaxis_title='p',\n",
    "                  yaxis_title='Плотность вероятности',\n",
    "                  xaxis_range=[p_A/2, p_A*2],\n",
    "                  hovermode=\"x\",\n",
    "                  height=500)\n",
    "fig.show()\n",
    "\n",
    "print(f'P(pB > pA): {prob_pb_gt_pa(post_dist_A, post_dist_B)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a5abff",
   "metadata": {},
   "source": [
    "Динамика по мере набора данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aca6765",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8a6e39c0",
   "metadata": {},
   "source": [
    "Количество правильно угаданных вариантов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874dbdb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cmp = pd.DataFrame(columns=['A', 'B', 'best_exact', 'exp_samp_size', 'A_exp', 'B_exp', 'best_exp', 'p_best'])\n",
    "\n",
    "p = 0.1\n",
    "nexps = 100\n",
    "cmp['A'] = [p] * nexps\n",
    "cmp['B'] = p * (1 + stats.uniform.rvs(loc=-0.05, scale=0.1, size=nexps))\n",
    "cmp['best_exact'] = cmp.apply(lambda r: 'B' if r['B'] > r['A'] else 'A', axis=1)\n",
    "\n",
    "prob_stop = 0.95\n",
    "for i in range(nexps):\n",
    "    pA = cmp.at[i, 'A']\n",
    "    pB = cmp.at[i, 'B']\n",
    "    exact_dist_A = stats.bernoulli(p=pA)\n",
    "    exact_dist_B = stats.bernoulli(p=pB)\n",
    "    n_samp_max = 10_000_000\n",
    "    n_samp_total = 0\n",
    "    n_samp_step = 10_000\n",
    "    ns_A = 0\n",
    "    ns_B = 0\n",
    "    while n_samp_total < n_samp_max:\n",
    "        dA = exact_dist_A.rvs(n_samp_step)\n",
    "        dB = exact_dist_B.rvs(n_samp_step)\n",
    "        n_samp_total += n_samp_step\n",
    "        ns_A = ns_A + np.sum(dA)\n",
    "        ns_B = ns_B + np.sum(dB)\n",
    "        post_dist_A = posterior_dist_binom(ns=ns_A, ntotal=n_samp_total)\n",
    "        post_dist_B = posterior_dist_binom(ns=ns_B, ntotal=n_samp_total)\n",
    "        pb_gt_pa = prob_pb_gt_pa(post_dist_A, post_dist_B)\n",
    "        best_gr = 'B' if pb_gt_pa >= prob_stop else 'A' if (1 - pb_gt_pa) >= prob_stop else None\n",
    "        if best_gr:\n",
    "            cmp.at[i, 'A_exp'] = post_dist_A.mean()\n",
    "            cmp.at[i, 'B_exp'] = post_dist_B.mean()\n",
    "            cmp.at[i, 'exp_samp_size'] = n_samp_total\n",
    "            cmp.at[i, 'best_exp'] = best_gr\n",
    "            cmp.at[i, 'p_best'] = pb_gt_pa\n",
    "            break\n",
    "    print(f'done {i}: {n_samp_total}, {best_gr}, {pb_gt_pa}')\n",
    "\n",
    "cmp['correct'] = cmp['best_exact'] == cmp['best_exp']\n",
    "display(cmp.head(10))\n",
    "cor_guess = np.sum(cmp['correct'])\n",
    "print(f\"Nexp: {nexps}, Correct Guesses: {cor_guess}, Accuracy: {cor_guess / nexps}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58e0dfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(x=cmp['exp_samp_size'], histnorm='probability', name='Groups Sample Size', \n",
    "                           marker_color='black', nbinsx=100))\n",
    "fig.update_layout(title='Размер выборки',\n",
    "                  xaxis_title='Точек в группе',\n",
    "                  yaxis_title='Доля экспериментов',\n",
    "                  hovermode=\"x\",\n",
    "                  height=500)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29f2a0f",
   "metadata": {},
   "source": [
    "# Средние"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9a0af2",
   "metadata": {},
   "source": [
    "Байесовский подход [[SGBS](https://www.amazon.co.uk/Students-Guide-Bayesian-Statistics/dp/1473916364), [SR](https://www.amazon.co.uk/Statistical-Rethinking-Bayesian-Examples-Chapman/dp/036713991X/ref=sr_1_1)] требует построения моделей распределений сравниваемых величин. Выбор модели - неочевидный вопрос. Есть отдельные модели, получившие распространение - например, Buy Till You Die [[BTYD](https://en.wikipedia.org/wiki/Buy_Till_you_Die)] для количества покупок клиента за все время использования сервиса. Но универсальных моделей нет. Это создает сложности.\n",
    "\n",
    "При этом для многих величин не всегда нужно знать все распределение. Можно ограничиться сравнением средних:\n",
    "средней выручкой на пользователя, средней длительностью просмотра и т.д. Для средних значений часто применима центральная предельная теорема. Можно приближенно считать, что средние значения в выборках из распределения будут распределены нормально. Причем это не зависит от формы исходного распределения. Центральная предельная теорема позволяет при сравнении средних использовать нормальное распределение в качестве функции правдоподобия.\n",
    "\n",
    "Есть несколько центральных предельных теорем [[CLT](https://en.wikipedia.org/wiki/Central_limit_theorem)].\n",
    "Одна из возможных формулировок следующая. Пусть есть последовательность независимых одинаково распределенных случайных величин $X_1, X_2, \\dots, X_n, \\dots$ с конечными математическим ожиданием $\\mu$ и дисперсией $\\sigma^2$. Пусть $\\bar{X}_n = \\frac{1}{n} \\sum_{i=1}^{n} X_i$ их выборочное среднее. Тогда при $n$, стремящемся к бесконечности, распределение центрированных и масштабированных выборочных средних сходится к нормальному распределению [[NormDist](https://en.wikipedia.org/wiki/Normal_distribution), [SciPyNorm](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.norm.html?highlight=norm)] со средним значением 0 и дисперсией 1\n",
    "\n",
    "$$\n",
    "P \\left( \\frac{\\bar{X}_n - \\mu}{\\sigma / \\sqrt{n}} = x \\right) \\to N(x; 0, 1), \\quad n \\to \\infty,\n",
    "\\\\\n",
    "N(x ; \\mu, \\sigma^2) = \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} e^{- \\frac{(x-\\mu)^2}{2 \\sigma^2} } .\n",
    "$$\n",
    "\n",
    "Сходимость понимается как сходимость по распределению [[RandVarsConv](https://en.wikipedia.org/wiki/Convergence_of_random_variables#Convergence_in_distribution)].\n",
    "\n",
    "Неформально этот результат можно применить следующим образом. Если взять произвольное распределение со средним значением $\\mu$ и диспресий $\\sigma^2$, начать выбирать из него сэмплы длины $n$ и считать среднее в каждом сэмпле, то средние значения сэмплов будут распределены приблизительно нормально $N(\\mu, \\sigma^2/n)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4455a8b2",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"./figs/central_limit_theorem.png\" alt=\"central_limit_theorem\" width=\"600\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62f84cf",
   "metadata": {},
   "source": [
    "Центральная предельная теорема говорит о сходимости к нормальному распределению центрированных и масштабированных выборочных средних $\\bar{X}_n$ при стремлении $n$ к бесконечности. Для фиксированного конечного числа $n$ нормальное распределение не гарантируется. При этом есть теоремы, дающие оценку отличия распределения суммы конечного количества случайных величин от нормального - см. [[BerryEsseenTheorem](https://en.wikipedia.org/wiki/Berry%E2%80%93Esseen_theorem)]. Отличие зависит как от количества слагаемых, так и от параметров распределения. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb4bec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1\n",
    "sample_len = 100\n",
    "n_samples = 1000\n",
    "\n",
    "exact_dist = stats.gamma(a=a)\n",
    "samp = exact_dist.rvs(size=(n_samples, sample_len))\n",
    "means = np.array([x.mean() for x in samp])\n",
    "clt_mu = exact_dist.mean()\n",
    "clt_stdev = exact_dist.std() / np.sqrt(sample_len)\n",
    "means_stdev = means.std()\n",
    "\n",
    "x = np.linspace(0, 10, 1000)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=exact_dist.pdf(x), \n",
    "                         mode='lines', line_color='black', line_dash='dash', name='Исходное распределение'))\n",
    "fig.add_trace(go.Histogram(x=np.concatenate(samp), histnorm='probability density', name='Выборка', nbinsx=500,\n",
    "                           marker_color='black', opacity=0.3))\n",
    "#fig.add_vline(exact_dist.mean(), name='Точное среднее')\n",
    "fig.add_trace(go.Scatter(x=x, y=stats.norm.pdf(x, loc=clt_mu, scale=clt_stdev), \n",
    "                         mode='lines', line_color='black', line_dash='solid', name='ЦПТ-распределение'))\n",
    "fig.add_trace(go.Histogram(x=means, histnorm='probability density', name='Выборочные средние', nbinsx=50,\n",
    "                           marker_color='green', opacity=0.5))\n",
    "fig.update_layout(title='Выборочные средние',\n",
    "                  xaxis_title='x',\n",
    "                  yaxis_title='Плотность вероятности',\n",
    "                  barmode='overlay',\n",
    "                  hovermode=\"x\",\n",
    "                  height=550)\n",
    "fig.update_layout(xaxis_range=[0, 5])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61eb7b62",
   "metadata": {},
   "source": [
    "В приведенной формулировке центральная предельная теорема требует существования конечных среднего и дисперсии у исходного распределения. Примерами распределений, для которых эти свойства могут не выполнятся, являются распределение Парето [[ParetoDist](https://en.wikipedia.org/wiki/Pareto_distribution), [SciPyPareto](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.pareto.html)] и близкое к нему распределение Ломакса [[LomaxDist](https://en.wikipedia.org/wiki/Lomax_distribution), [SciPyLomax](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.lomax.html)]. Плотность вероятности последнего имеет вид\n",
    "\n",
    "$$\n",
    "P(x; c) = \\frac{c}{(1 + x )^{c + 1}}, \\quad x \\ge 0, c > 0.\n",
    "$$\n",
    "\n",
    "При значениях параметра $c$ меньше или равном 2 дисперсия распределения Ломакса не является конечной. \n",
    "На графиках ниже приведена гистограмма средних в сэмплах и нормальное распределение с параметрами, равными среднему и дисперсии средних сэмплов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6847652f",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 1.7\n",
    "sample_len = 500\n",
    "n_samples = 1000\n",
    "\n",
    "exact_dist = stats.lomax(c=c)\n",
    "samp = exact_dist.rvs(size=(n_samples, sample_len))\n",
    "means = np.array([x.mean() for x in samp])\n",
    "clt_mu = exact_dist.mean()\n",
    "clt_stdev = exact_dist.std() / np.sqrt(sample_len)\n",
    "means_stdev = means.std()\n",
    "\n",
    "xaxis_max=10\n",
    "x = np.linspace(0, xaxis_max, 2000)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=exact_dist.pdf(x), \n",
    "                         mode='lines', line_color='black', line_dash='dash', name='Исходное распределение'))\n",
    "fig.add_trace(go.Histogram(x=np.concatenate(samp)[np.concatenate(samp) < xaxis_max], histnorm='probability density', \n",
    "                           name='Выборка', nbinsx=500,\n",
    "                           marker_color='black', opacity=0.3))\n",
    "#fig.add_vline(exact_dist.mean(), name='Точное среднее')\n",
    "fig.add_trace(go.Scatter(x=x, y=stats.norm.pdf(x, loc=clt_mu, scale=means_stdev), \n",
    "                         mode='lines', line_color='black', line_dash='solid', name='ЦПТ-подобное распределение'))\n",
    "fig.add_trace(go.Histogram(x=means, histnorm='probability density', name='Выборочные средние', nbinsx=150,\n",
    "                          marker_color='green', opacity=0.5))\n",
    "fig.update_layout(title='Выборочные средние',\n",
    "                  xaxis_title='x',\n",
    "                  yaxis_title='Плотность вероятности',\n",
    "                  barmode='overlay',\n",
    "                  hovermode=\"x\",\n",
    "                  xaxis_range=[0, xaxis_max],\n",
    "                  height=550)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84782c1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d09f0483",
   "metadata": {},
   "source": [
    "# Выручка на пользователя"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a346681e",
   "metadata": {},
   "source": [
    "# Заказы на платящего"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16c3c5a",
   "metadata": {},
   "source": [
    "Заказы пользователя дискретная величина $P_{заказы}(n)$, $n \\in 1, 2, \\dots$. Можно ожидать лог-нормальное или степенное распределение - Парето, распределение Ципфа [[ZipfDist](https://en.wikipedia.org/wiki/Zipf%27s_law#Formal_definition)] $P(n) \\propto n^{-s}$. Модель с меньшими ограничениями - свои вероятности $p_i$ под каждое количество заказов. Пусть масимальное количество заказов $N$ ограничено, $n_i$ - количество пользователей с $i=1, 2, \\dots, N$ заказами, $p_i$ - вероятность сделать $i$ заказов. Функция правдоподобия задается мультиномиальным распределением [[MultiDist](https://en.wikipedia.org/wiki/Multinomial_distribution)]\n",
    "\n",
    "$$\n",
    "P(data|model) = P(n_1, \\dots, n_N) = \\frac{(n_1 + \\dots + n_N)!}{n_{1}! \\dots n_{N}!} p_{1}^{n_{1}} \\dots p_{N}^{n_{N}} .\n",
    "$$\n",
    "\n",
    "Распределение Дирихле [[DrDist](https://en.wikipedia.org/wiki/Dirichlet_distribution)] будет сопряженным априорным распределением\n",
    "\n",
    "$$\n",
    "P(model) = \n",
    "Dir \\left( p_{1}, \\dots, p_{N}; \\alpha_{1}, \\dots, \\alpha_{N} \\right) = \n",
    "\\dfrac{1}{B( \\alpha_{1}, \\dots, \\alpha_{N} )} \\prod_{i=1}^{N} p_{i}^{\\alpha_{i}-1},\n",
    "\\qquad\n",
    "\\sum_{i=1}^{N} p_i = 1,\n",
    "\\qquad\n",
    "p_i \\in [0, 1], \n",
    "\\qquad\n",
    "B(\\alpha_{1}, \\dots, \\alpha_{N}) = \n",
    "\\frac{\\prod \\limits_{i=1}^{N} \\Gamma( \\alpha_{i} )}\n",
    "{\\Gamma \\left( \\sum \\limits_{i=1}^{N} \\alpha_{i} \\right)} .\n",
    "$$\n",
    "\n",
    "Апостериорное распределение \n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "P(model | data) \n",
    "& \\propto\n",
    "\\frac{(n_1 + \\dots + n_N)!}{n_{1}! \\dots n_{N}!} p_{1}^{n_{1}} \\dots p_{N}^{n_{N}}\n",
    "\\dfrac{1}{B(\\alpha_{1}, \\dots ,\\alpha_{N})} \\prod _{i=1}^{N} p_{i}^{\\alpha_{i}-1}\n",
    "\\\\\n",
    "& \\propto\n",
    "\\prod_{i=1}^{N} p_{i}^{n_{i} + \\alpha_{i} - 1}\n",
    "\\\\\n",
    "& =\n",
    "Dir \\left( p_{1}, \\dots, p_{N}; n_1 + \\alpha_{1}, \\dots, n_N + \\alpha_{N} \\right)\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "Маржинальными распределениями для каждого $p_i$ будут бета-распределения\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "f(p_i) = \n",
    "Beta( p_i; \\alpha_i, \\alpha_0 - \\alpha_i ),\n",
    "\\quad\n",
    "\\alpha_0 = \\sum_{i=1}^{N} \\alpha_i .\n",
    "\\end{split}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b73e2ef",
   "metadata": {},
   "source": [
    "Оценка параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5714d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_params_dr(N):\n",
    "    return np.ones(N)\n",
    "\n",
    "def posterior_params_dr(data, initial_pars):\n",
    "    u, c = np.unique(data, return_counts=True)\n",
    "    post_pars = np.copy(initial_pars)\n",
    "    for k, v in zip(u, c):\n",
    "        post_pars[k - 1] = post_pars[k - 1] + v\n",
    "    return post_pars\n",
    "\n",
    "def posterior_nords_rvs(params, nsamp):\n",
    "    nords = np.empty(nsamp)\n",
    "    probs = stats.dirichlet.rvs(alpha=params, size=nsamp)\n",
    "    for i, p in enumerate(probs):\n",
    "        nords[i] = np.argmax(stats.multinomial.rvs(n=1, p=p)) + 1\n",
    "    return nords\n",
    "\n",
    "def posterior_marginal_dist_pi(i, params):\n",
    "    imin = 1\n",
    "    p_i = stats.beta(a=params[i - imin], b=np.sum(params) - params[i - imin])\n",
    "    return p_i\n",
    "\n",
    "def posterior_pi_mean_95pdi(i, params):\n",
    "    p = posterior_marginal_dist_pi(i, params)\n",
    "    m = p.mean()\n",
    "    lower = p.ppf(0.025)\n",
    "    upper = p.ppf(0.975)\n",
    "    return m, lower, upper\n",
    "\n",
    "def posterior_nords_mean(params):\n",
    "    ex = 0\n",
    "    for i in range(1, len(params)+1):\n",
    "        m = posterior_marginal_dist_pi(i, params).mean()\n",
    "        ex += i * m\n",
    "    return ex\n",
    "\n",
    "Nmax = 30\n",
    "s = 1.5\n",
    "nsample = 1000\n",
    "\n",
    "exact_dist = stats.zipfian(a=s, n=Nmax)\n",
    "data = exact_dist.rvs(nsample)\n",
    "\n",
    "pars = initial_params_dr(Nmax)\n",
    "pars = posterior_params_dr(data, pars)\n",
    "\n",
    "post_samp = posterior_nords_rvs(pars, 100000)\n",
    "\n",
    "pi = [posterior_pi_mean_95pdi(i, pars) for i in range(1, Nmax+1)]\n",
    "\n",
    "x = np.arange(1, Nmax+1)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=exact_dist.pmf(x), name='Точное распределение Ципфа'))\n",
    "fig.add_trace(go.Histogram(x=data, histnorm='probability', name='Сэмпл', nbinsx=round(Nmax*2)))\n",
    "fig.add_trace(go.Histogram(x=post_samp, histnorm='probability', name='Апостериорное распределение', opacity=0.5, nbinsx=round(Nmax*2)))\n",
    "fig.add_trace(go.Scatter(x=x, \n",
    "                         y=[p[0] for p in pi],\n",
    "                         error_y=dict(type='data', symmetric=False, array=[p[2] - p[0] for p in pi], arrayminus=[p[0] - p[1] for p in pi]), \n",
    "                         name='$\\mbox{Оценки } p_i$',\n",
    "                         mode='markers'))\n",
    "fig.update_layout(title='Заказы на платящего',\n",
    "                  xaxis_title='$x$',\n",
    "                  yaxis_title='Вероятность',\n",
    "                  xaxis_range=[0, Nmax+1],\n",
    "                  hovermode=\"x\",\n",
    "                  barmode=\"group\",\n",
    "                  height=550)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8502fe",
   "metadata": {},
   "source": [
    "Сравнение двух групп"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6b5738",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_pb_gt_pa_postsamp(post_samp_a, post_samp_b):\n",
    "    if len(post_samp_a) != len(post_samp_b):\n",
    "        return None\n",
    "    b_gt_a = np.sum(post_samp_b > post_samp_a)\n",
    "    return b_gt_a / len(post_samp_a)\n",
    "\n",
    "Nmax = 30\n",
    "s_a = 2.7\n",
    "s_b = s_a * 1.03\n",
    "nsample = 3000\n",
    "\n",
    "exact_dist_a = stats.zipfian(a=s_a, n=Nmax)\n",
    "exact_dist_b = stats.zipfian(a=s_b, n=Nmax)\n",
    "data_a = exact_dist_a.rvs(nsample)\n",
    "data_b = exact_dist_b.rvs(nsample)\n",
    "\n",
    "pars_a = initial_params_dr(Nmax)\n",
    "pars_a = posterior_params_dr(data_a, pars_a)\n",
    "pars_b = initial_params_dr(Nmax)\n",
    "pars_b = posterior_params_dr(data_b, pars_b)\n",
    "\n",
    "post_samp_len = 100000\n",
    "post_samp_a = posterior_nords_rvs(pars_a, post_samp_len)\n",
    "post_samp_b = posterior_nords_rvs(pars_b, post_samp_len)\n",
    "\n",
    "pi_a = [posterior_pi_mean_95pdi(i, pars) for i in range(1, Nmax+1)]\n",
    "\n",
    "x = np.arange(1, Nmax+1)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=exact_dist_a.pmf(x), name='Точное распределение A'))\n",
    "fig.add_trace(go.Scatter(x=x, y=exact_dist_b.pmf(x), name='Точное распределение A'))\n",
    "fig.add_vline(x=exact_dist_a.mean())\n",
    "fig.add_vline(x=exact_dist_b.mean())\n",
    "fig.add_trace(go.Histogram(x=post_samp_a, histnorm='probability', name='Апостериорное A', opacity=0.5, nbinsx=round(Nmax*2)))\n",
    "fig.add_trace(go.Histogram(x=post_samp_b, histnorm='probability', name='Апостериорное B', opacity=0.5, nbinsx=round(Nmax*2)))\n",
    "# fig.add_trace(go.Scatter(x=x, \n",
    "#                          y=[p[0] for p in pi],\n",
    "#                          error_y=dict(type='data', symmetric=False, array=[p[2] - p[0] for p in pi], arrayminus=[p[0] - p[1] for p in pi]), \n",
    "#                          name='$\\mbox{Оценки } p_i$',\n",
    "#                          mode='markers'))\n",
    "fig.update_layout(title='Заказы на платящего',\n",
    "                  xaxis_title='$x$',\n",
    "                  yaxis_title='Вероятность',\n",
    "                  xaxis_range=[0, Nmax+1],\n",
    "                  hovermode=\"x\",\n",
    "                  barmode=\"group\",\n",
    "                  height=550)\n",
    "fig.show()\n",
    "\n",
    "print(f'E[n_ords] A:, {posterior_nords_mean(pars_a)}, B: {posterior_nords_mean(pars_b)}')\n",
    "print(f'P(pB > pA): {prob_pb_gt_pa_postsamp(post_samp_a, post_samp_b)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e72371d",
   "metadata": {},
   "source": [
    "Количество правильно угаданных вариантов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec4fbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmp = pd.DataFrame(columns=['A', 'B', 'best_exact', 'exp_samp_size', 'A_exp', 'B_exp', 'best_exp', 'p_best'])\n",
    "\n",
    "s = 2.7\n",
    "Nmax=30\n",
    "nexps = 100\n",
    "cmp['A'] = [s] * nexps\n",
    "cmp['B'] = s * (1 + stats.uniform.rvs(loc=-0.05, scale=0.1, size=nexps))\n",
    "cmp['best_exact'] = cmp.apply(lambda r: 'B' if r['B'] < r['A'] else 'A', axis=1)\n",
    "\n",
    "prob_stop = 0.90\n",
    "for i in range(nexps):\n",
    "    s_a = cmp.at[i, 'A']\n",
    "    s_b = cmp.at[i, 'B']\n",
    "    exact_dist_a = stats.zipfian(a=s_a, n=Nmax)\n",
    "    exact_dist_b = stats.zipfian(a=s_b, n=Nmax)\n",
    "    n_samp_max = 200000\n",
    "    n_samp_total = 0\n",
    "    n_samp_step = 10000\n",
    "    pars_a = initial_params_dr(Nmax)\n",
    "    pars_b = initial_params_dr(Nmax)\n",
    "    while n_samp_total < n_samp_max:\n",
    "        data_a = exact_dist_a.rvs(n_samp_step)\n",
    "        data_b = exact_dist_b.rvs(n_samp_step)\n",
    "        n_samp_total += n_samp_step\n",
    "        pars_a = posterior_params_dr(data_a, pars_a)\n",
    "        pars_b = posterior_params_dr(data_b, pars_b)\n",
    "        post_samp_len = 10000\n",
    "        post_samp_a = posterior_nords_rvs(pars_a, post_samp_len)\n",
    "        post_samp_b = posterior_nords_rvs(pars_b, post_samp_len)\n",
    "        pb_gt_pa = prob_pb_gt_pa_postsamp(post_samp_a, post_samp_b)\n",
    "        best_gr = 'B' if pb_gt_pa >= prob_stop else 'A' if (1 - pb_gt_pa) >= prob_stop else None\n",
    "        if best_gr:\n",
    "            cmp.at[i, 'A_exp'] = post_dist_A.mean()\n",
    "            cmp.at[i, 'B_exp'] = post_dist_B.mean()\n",
    "            cmp.at[i, 'exp_samp_size'] = n_samp_total\n",
    "            cmp.at[i, 'best_exp'] = best_gr\n",
    "            cmp.at[i, 'p_best'] = pb_gt_pa\n",
    "            break\n",
    "    print(f'done {i}: {n_samp_total}, {best_gr}, {pb_gt_pa}')\n",
    "\n",
    "cmp['correct'] = cmp['best_exact'] == cmp['best_exp']\n",
    "display(cmp.head(10))\n",
    "cor_guess = np.sum(cmp['correct'])\n",
    "print(f\"Nexp: {nexps}, Correct Guesses: {cor_guess}, Accuracy: {cor_guess / nexps}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00dfd8bb",
   "metadata": {},
   "source": [
    "# Средний чек"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03324297",
   "metadata": {},
   "source": [
    "# Заключение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2b3dfc",
   "metadata": {},
   "source": [
    "# Ссылки\n",
    "\n",
    "[BinomDist] - [Binomial Distribution](https://en.wikipedia.org/wiki/Binomial_distribution), *Wikipedia.*  \n",
    "[SciPyBinom] - [scipy.stats.binom](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.binom.html), *SciPy Reference.*   \n",
    "[BetaDist] - [Beta Distribution](https://en.wikipedia.org/wiki/Beta_distribution), *Wikipedia.*     \n",
    "[SciPyBeta] - [scipy.stats.beta](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.beta.html), *SciPy Reference.*   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543017df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51bd976",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f85f74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f59967f8",
   "metadata": {},
   "source": [
    "Пациент приходит ко врачу. Симптомы - температура.   \n",
    "Врач делает предположения на счет болезней - простуда, пневмония и т.д.  \n",
    "Врач прикидывает, при каких болезнях эти симптомы вероятны.  \n",
    "Дальше с учетом своего опыта и распространенности болезней ставит диагноз.  \n",
    "\n",
    "Можно записать рассуждения количественно.\n",
    "Для диагноза интересует $P(болезнь | симптомы)$.  \n",
    "Вначале выбирается список возможных болезней и для каждой вычисляется $P(симптомы | болезнь)$.  \n",
    "Распространенность болезней в регионе и опыт врача учитывает $P(болезнь)$.  \n",
    "\n",
    "$$\n",
    "P(болезнь | симптомы) \\approx P(симптомы | болезнь) P(болезнь)\n",
    "$$\n",
    "\n",
    "На этом примере видны компоненты байесовского моделирования.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed70ecf7",
   "metadata": {},
   "source": [
    "Let’s walk through an example of using the **Bayesian approach** to guess what’s inside a present based on the **size of the box**.\n",
    "\n",
    "### Setting:\n",
    "You receive a box as a gift, but you don’t know what’s inside. Based on the **size of the box**, you want to update your belief about what the present might be. You have a few reasonable guesses, and you’ll use **Bayes’ Theorem** to compute the posterior probabilities of each possible item given the size of the box.\n",
    "\n",
    "### Hypotheses (Possible Contents of the Box):\n",
    "You consider three possible items that could be inside the box:\n",
    "\n",
    "- \\( H_1 \\): A **book**.\n",
    "- \\( H_2 \\): A **pair of shoes**.\n",
    "- \\( H_3 \\): A **laptop**.\n",
    "\n",
    "### Prior Probabilities:\n",
    "Before looking at the size of the box, you have some prior beliefs about what the gift could be based on your knowledge of the person who gave you the gift. For example:\n",
    "\n",
    "- \\( P(H_1) = 0.3 \\) (They often give books as gifts).\n",
    "- \\( P(H_2) = 0.5 \\) (They’ve given shoes before).\n",
    "- \\( P(H_3) = 0.2 \\) (They once mentioned buying you a laptop).\n",
    "\n",
    "### Likelihoods (Based on the Size of the Box):\n",
    "Now, you observe the **size of the box**, and you know how likely it is for each possible item to fit into a box of this size. Suppose the box is medium-sized. Based on that, you assign the following likelihoods:\n",
    "\n",
    "- \\( P(\\text{Medium box} \\mid H_1) = 0.8 \\) (Books often come in medium-sized boxes).\n",
    "- \\( P(\\text{Medium box} \\mid H_2) = 0.6 \\) (Shoes could fit in a medium-sized box, but not always).\n",
    "- \\( P(\\text{Medium box} \\mid H_3) = 0.3 \\) (Laptops usually come in larger boxes, so this is less likely).\n",
    "\n",
    "### Evidence (Total Probability of Observing the Box Size):\n",
    "The total probability of receiving a **medium-sized box** is calculated by summing over all the possible contents:\n",
    "\\[\n",
    "P(\\text{Medium box}) = P(\\text{Medium box} \\mid H_1)P(H_1) + P(\\text{Medium box} \\mid H_2)P(H_2) + P(\\text{Medium box} \\mid H_3)P(H_3)\n",
    "\\]\n",
    "\\[\n",
    "P(\\text{Medium box}) = (0.8 \\times 0.3) + (0.6 \\times 0.5) + (0.3 \\times 0.2) = 0.24 + 0.3 + 0.06 = 0.6\n",
    "\\]\n",
    "\n",
    "### Applying Bayes’ Theorem:\n",
    "Now, you can compute the **posterior probability** for each possible item using **Bayes’ Theorem**:\n",
    "\n",
    "1. **Posterior for a Book**:\n",
    "   \\[\n",
    "   P(H_1 \\mid \\text{Medium box}) = \\frac{P(\\text{Medium box} \\mid H_1) P(H_1)}{P(\\text{Medium box})} = \\frac{0.8 \\times 0.3}{0.6} = \\frac{0.24}{0.6} = 0.4\n",
    "   \\]\n",
    "\n",
    "2. **Posterior for Shoes**:\n",
    "   \\[\n",
    "   P(H_2 \\mid \\text{Medium box}) = \\frac{P(\\text{Medium box} \\mid H_2) P(H_2)}{P(\\text{Medium box})} = \\frac{0.6 \\times 0.5}{0.6} = \\frac{0.3}{0.6} = 0.5\n",
    "   \\]\n",
    "\n",
    "3. **Posterior for a Laptop**:\n",
    "   \\[\n",
    "   P(H_3 \\mid \\text{Medium box}) = \\frac{P(\\text{Medium box} \\mid H_3) P(H_3)}{P(\\text{Medium box})} = \\frac{0.3 \\times 0.2}{0.6} = \\frac{0.06}{0.6} = 0.1\n",
    "   \\]\n",
    "\n",
    "### Conclusion:\n",
    "Based on the size of the box and your priors, you now have updated probabilities for what might be inside the box:\n",
    "- \\( P(\\text{Book} \\mid \\text{Medium box}) = 0.4 \\),\n",
    "- \\( P(\\text{Shoes} \\mid \\text{Medium box}) = 0.5 \\),\n",
    "- \\( P(\\text{Laptop} \\mid \\text{Medium box}) = 0.1 \\).\n",
    "\n",
    "The most likely item is a **pair of shoes** (50% chance), followed by a **book** (40% chance). A **laptop** is the least likely (10% chance)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad140172",
   "metadata": {},
   "source": [
    "Аномалия в дашборде. Как выглядит процесс расследования причин?  \n",
    "Вначале нужно сформулировать возможные предположения: баг в недавнем релизе, не отработали ETL-скрипты, ... .\n",
    "С учетом прошлого опыта выбрать наиболее вероятное.  \n",
    "Проверить.  \n",
    "\n",
    "Можно записать рассуждения количественно.\n",
    "Интересует $P(изменения | аномалия)$.  \n",
    "Вначале выбирается список возможных причин и для каждой вычисляется $P(аномалия | изменения)$.  \n",
    "Прошлый опыт учитывает $P(изменения)$.  \n",
    "\n",
    "$$\n",
    "P(изменения | аномалия) \\approx P(аномалия | изменения) P(изменения)\n",
    "$$\n",
    "\n",
    "На этом примере видны компоненты байесовского моделирования. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e1627c",
   "metadata": {},
   "source": [
    "* В мешке лежат черные и белые шары, всего 1000 штук. Для оценки количества черных шаров вынимают шар, записывают цвет, возвращают обратно. За 20 повторов вынули 5 черных шаров. Сколько может быть черных шаров в мешке и каковы вероятности этих значений?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8366fca7",
   "metadata": {},
   "source": [
    "1)\n",
    "\n",
    "При количестве черных шаров $N_B$ вероятность достать черный шар $p_B = N_B / N$.  \n",
    "Вероятность вынуть 5 черных шаров в 20 экспериментах задается биномиальным распределением.\n",
    "\n",
    "$$\n",
    "P(5, 20 | N_B) = Binom(5, 20) = C^5_{20} p_B^5 p_W^{15}\n",
    "$$\n",
    "\n",
    "Возможные значения $N_B$ от 1 (мог попадаться один и тот же черный шар) до 999 (есть как минимум 1 белый).\n",
    "\n",
    "Интересует\n",
    "\n",
    "$$\n",
    "P(N_B | 5, 20) = \\frac{ P(5,20 | N_B) P(N_B)}{P(5,20)} = \\frac{ P(5,20 | N_B) P(N_B)}{\\sum \\limits_{N_B=1}^{999} P(5,20 | N_B) P(N_B)}\n",
    "$$\n",
    "\n",
    "В знаменателе нормировочный коэффициент.\n",
    "\n",
    "Значения $P(N_B)$ равновероятны $P(N_B) = 1/999$.\n",
    "\n",
    "$$\n",
    "P(N_B | 5, 20) \n",
    "= \\frac{ P(5,20 | N_B)}{\\sum \\limits_{N_B=1}^{999} P(5,20 | N_B)} \n",
    "= \\frac{C^5_{20} p_B^5 p_W^{15}}{\\sum \\limits_{N_B=1}^{999} C^5_{20} p_B^5 p_W^{15}}\n",
    "= \\frac{C^5_{20} N_B^5 (N - N_B)^{15}}{\\sum \\limits_{N_B=1}^{999} C^5_{20} N_B^5 (N-N_B)^{15}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7506514b",
   "metadata": {},
   "source": [
    "Лучше так:\n",
    "1000 шаров, достали-вернули 5, все 5 черные. Сколько всего черных?\n",
    "\n",
    "\n",
    "$$\n",
    "P(5 | N_B) = Binom(5, 5) = C^5_{5} p_B^5 p_W^{0} = p_B^5\n",
    "$$\n",
    "\n",
    "$$\n",
    "P(N_B | 5) = \\frac{ P(5 | N_B) P(N_B)}{\\sum \\limits_{N_B=1}^{1000} P(5 | N_B) P(N_B)}\n",
    "$$\n",
    "\n",
    "Значения $P(N_B)$ равновероятны $P(N_B) = 1/1000$.\n",
    "\n",
    "$$\n",
    "P(N_B | 5) \n",
    "= \\frac{ P(5 | N_B)}{\\sum \\limits_{N_B=1}^{1000} P(5 | N_B)} \n",
    "= \\frac{p_B^5}{\\sum \\limits_{N_B=1}^{1000} p_B^5}\n",
    "= \\frac{N_B^5}{\\sum \\limits_{N_B=1}^{1000} N_B^5}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c36bf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0b953d11",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mbox{Beta}(1, 1) = \n",
    "\\mbox{Uniform}(p) = \n",
    "\\begin{cases}\n",
    "1, p \\in [0, 1]\n",
    "\\\\\n",
    "0, p \\not\\in [0, 1]\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35d03cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3742922",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "360d5011",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "d = np.arange(0, 30)\n",
    "\n",
    "p = 0.05\n",
    "N = 5000\n",
    "ns = stats.binom.rvs(n=N, p=p, size=len(d))\n",
    "cr = ns / N\n",
    "p_drop = p*2/3\n",
    "ns_drop = stats.binom.rvs(n=N, p=p_drop, size=len(d)//2)\n",
    "cr_drop = ns_drop / N\n",
    "p_inc = p*1.03\n",
    "ns_inc = stats.binom.rvs(n=N, p=p_inc, size=len(d)//2)\n",
    "cr_inc = ns_inc / N\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=d, y=cr*100, \n",
    "                        name='Базовое значение', line_color='black'))\n",
    "fig.add_trace(go.Scatter(x=d[len(d)//2-1:], y=np.concatenate([cr[[len(d)//2-1]]*100, cr_drop*100]),\n",
    "                         name='-30%', line_color='black', line_dash='dash'))\n",
    "fig.add_trace(go.Scatter(x=d[len(d)//2-1:], y=np.concatenate([cr[[len(d)//2-1]]*100, cr_inc*100]),\n",
    "                        name='+3%', line_color='black', opacity=0.4, line_dash='dash'))\n",
    "fig.update_layout(title='Эффект',\n",
    "                  xaxis_title='Дни',\n",
    "                  yaxis_title='Метрика',\n",
    "                  xaxis_range=[0, len(d)-1],\n",
    "                  xaxis_showticklabels=False,\n",
    "                  yaxis_range=[1, 7],\n",
    "                  yaxis_showticklabels=False,\n",
    "                  hovermode=\"x\",\n",
    "                  barmode=\"group\",\n",
    "                  width=900)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84ea0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.write_image(\"./effect_size.png\", scale=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83a6ef55",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local-venv-kernel",
   "language": "python",
   "name": "local-venv-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
