{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b087aaa2",
   "metadata": {},
   "source": [
    "# Байесовская оценка А/Б-тестов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c84793b",
   "metadata": {},
   "source": [
    "*Описана механика А/Б-тестов. Рассмотрены примеры байесовского моделирования. Байесовская оценка применена к сравнению конверсий, средних с помощью центральной предельной теоремы, выручки на пользователя, заказов на платящего, средних чеков.*\n",
    "\n",
    "&nbsp; &nbsp; *- [А/Б тесты](#А/Б-тесты)*  \n",
    "&nbsp; &nbsp; *- [Байесовское моделирование](#Байесовское-моделирование)*  \n",
    "&nbsp; &nbsp; *- [Конверсии](#Конверсии)*   \n",
    "&nbsp; &nbsp; *- [Средние](#Средние)*    \n",
    "&nbsp; &nbsp; *- [Выручка на пользователя](#Выручка-на-пользователя)*  \n",
    "&nbsp; &nbsp; *- [Заказы на платящего](#Заказы-на-платящего)*  \n",
    "&nbsp; &nbsp; *- [Средний чек](#Средний-чек)*  \n",
    "&nbsp; &nbsp; *- [Заключение](#Заключение)*  \n",
    "&nbsp; &nbsp; *- [Ссылки](#Ссылки)*  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e08f80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "from collections import namedtuple\n",
    "\n",
    "np.random.seed(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5e4c34",
   "metadata": {},
   "source": [
    "# А/Б тесты  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc9b0098",
   "metadata": {},
   "source": [
    "В мобильные приложения и веб-сервисы вносят изменения для роста выручки, конверсий, вовлеченности и других ключевых метрик. Повышение цен может снизить конверсию, но увеличить прибыль. Точный эффект непредсказуем - изменения могут ухудшить продукт. По оценкам только треть релизов приводит к положительным результатам [[MicroExp](https://www.microsoft.com/en-us/research/publication/online-experimentation-at-microsoft/)]. Поэтому необходимо измерять эффект от новой функциональности."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208d8e59",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"./figs/experiment_versions_ru.png\" alt=\"experiment_versions\" width=\"400\"/>\n",
    "    \n",
    "<em>Увеличение стоимости (справа) может привести к росту выручки, но падению конверсии. Эффект непредсказуем и требует измерения. </em>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c98fdba",
   "metadata": {},
   "source": [
    "Сравнение метрик до и после релиза не всегда позволяет оценить изменение. При \"сильном\" эффекте будет виден скачок в метрике, но \"слабый\" эффект может быть незаметен на фоне колебаний. На метрики также влияют изменения в других частях продукта, привлекаемом трафике или общей активности аудитории - например, запуск рекламной акции. Поэтому изменения метрик после релиза не всегда можно объяснять новой функциональностью. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a5468b",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"./figs/effect_size.png\" alt=\"effect_size\"  width=\"900\"/>\n",
    "<em>При оценке эффекта сильные изменения заметны в динамике метрики (см. падение на 30%), но слабые изменения могут быть незаметны на фоне колебаний (см. рост на 3%). Кроме того, изменение метрик после релиза не всегда связано с новой функциональностью. </em>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e7b24bb",
   "metadata": {},
   "source": [
    "Для более точной оценки эффекта используют А/Б-тесты. В этом подходе версию без изменений и измененный вариант сервиса запускают параллельно. При попадании на сайт или в приложение пользователь случайным образом определяется в один из вариантов. В каждой группе собирают данные, вычисляют и сравнивают интересующие метрики. Эксперимент останавливают, если одна из групп лидирует или продолжать тест неоправдано. В итоге принимается решение о дальнейших действиях - как правило, о выборе одного из вариантов для всех пользователей. Описание деталей см. также в [[TrustworthyAB]((https://www.amazon.com/gp/product/B0845Y3DJV)]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b583dcb1",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"./figs/ab_test.png\" alt=\"ab_test\" width=\"800\"/>\n",
    "    \n",
    "<em>Схема А/Б эксперимента: тестируемые версии сервиса запускают параллельно, пользователи случайным образом попадают в один из вариантов. В каждой группе вычисляют интересующие метрики, по результатам сравнения определяют дальнейшие действия. </em>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "796a9520",
   "metadata": {},
   "source": [
    "Причинная диаграмма [[CausalDAG](https://en.wikipedia.org/wiki/Causal_graph)] А/Б-тестов следующая. Метрики определяются действиями пользователей в сервисе. Действия зависят от версии сайта или приложения (например, доступных тарифных планов), внешних факторов (например, сезонности) и также отличаются между сегментами пользователей (новые, постоянные клиенты и др.). В А/Б-тесте версии запускают одновременно и пользователей случайно делят между вариантами. Внешние факторы сохраняются, но при сравнении за одинаковый период их влияние на группы одинаково. При случайном делении пользователей состав сегментов можно считать одинаковым. В итоге разница метрик между группами объясняется функциональностью приложения.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89384924",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"./figs/causal.png\" alt=\"causal\" width=\"600\"/>\n",
    "    \n",
    "<em>Метрики определяются действиями пользователей в сервисе. Действия зависят от текущей версии сайта или приложения, внешних факторов и также отличаются между сегментами пользователей. Случайное деление пользователей между вариантами А/Б-теста позволяет говорить об одинаковом влиянии сегментов на метрики, а одновременный запуск - об одинаковом влиянии внешних факторов. В итоге разницу метрик между группами можно объяснять тестируемой функциональностью. </em>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "485de2fb",
   "metadata": {},
   "source": [
    "По итогам эксперимента нужно оценить метрики, эффект и выбрать \"лучшую\" группу. Точные значения метрик неизвестны. Их удобнее рассматривать как случайные величины. Распределения вероятностей этих величин нужно подобрать для наибольшей совместимости с экспериментальными данными. Сравнение распределений позволяет оценить эффект. Для презентации удобна точечная оценка метрик и интервал наибольшей плотности вероятности. Например, среднее значение метрики в группе А $p_A = 7.1 \\pm 0.2$, в группе Б $p_B = 7.4 \\pm 0.3$. Эффект можно охарактеризовать относительной разностью $(p_B - p_A) / p_A = 4.2 \\pm 0.2 \\%$. Для выбора \"лучшей\" группы можно оценить с какой вероятностью метрика в группе Б больше метрики в группе А, например, $P(p_B > p_A) = 95\\%$. Вероятность здесь и далее понимается в субъективном смысле - как мера уверенности в определенном исходе процесса с несколькими возможными исходами [[SubjProb](https://en.wikipedia.org/wiki/Probability_interpretations#Subjectivism)]."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "702718f8",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"./figs/ab_metric_random.png\" alt=\"ab_metric_random\" width=\"500\"/>\n",
    "    \n",
    "<em>\n",
    "В А/Б тесте нужно оценить метрики, эффект и выбрать \"лучшую\" группу. Неизвестные точные значения метрик удобнее рассматривать как случайные величины. Их распределения вероятностей нужно подобрать для наибольшей совместимости с экспериментальными данными. Сравнение распределений позволяет оценить эффект.\n",
    "</em>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bec192",
   "metadata": {},
   "source": [
    "Пока данных мало, неопределенность в оценках метрик большая. По мере набора данных оценки уточняются. Вместе с этим растет уверенность, какая из групп лучше. Когда уверенность достигает достаточного значения, эксперимент можно останавливать. Возможны другие критерии остановки."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef663589",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"./figs/ab_dynamics.png\" alt=\"ab_dynamics\" width=\"400\"/>\n",
    "<em>\n",
    "По мере набора данных снижается неопределенность в оценках метрик и растет уверенность, какая из групп лучше. Когда уверенность достигает достаточного значения, эксперимент можно останавливать.\n",
    "</em>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f5e824f",
   "metadata": {},
   "source": [
    "Для оценки распределений метрик на основе экспериментальных данных используется байесовское моделирование."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd317e22",
   "metadata": {},
   "source": [
    "# Байесовское моделирование"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d6ed685",
   "metadata": {},
   "source": [
    "Несколько примеров байесовского моделирования."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559d2275",
   "metadata": {},
   "source": [
    "Вы нашли небольшую коробку в ящике стола. Вы не помните, что внутри и угадываете перед открытием коробки. У вас несколько вариантов - документы, старая электроника, возможно, пусто. Документы вы обычно храните отдельно, также они не влезли бы в коробку. Коробка может быть пустой, но вряд ли вы бы стали хранить пустую коробку. Скорее всего электроника. Вы открываете коробку. В ней сувениры из прошлой поездки."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f65ac1cc",
   "metadata": {},
   "source": [
    "Рассуждения выше можно сделать количественными. Нужно предположить несколько вариантов содержимого коробки и для каждого оценить вероятность, что предмет в коробке $P(предмет | коробка)$. \n",
    "Это делается с помощью соотношения Байеса. Вероятность $P(предмет | коробка)$ пропорциональная вероятности, что вы из всех пришедших в голову вариантов в коробке именно этот предмет $P(предмет)$ и вероятности, что вы положили этот предмет именно в найденную коробку $P(коробка|предмет)$.\n",
    "\n",
    "$$\n",
    "P(предмет | коробка) \\propto P(коробка|предмет) P(предмет)\n",
    "$$\n",
    "\n",
    "Например, $P(документы) = 0.3$, документы хранятся отдельно $P(коробка|документы) = 0.2$. $P(документы | коробка) \\propto 0.6$. Электроника может быть $P(электроника) = 0.5$. Также $P(коробка|электроника)$ = 0.6. Для пустой коробки остается $P(пусто) = 0.2$. Пусть $P(коробка|пусто)$ = 0.2. \n",
    "\n",
    "$$\n",
    "P(документы | коробка) \\propto P(коробка|документы) P(документы) = 0.3 \\cdot 0.2 = 0.06\n",
    "\\\\\n",
    "P(электроника | коробка) \\propto P(коробка|электроника) P(электроника) = 0.5 \\cdot 0.6 = 0.3 \n",
    "\\\\\n",
    "P(пусто | коробка) \\propto P(коробка|пусто) P(пусто) = 0.2 \\cdot 0.2 = 0.04\n",
    "$$\n",
    "\n",
    "пропуск  \n",
    "банковская карта  \n",
    "проездной"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907e29a9",
   "metadata": {},
   "source": [
    "На этом примере видны основные элементы байесовского моделирования. Есть данные (или факты). Есть несколько гипотез (или моделей, или предположений), объясняющих данные. Для выбора одной из гипотез нужно оценить, насколько каждая из гипотез согласуется с данными. Насколько хорошо гипотеза объясняет данные $P(данные | модель)$ и уверенность в гипотезе по сравнению с другими $P(модель)$. После чего выбрать наиболее хорошо согласующуюся. Для этого нужно вычислить вероятности получить данные в рамках гипотез (правдоподобия) и априорные вероятности каждой гипотезы. Связь выражается соотношением Байеса:\n",
    "\n",
    "$$\n",
    "P(модель | данные) = \\frac{ P(данные | модель) P(модель) }{P(данные)} .\n",
    "$$\n",
    "\n",
    "$P(модель | данные)$ - апостериорное распределение вероятности, $P(данные | модель)$ - функция правдоподобия, $P(модель)$ - априорное распределение вероятности, $P(данные)$ не имеет специального названия и играет роль нормировочного коэффициента."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2103fdae",
   "metadata": {},
   "source": [
    "Таким образом, в байесовском подходе выбирается набор возможных моделей для объяснения данных. Для каждой модели вычисляется вероятность получить данные в рамках выбранной модели - функция правдоподобия $P(данные|модель)$. Для каждой модели задается уверенность в этой модели относительно остальных - априорная вероятность $P(модель)$. По соотношению Байеса вычисляется апостериорная вероятность $P(модель|данные)$. Выбирается наиболее подходящая модель."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c18355",
   "metadata": {},
   "source": [
    "В примере выше в коробке не оказалось ничего из исходных предположений. Это напоминает о том, что ни одна из рассматриваемых гипотез может быть не верна."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19043be3",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"./figs/bayes_hypotheses.png\" alt=\"bayes_hypotheses\" width=\"600\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68672877",
   "metadata": {},
   "source": [
    "Следующий пример. На страницу зашло $N = 1000$ человек, $n_s = 100$ из них нажали кнопку \"Продолжить\". Как выглядит распределение возможных значений конверсии $\\theta$? Вероятность конверсии каждого пользователя можно считать одинаковой, все возможные априорные значения конверсии равновероятными. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44d286c",
   "metadata": {},
   "source": [
    "Необходимо оценить вероятность $P(\\theta | n_s, N)$. По соотношению Байеса $P(\\theta | n_s, N) \\propto P(n_s, N | \\theta) P(\\theta)$. Заход на страницу и клик по кнопке можно представить как случайную величину с 2 исходами с шансом на успех $\\theta$. Вероятность $n_s$ конверсий из $N$ с шансом на успех $\\theta$ (схема Бернулли [[Bern](https://en.wikipedia.org/wiki/Bernoulli_process)]) задается биномиальным распределением [[BinomDist](https://en.wikipedia.org/wiki/Binomial_distribution)]  $P(n_s, N | \\theta) = \\mbox{Binom}(n_s, N; \\theta)$. Т.к. все возможные априорные значения конверсий равновероятны, априорное распределение равномерно $P(\\theta) = \\mbox{Unif}(0, 1) = 1$. Распределение $P(\\theta | n_s, N)$ будет бета-распределением [[BetaDist](https://en.wikipedia.org/wiki/Beta_distribution), [SciPyBeta](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.beta.html)].\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "P(n_s, N | \\theta) & = \\mbox{Binom}(n_s, N; \\theta) = C^{n_s}_{N} \\theta^{n_s} (1 - \\theta)^{N-n_s}\n",
    "\\\\\n",
    "P(\\theta) & = \\mbox{Unif}(0, 1) = 1\n",
    "\\\\\n",
    "P(\\theta | n_s, N) \n",
    "& = \\frac{P(n_s, N | \\theta) P(\\theta)}{P(n_s, N)}\n",
    "= \\frac{P(n_s, N | \\theta) P(\\theta)}{\\int_0^1 d \\theta P(n_s, N | \\theta) P(\\theta)}\n",
    "\\\\\n",
    "& = \\frac{\\theta^{n_s} (1 - \\theta)^{N-n_s}}{\\int_0^1 d \\theta (1 - \\theta)^{N-n_s} \\theta^{n_s} }\n",
    "= \\mbox{Beta}(\\theta; n_s + 1, N - n_s + 1)\n",
    "\\end{split}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e7a82a",
   "metadata": {},
   "source": [
    "Гипотезы в примере - использование схемы Бернулли для моделирования конверсий и возможные значения $\\theta$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5136734e",
   "metadata": {},
   "source": [
    "График апостериорного распределения $P(\\theta | n_s, N)$ ниже. Мода совпадает со средним в выборке $n_s/N$, наиболее вероятные значения $\\theta$ лежат вблизи этого значения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d072080",
   "metadata": {},
   "outputs": [],
   "source": [
    "ns = 100\n",
    "ntotal = 1000\n",
    "\n",
    "p_samp = ns / ntotal\n",
    "p_dist = stats.beta(a=ns+1, b=ntotal-ns+1)\n",
    "\n",
    "xaxis_max = 0.2\n",
    "x = np.linspace(0, xaxis_max, 1000)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=p_dist.pdf(x), line_color='black', name='Распределение'))\n",
    "fig.add_trace(go.Scatter(x=[p_samp, p_samp], y=[0, max(p_dist.pdf(x))], \n",
    "                         line_color='black', mode='lines', line_dash='dash', name='Среднее в выборке'))\n",
    "fig.update_layout(title='$\\mbox{Апостериорное распределение} \\, P(\\\\theta | n_s, N)$',\n",
    "                  xaxis_title='$\\mbox{Конверсия} \\, \\\\theta$',\n",
    "                  yaxis_title='Плотность вероятности',\n",
    "                  xaxis_range=[0, xaxis_max],\n",
    "                  hovermode=\"x\",\n",
    "                  height=500)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db2edc81",
   "metadata": {},
   "source": [
    "Еще один пример. На версию А страницы веб-сайта зашло 1000 человек, 100 нажали кнопку \"Продолжить\". На версию Б зашло 1000 человек, 110 нажали кнопку продолжить. С какой вероятностью конверсия страницы Б выше страницы А?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de5109d",
   "metadata": {},
   "source": [
    "Нужна вероятность $P(\\theta_B > \\theta_A)$. Апостериорное распределение каждой группы вычисляется как в предыдущем примере $P(\\theta; n_s, N) = \\mbox{Beta}(\\theta ; n_s + 1, N - n_s + 1)$. Вероятность $P(\\theta_B > \\theta_A)$ можно оценить аналитически, но чаще это делают численно. Для этого генерируют выборки из апострериорных распределений и сравнивают их между собой. Для заданных параметров $P(\\theta_B > \\theta_A) = 76.7 \\%$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9762b9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "na = 1000\n",
    "sa = 100\n",
    "nb = 1000\n",
    "sb = 110\n",
    "\n",
    "npost = 50000\n",
    "\n",
    "p_dist_a = stats.beta(a=sa+1, b=na-sa+1)\n",
    "p_dist_b = stats.beta(a=sb+1, b=nb-sb+1)\n",
    "\n",
    "xaxis_max = 0.2\n",
    "x = np.linspace(0, xaxis_max, 1000)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=p_dist_a.pdf(x), line_color='black', name='А'))\n",
    "fig.add_trace(go.Scatter(x=x, y=p_dist_b.pdf(x), line_color='black', opacity=0.3, name='Б'))\n",
    "fig.update_layout(title='Апостериорные распределения',\n",
    "                  xaxis_title='$Конверсия$',\n",
    "                  yaxis_title='Плотность вероятности',\n",
    "                  xaxis_range=[0, xaxis_max],\n",
    "                  hovermode=\"x\",\n",
    "                  height=500)\n",
    "fig.show()\n",
    "\n",
    "samp_a = p_dist_a.rvs(size=npost)\n",
    "samp_b = p_dist_b.rvs(size=npost)\n",
    "p_b_gt_a = np.sum(samp_b > samp_a) / npost\n",
    "\n",
    "print(f\"P(theta_b > theta_a): {p_b_gt_a}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e20d872",
   "metadata": {},
   "source": [
    "# Конверсии"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "325e7da1",
   "metadata": {},
   "source": [
    "Конверсии - есть $N$ пользователей, $n_s$ из них сделали целевое действие (сделали заказ, зашли на страницу и т.п.). Всего пользователей $N$, $n_s$ из них сделали целевое действие. Пользователи независимы друг от друга (т.е. действия одного не влияют на других). Конверсию каждого пользователя одинаковы. В этом случае можно моделировать биномиальным распределением. Функция правдоподобия задается биномиальным распределением $P(n_s, N | p) \\sim \\mbox{Binom}(p, N)$. Априорное распределение конверсий удобно задать бета-распределением $P(p) = \\mbox{Beta}(p; \\alpha, \\beta)$. Зависимость от $p$ без учета нормировочных коэффициентов $\\mbox{Beta}(p; \\alpha, \\beta) \\propto p^{\\alpha-1}(1-p)^{\\beta-1}$. Эта зависимость сохранится для произведения правдоподобия на априорное распределение $P(p | n_s, N) \\propto \\mbox{Binom}(p, N) \\mbox{Beta}(p; \\alpha, \\beta) \\propto p^{n_s + \\alpha - 1} (1-p)^{N - n_s + \\beta - 1}$. Априорные распределения с таким свойством называют сопряженными априорными распределениями. При $\\alpha=1, \\beta=1$ бета-распределение совпадает с однородным - можно выбирать эти значения как стартовые. Либо можно подобрать на основе исторических данных, чтобы априорное распределение конверсий совпадало с историческим значением."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c61b53d",
   "metadata": {},
   "source": [
    "$$\n",
    "P(model | data) \\propto P(data | model) P(model)\n",
    "$$\n",
    "\n",
    "$$\n",
    "P(data | model) = P(n_s, N | p) = \\mbox{Binom}(p, N) = C_{N}^{n_s} p^{n_s} (1-p)^{N-n_s}\n",
    "$$\n",
    "\n",
    "$$\n",
    "P(model) = P(p) = \\mbox{Beta}(p; \\alpha, \\beta) = \n",
    "\\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\alpha) \\Gamma(\\beta)} p^{\\alpha-1}(1-p)^{\\beta-1}\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "P(model | data) & = P(p | n_s, N)\n",
    "\\\\\n",
    "& \\propto \\mbox{Binom}(p, N) \\mbox{Beta}(p; \\alpha, \\beta)\n",
    "\\\\\n",
    "& \\propto C_{N}^{n_s} p^{n_s} (1-p)^{N-n_s}\n",
    "\\frac{\\Gamma(\\alpha + \\beta)}{\\Gamma(\\alpha) \\Gamma(\\beta)} p^{\\alpha-1}(1-p)^{\\beta-1}\n",
    "\\\\\n",
    "& \\propto p^{n_s + \\alpha - 1} (1-p)^{N - n_s + \\beta - 1}\n",
    "\\\\\n",
    "& = \\mbox{Beta}(p; \\alpha + n_s, \\beta + N - n_s)\n",
    "\\end{split}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4060da4a",
   "metadata": {},
   "source": [
    "Примеры бета-распределения на графике ниже [[BetaDist](https://en.wikipedia.org/wiki/Beta_distribution), [SciPyBeta](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.beta.html)]. При $\\alpha = 1, \\beta=1$ распределение однородное. Максимум в точке $p = (\\alpha-1) / (\\alpha + \\beta - 2)$. При увеличении $\\alpha$ и $\\beta$ распределение сужается и приближается к нормальному.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38bd8a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 1, 1000)\n",
    "fig = go.Figure()\n",
    "a, b = 1, 1\n",
    "fig.add_trace(go.Scatter(x=x, y=stats.beta.pdf(x, a=a, b=b), \n",
    "                             mode='lines', line_color='black', line_dash='dash',\n",
    "                             name=f'a={a}, b={b}'))\n",
    "a, b = 1, 5\n",
    "fig.add_trace(go.Scatter(x=x, y=stats.beta.pdf(x, a=a, b=b), \n",
    "                             mode='lines', line_color='black', line_dash='solid',\n",
    "                             name=f'a={a}, b={b}'))\n",
    "a, b = 3, 5\n",
    "fig.add_trace(go.Scatter(x=x, y=stats.beta.pdf(x, a=a, b=b), \n",
    "                             mode='lines', line_color='black', line_dash='solid',\n",
    "                             name=f'a={a}, b={b}'))\n",
    "a, b = 25, 30\n",
    "fig.add_trace(go.Scatter(x=x, y=stats.beta.pdf(x, a=a, b=b), \n",
    "                             mode='lines', line_color='black', line_dash='solid',\n",
    "                             name=f'a={a}, b={b}'))\n",
    "a, b = 150, 50\n",
    "fig.add_trace(go.Scatter(x=x, y=stats.beta.pdf(x, a=a, b=b), \n",
    "                             mode='lines', line_color='black', line_dash='solid',\n",
    "                             name=f'a={a}, b={b}')) \n",
    "fig.add_trace(go.Scatter(\n",
    "    x=[0.98, 0.08, 0.32, 0.55, 0.87],\n",
    "    y=[1.35, 5.00, 2.80, 6.20, 12.0],\n",
    "    mode=\"text\",\n",
    "    name=None,\n",
    "    showlegend=False,\n",
    "    text=[\"a=1, b=1\", \"a=1, b=5\", \"a=3, b=5\", \"a=25, b=30\", \"a=150, b=50\"],\n",
    "    textposition=\"top left\"\n",
    "))\n",
    "fig.update_layout(title='Бета-распределение Beta(a, b)',\n",
    "                  xaxis_title='x',\n",
    "                  yaxis_title='Плотность вероятности',\n",
    "                  showlegend=False,\n",
    "                  xaxis_range=[0, 1],\n",
    "                  height=550)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7918681",
   "metadata": {},
   "source": [
    "В примере ниже строится оценка неизвестного значения конверсии по данным. Задается точное значение конверсии `p`, генерируется `nsample` точек. По выборке строится апостериорное распределение возможных значений конверсий. Мода апостериорного распределения совпадает со средним в выборке, но не всегда совпадает с точным значением. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e25350",
   "metadata": {},
   "outputs": [],
   "source": [
    "def posterior_dist_binom(ns, ntotal, a_prior=1, b_prior=1):\n",
    "    a = a_prior + ns\n",
    "    b = b_prior + (ntotal - ns) \n",
    "    return stats.beta(a=a, b=b)\n",
    "    \n",
    "def posterior_binom_approx_95pdi(post_dist):\n",
    "    lower = post_dist.ppf(0.025)\n",
    "    upper = post_dist.ppf(0.975)\n",
    "    return lower, upper\n",
    "\n",
    "def prob_pb_gt_pa(post_dist_A, post_dist_B, post_samp=100_000):\n",
    "    sa = post_dist_A.rvs(size=post_samp)\n",
    "    sb = post_dist_B.rvs(size=post_samp)\n",
    "    b_gt_a = np.sum(sb > sa)\n",
    "    return b_gt_a / post_samp\n",
    "\n",
    "p = 0.1\n",
    "nsample = 1000\n",
    "\n",
    "exact_dist = stats.bernoulli(p=p)\n",
    "data = exact_dist.rvs(nsample)\n",
    "\n",
    "post_dist = posterior_dist_binom(ns=np.sum(data), ntotal=len(data))\n",
    "\n",
    "x = np.linspace(0, 1, 1000)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=post_dist.pdf(x), line_color='black', name='Апостериорное'))\n",
    "fig.add_trace(go.Scatter(x=[np.sum(data)/len(data), np.sum(data)/len(data)], y=[0, max(post_dist.pdf(x))], \n",
    "                         line_color='black', mode='lines', line_dash='dash', name='Среднее в выборке'))\n",
    "fig.add_trace(go.Scatter(x=[exact_dist.mean(), exact_dist.mean()], y=[0, max(post_dist.pdf(x))*1.05], \n",
    "                         line_color='red', mode='lines', line_dash='dash', name='Точное p'))\n",
    "fig.update_layout(title='Апостериорное распределение',\n",
    "                  xaxis_title='p',\n",
    "                  yaxis_title='Плотность вероятности',\n",
    "                  xaxis_range=[0, 1],\n",
    "                  hovermode=\"x\",\n",
    "                  height=500)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487e3d75",
   "metadata": {},
   "source": [
    "Сравнение двух групп. Выбирается $p_A$, $p_B$ на 5% больше. Для каждой группы генерируется `nsample` точек, на их основе строятся апостериорные распределения конверсий в каждой группе. Вычисляется вероятность конверсия в группе Б больше $P(p_B > p_A)$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33eb7827",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_A = 0.1\n",
    "p_B = p_A * 1.05\n",
    "nsample = 1000\n",
    "\n",
    "exact_dist_A = stats.bernoulli(p=p_A)\n",
    "exact_dist_B = stats.bernoulli(p=p_B)\n",
    "data_A = exact_dist_A.rvs(nsample)\n",
    "data_B = exact_dist_B.rvs(nsample)\n",
    "\n",
    "post_dist_A = posterior_dist_binom(ns=np.sum(data_A), ntotal=len(data_A))\n",
    "post_dist_B = posterior_dist_binom(ns=np.sum(data_B), ntotal=len(data_B))\n",
    "\n",
    "x = np.linspace(0, 1, 1000)\n",
    "fig = go.Figure()\n",
    "#fig.add_vline(x=exact_dist.mean(), line_dash='dash', name='Exact')\n",
    "fig.add_trace(go.Scatter(x=x, y=post_dist_A.pdf(x), line_color='black', name='A'))\n",
    "fig.add_trace(go.Scatter(x=x, y=post_dist_B.pdf(x), line_color='black', opacity=0.2, name='B'))\n",
    "fig.add_trace(go.Scatter(x=[exact_dist_A.mean(), exact_dist_A.mean()], y=[0, max(post_dist_A.pdf(x))*1.05], \n",
    "                         mode='lines', line_dash='dash', line_color='black', name='Точное A'))\n",
    "fig.add_trace(go.Scatter(x=[exact_dist_B.mean(), exact_dist_B.mean()], y=[0, max(post_dist_A.pdf(x))*1.05], \n",
    "                         mode='lines', line_dash='dash', line_color='black', opacity=0.2, name='Точное B'))\n",
    "fig.update_layout(title='Апостериорные распределения',\n",
    "                  xaxis_title='p',\n",
    "                  yaxis_title='Плотность вероятности',\n",
    "                  xaxis_range=[p_A/2, p_A*2],\n",
    "                  hovermode=\"x\",\n",
    "                  height=500)\n",
    "fig.show()\n",
    "\n",
    "print(f'P(pB > pA): {prob_pb_gt_pa(post_dist_A, post_dist_B)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a5abff",
   "metadata": {},
   "source": [
    "Динамика по мере набора данных. Две группы. Задаются $p_A$, $p_B$ на 5% лучше. В каждой группе генерируется `nstep` точек `nsize` раз (всего `nstep * nsize` точек). По накопленным данным на каждом шаге строятся апостериорные распределения. Строится оценка интервала наибольшей плотности вероятности. Строится вероятность $P(p_B > p_A)$. По мере набора данных интервалы сужаются, вероятность стремится к 1 в пользу лучшей группы."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aca6765",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pa = 0.1\n",
    "pb = pa * 1.05\n",
    "\n",
    "nstep = 1000\n",
    "size = 150\n",
    "sa = stats.binom.rvs(p=pa, n=nstep, size=size)\n",
    "sb = stats.binom.rvs(p=pb, n=nstep, size=size)\n",
    "\n",
    "df = pd.DataFrame()\n",
    "df['n_step'] = [nstep] * size\n",
    "df['sa_step'] = sa\n",
    "df['sb_step'] = sb\n",
    "df['N'] = df['n_step'].cumsum()\n",
    "df['sa'] = df['sa_step'].cumsum()\n",
    "df['sb'] = df['sb_step'].cumsum()\n",
    "df['pa'] = df.apply(lambda r: posterior_dist_binom(r['sa'], r['N']).mean(), axis=1)\n",
    "df[['pa_lower', 'pa_upper']] = df.apply(lambda r: posterior_binom_approx_95pdi(posterior_dist_binom(r['sa'], r['N'])), axis=1, result_type=\"expand\")\n",
    "df['pb'] = df.apply(lambda r: posterior_dist_binom(r['sb'], r['N']).mean(), axis=1)\n",
    "df[['pb_lower', 'pb_upper']] = df.apply(lambda r: posterior_binom_approx_95pdi(posterior_dist_binom(r['sb'], r['N'])), axis=1, result_type=\"expand\")\n",
    "df['pb_gt_pa'] = df.apply(lambda r: prob_pb_gt_pa(posterior_dist_binom(r['sa'], r['N']), posterior_dist_binom(r['sb'], r['N']), post_samp=10_000), axis=1)\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=df['N'], y=df['pa'], name='A',\n",
    "                         line_color='black'))\n",
    "fig.add_trace(go.Scatter(x=list(df['N']) + list(reversed(df['N'])), \n",
    "                         y=list(df['pa_upper']) + list(reversed(df['pa_lower'])),\n",
    "                         fill=\"toself\", name='A, 95% HPDI', marker_color='black', opacity=0.2))\n",
    "fig.add_trace(go.Scatter(x=df['N'], y=df['pb'], name='B',\n",
    "                         line_color='blue'))\n",
    "fig.add_trace(go.Scatter(x=list(df['N']) + list(reversed(df['N'])), \n",
    "                         y=list(df['pb_upper']) + list(reversed(df['pb_lower'])),\n",
    "                         fill=\"toself\", name='B, 95% HPDI', marker_color='blue', opacity=0.2))\n",
    "fig.update_layout(title='$p_A, p_B$',\n",
    "                  yaxis_tickformat = ',.1%',\n",
    "                  xaxis_title='N')\n",
    "fig.show()\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=df['N'], y=df['pb_gt_pa'], name='P(pb > pa)',\n",
    "                         line_color='black'))\n",
    "fig.update_layout(title='$P(p_B > p_A)$',\n",
    "                  yaxis_range=[0, 1],\n",
    "                  xaxis_title='N')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a6e39c0",
   "metadata": {},
   "source": [
    "Доля правильно угаданных вариантов. В группе А выбирается значение конверсии `p`. Для группы Б генерируется `nexps` значений в диапазоне +-5% от `p`. Для каждой пары генерируются данные с шагом `n_samp_step`. Считаются апостериорные распределения и $P(p_B > p_A)$. Эксперимент останавливается, если  $P(p_B > p_A)$ достигает `prob_stop`. Или если достигнуто максимальное количество точек `n_samp_max`. Считается доля правильно угаданных групп во всех экспериментах. В данном случае в `nexps = 100` правильно угадано 94. Точность 0.94 близка к `prob_stop = 0.95`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874dbdb9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cmp = pd.DataFrame(columns=['A', 'B', 'best_exact', 'exp_samp_size', 'A_exp', 'B_exp', 'best_exp', 'p_best'])\n",
    "\n",
    "p = 0.1\n",
    "nexps = 100\n",
    "cmp['A'] = [p] * nexps\n",
    "cmp['B'] = p * (1 + stats.uniform.rvs(loc=-0.05, scale=0.1, size=nexps))\n",
    "cmp['best_exact'] = cmp.apply(lambda r: 'B' if r['B'] > r['A'] else 'A', axis=1)\n",
    "\n",
    "prob_stop = 0.95\n",
    "for i in range(nexps):\n",
    "    pA = cmp.at[i, 'A']\n",
    "    pB = cmp.at[i, 'B']\n",
    "    exact_dist_A = stats.bernoulli(p=pA)\n",
    "    exact_dist_B = stats.bernoulli(p=pB)\n",
    "    n_samp_max = 10_000_000\n",
    "    n_samp_total = 0\n",
    "    n_samp_step = 10_000\n",
    "    ns_A = 0\n",
    "    ns_B = 0\n",
    "    while n_samp_total < n_samp_max:\n",
    "        dA = exact_dist_A.rvs(n_samp_step)\n",
    "        dB = exact_dist_B.rvs(n_samp_step)\n",
    "        n_samp_total += n_samp_step\n",
    "        ns_A = ns_A + np.sum(dA)\n",
    "        ns_B = ns_B + np.sum(dB)\n",
    "        post_dist_A = posterior_dist_binom(ns=ns_A, ntotal=n_samp_total)\n",
    "        post_dist_B = posterior_dist_binom(ns=ns_B, ntotal=n_samp_total)\n",
    "        pb_gt_pa = prob_pb_gt_pa(post_dist_A, post_dist_B)\n",
    "        best_gr = 'B' if pb_gt_pa >= prob_stop else 'A' if (1 - pb_gt_pa) >= prob_stop else None\n",
    "        if best_gr:\n",
    "            cmp.at[i, 'A_exp'] = post_dist_A.mean()\n",
    "            cmp.at[i, 'B_exp'] = post_dist_B.mean()\n",
    "            cmp.at[i, 'exp_samp_size'] = n_samp_total\n",
    "            cmp.at[i, 'best_exp'] = best_gr\n",
    "            cmp.at[i, 'p_best'] = pb_gt_pa\n",
    "            break\n",
    "    print(f'done {i}: {n_samp_total}, {best_gr}, {pb_gt_pa}')\n",
    "\n",
    "cmp['correct'] = cmp['best_exact'] == cmp['best_exp']\n",
    "display(cmp.head(10))\n",
    "cor_guess = np.sum(cmp['correct'])\n",
    "print(f\"Nexp: {nexps}, Correct Guesses: {cor_guess}, Accuracy: {cor_guess / nexps}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d29f2a0f",
   "metadata": {},
   "source": [
    "# Средние"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd9a0af2",
   "metadata": {},
   "source": [
    "Байесовский подход [[SGBS](https://www.amazon.co.uk/Students-Guide-Bayesian-Statistics/dp/1473916364), [SR](https://www.amazon.co.uk/Statistical-Rethinking-Bayesian-Examples-Chapman/dp/036713991X/ref=sr_1_1)] требует построения моделей распределений сравниваемых величин. Выбор модели всегда произвольный и всегда остаются вопросы обоснования модели.\n",
    "\n",
    "Для многих величин не нужно знать все распределение. Можно ограничиться сравнением средних:\n",
    "средней выручкой на пользователя, средней длительностью просмотра и т.д. Для средних значений часто применима центральная предельная теорема. Можно приближенно считать, что средние значения в выборках из распределения будут распределены нормально. Причем это не зависит от формы исходного распределения. Центральная предельная теорема позволяет при сравнении средних использовать нормальное распределение в качестве функции правдоподобия.\n",
    "\n",
    "Есть несколько центральных предельных теорем [[CLT](https://en.wikipedia.org/wiki/Central_limit_theorem)].\n",
    "Одна из формулировок следующая. Пусть есть последовательность независимых одинаково распределенных случайных величин $X_1, X_2, \\dots$ с конечными математическим ожиданием $\\mu$ и дисперсией $\\sigma^2$. Пусть $\\bar{X}_N = \\frac{1}{N} \\sum_{i=1}^{N} X_i$ их выборочное среднее. Тогда при стремящемся к бесконечности $N$ распределение центрированных и масштабированных выборочных средних сходится к нормальному распределению [[NormDist](https://en.wikipedia.org/wiki/Normal_distribution), [SciPyNorm](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.norm.html?highlight=norm)] со средним значением 0 и дисперсией 1. Сходимость понимается как сходимость по распределению [[RandVarsConv](https://en.wikipedia.org/wiki/Convergence_of_random_variables#Convergence_in_distribution)].\n",
    "\n",
    "$$\n",
    "P \\left( \\frac{\\bar{X}_N - \\mu}{\\sigma / \\sqrt{N}} = x \\right) \\to Norm(x; 0, 1), \\quad N \\to \\infty\n",
    "\\\\\n",
    "Norm(x ; \\mu, \\sigma^2) = \\frac{1}{\\sqrt{2 \\pi \\sigma^2}} e^{-\\tfrac{(x-\\mu)^2}{2 \\sigma^2} }\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "509c0cff",
   "metadata": {},
   "source": [
    "Неформально этот результат можно применить следующим образом. Если взять произвольное распределение со средним значением $\\mu$ и диспресий $\\sigma^2$, выбирать из него сэмплы длины $N$ и считать среднее в каждом сэмпле, то средние значения сэмплов будут распределены приблизительно нормально $Norm(\\mu, \\sigma^2/N)$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4455a8b2",
   "metadata": {},
   "source": [
    "<center>\n",
    "<img src=\"./figs/central_limit_theorem_ru.png\" alt=\"Центральная предельная теорема\" width=\"800\"/>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e62f84cf",
   "metadata": {},
   "source": [
    "Центральная предельная теорема говорит о сходимости к нормальному распределению центрированных и масштабированных выборочных средних $\\bar{X}_N$ при стремлении $N$ к бесконечности. Для фиксированного конечного числа $N$ нормальное распределение не гарантируется. При этом есть теоремы, дающие оценку отличия распределения суммы конечного количества случайных величин от нормального - см. [[BerryEsseenTheorem](https://en.wikipedia.org/wiki/Berry%E2%80%93Esseen_theorem)]. Отличие зависит как от количества слагаемых, так и от параметров распределения. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb4bec0",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 1\n",
    "sample_len = 100\n",
    "n_samples = 1000\n",
    "\n",
    "exact_dist = stats.gamma(a=a)\n",
    "samp = exact_dist.rvs(size=(n_samples, sample_len))\n",
    "means = np.array([x.mean() for x in samp])\n",
    "clt_mu = exact_dist.mean()\n",
    "clt_stdev = exact_dist.std() / np.sqrt(sample_len)\n",
    "means_stdev = means.std()\n",
    "\n",
    "x = np.linspace(0, 10, 1000)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=exact_dist.pdf(x), \n",
    "                         mode='lines', line_color='black', line_dash='solid', name='Исходное распределение'))\n",
    "fig.add_trace(go.Histogram(x=np.concatenate(samp), histnorm='probability density', name='Выборка', nbinsx=500,\n",
    "                           marker_color='black', opacity=0.3))\n",
    "#fig.add_vline(exact_dist.mean(), name='Точное среднее')\n",
    "fig.add_trace(go.Scatter(x=x, y=stats.norm.pdf(x, loc=clt_mu, scale=clt_stdev), \n",
    "                         mode='lines', line_color='black', line_dash='dash', name='ЦПТ-распределение'))\n",
    "fig.add_trace(go.Histogram(x=means, histnorm='probability density', name='Выборочные средние', nbinsx=50,\n",
    "                           marker_color='green', opacity=0.5))\n",
    "fig.update_layout(title='Выборочные средние',\n",
    "                  xaxis_title='x',\n",
    "                  yaxis_title='Плотность вероятности',\n",
    "                  barmode='overlay',\n",
    "                  hovermode=\"x\",\n",
    "                  height=550)\n",
    "fig.update_layout(xaxis_range=[0, 5])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61eb7b62",
   "metadata": {},
   "source": [
    "В приведенной формулировке центральная предельная теорема требует существования конечных среднего и дисперсии у исходного распределения. Примерами распределений, для которых эти свойства могут не выполнятся, являются распределение Парето [[ParetoDist](https://en.wikipedia.org/wiki/Pareto_distribution), [SciPyPareto](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.pareto.html)] и близкое к нему распределение Ломакса [[LomaxDist](https://en.wikipedia.org/wiki/Lomax_distribution), [SciPyLomax](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.lomax.html)]. Плотность вероятности последнего имеет вид\n",
    "\n",
    "$$\n",
    "P(x; c) = \\frac{c}{(1 + x )^{c + 1}}, \\quad x \\ge 0, c > 0.\n",
    "$$\n",
    "\n",
    "При значениях параметра $c$ меньше или равном 2 дисперсия распределения Ломакса не является конечной. \n",
    "На графиках ниже приведена гистограмма средних в сэмплах и нормальное распределение с параметрами, равными среднему и дисперсии средних сэмплов.\n",
    "\n",
    "На практике распределения ограничены. Поэтому дисперсии и средние конечные. Однако, выборки могут быть сильно перекошены. Для выполнения ЦПТ может требоваться большое количество точек."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6847652f",
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 1.7\n",
    "sample_len = 500\n",
    "n_samples = 1000\n",
    "\n",
    "exact_dist = stats.lomax(c=c)\n",
    "samp = exact_dist.rvs(size=(n_samples, sample_len))\n",
    "means = np.array([x.mean() for x in samp])\n",
    "clt_mu = exact_dist.mean()\n",
    "clt_stdev = exact_dist.std() / np.sqrt(sample_len)\n",
    "means_stdev = means.std()\n",
    "\n",
    "xaxis_max=10\n",
    "x = np.linspace(0, xaxis_max, 2000)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=exact_dist.pdf(x), \n",
    "                         mode='lines', line_color='black', line_dash='solid', name='Исходное распределение'))\n",
    "fig.add_trace(go.Histogram(x=np.concatenate(samp)[np.concatenate(samp) < xaxis_max], histnorm='probability density', \n",
    "                           name='Выборка', nbinsx=500,\n",
    "                           marker_color='black', opacity=0.3))\n",
    "#fig.add_vline(exact_dist.mean(), name='Точное среднее')\n",
    "fig.add_trace(go.Scatter(x=x, y=stats.norm.pdf(x, loc=clt_mu, scale=means_stdev), \n",
    "                         mode='lines', line_color='black', line_dash='dash', name='ЦПТ-подобное распределение'))\n",
    "fig.add_trace(go.Histogram(x=means, histnorm='probability density', name='Выборочные средние', nbinsx=150,\n",
    "                          marker_color='green', opacity=0.5))\n",
    "fig.update_layout(title='Выборочные средние',\n",
    "                  xaxis_title='x',\n",
    "                  yaxis_title='Плотность вероятности',\n",
    "                  barmode='overlay',\n",
    "                  hovermode=\"x\",\n",
    "                  xaxis_range=[0, xaxis_max],\n",
    "                  height=550)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ebb9782",
   "metadata": {},
   "source": [
    "Сопряженное априорное распределение для нормальной функции правдоподобия.  \n",
    "Один параметр: $\\mu$ меняется, $\\sigma$ фиксировано.  \n",
    "Модель с меняющимися $\\mu$ и $\\sigma$ см. отдельно.  \n",
    "Сопряженное априорное распределение - нормальное распределение.\n",
    "\n",
    "$$\n",
    "P(data | model) = Norm(x | \\mu, \\sigma_x^2) = \n",
    "\\frac{1}{\\sqrt{2 \\pi \\sigma_x^2}} e^{-\\tfrac{(x - \\mu)^2}{2 \\sigma_x^2}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "P(model) = Norm(\\mu | \\mu_0, \\sigma_0^2) = \n",
    "\\frac{1}{\\sqrt{2 \\pi \\sigma_{0}^2}} e^{-\\tfrac{(\\mu-\\mu_0)^2}{2 \\sigma_{0}^2}} \n",
    "$$\n",
    "\n",
    "Для $N$ точек:\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "P(model | data) \n",
    "& \\propto\n",
    "\\prod_i^N\n",
    "Norm(x_i | \\mu, \\sigma_x^2)\n",
    "Norm(\\mu | \\mu_0, \\sigma_0^2)\n",
    "\\\\\n",
    "& \\propto_{\\mu}\n",
    "\\prod_i^N\n",
    "e^{-\\tfrac{(x_i - \\mu)^2}{2 \\sigma_x^2}}\n",
    "e^{-\\tfrac{(\\mu-\\mu_0)^2}{2 \\sigma_0^2}} \n",
    "\\\\\n",
    "& \\propto_{\\mu}\n",
    "e^{-\\mu^2 \\left[\\tfrac{N}{2 \\sigma_x^2} + \\tfrac{1}{2 \\sigma_0^2} \\right] + \n",
    "   2\\mu \\left[\\tfrac{\\mu_0}{2 \\sigma_0^2} + \\tfrac{1}{2 \\sigma_x^2} \\sum_i^N x_i \\right]}\n",
    "\\\\\n",
    "& \\propto_{\\mu}\n",
    "e^{-\\tfrac{(\\mu - \\mu_N)^2}{2 \\sigma_N^2}}\n",
    "= Norm(\\mu | \\mu_N, \\sigma_N^2),\n",
    "\\quad\n",
    "\\sigma_N^2 = \\frac{\\sigma_0^2 \\sigma_x^2}{\\sigma_x^2 + N \\sigma_0^2},\n",
    "\\quad\n",
    "\\mu_N = \\mu_0 \\frac{\\sigma_N^2}{\\sigma_0^2} + \\frac{\\sigma_N^2}{\\sigma_x^2} \\sum_i^N x_i\n",
    "\\end{split}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eda70fb7",
   "metadata": {},
   "source": [
    "Проверка оцеки параметров нормального распределения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf7c474",
   "metadata": {},
   "outputs": [],
   "source": [
    "ConjugateNormalParams = namedtuple('ConjugateNormalParams', 'mu sigma sx')\n",
    "\n",
    "def initial_params_normal(mu, sigma, sx):\n",
    "    return ConjugateNormalParams(mu=mu, sigma=sigma, sx=sx)\n",
    "\n",
    "def posterior_params_normal(data, initial_pars):\n",
    "    N = len(data)\n",
    "    sigma_n_2 = (initial_pars.sigma**2 * initial_pars.sx**2) / (initial_pars.sx**2 + N * initial_pars.sigma**2)\n",
    "    mu_n = initial_pars.mu * sigma_n_2 / initial_pars.sigma**2 + np.sum(data) * sigma_n_2 / initial_pars.sx**2    \n",
    "    return ConjugateNormalParams(mu=mu_n, sigma=np.sqrt(sigma_n_2), sx=initial_pars.sx)\n",
    "\n",
    "def posterior_mu_dist(params):\n",
    "    return stats.norm(loc=params.mu, scale=params.sigma)\n",
    "\n",
    "def posterior_rvs(params, nsamp):\n",
    "    mus = stats.norm.rvs(loc=params.mu, scale=params.sigma, size=nsamp)\n",
    "    return stats.norm.rvs(loc=mus, scale=params.sx, size=nsamp)\n",
    "    \n",
    "# def posterior_binom_approx_95pdi(post_dist):\n",
    "#     lower = post_dist.ppf(0.025)\n",
    "#     upper = post_dist.ppf(0.975)\n",
    "#     return lower, upper\n",
    "\n",
    "# def prob_pb_gt_pa(post_dist_A, post_dist_B, post_samp=100_000):\n",
    "#     sa = post_dist_A.rvs(size=post_samp)\n",
    "#     sb = post_dist_B.rvs(size=post_samp)\n",
    "#     b_gt_a = np.sum(sb > sa)\n",
    "#     return b_gt_a / post_samp\n",
    "\n",
    "mu = 3\n",
    "sigma = 1\n",
    "nsample = 1000\n",
    "\n",
    "exact_dist = stats.norm(loc=mu, scale=sigma)\n",
    "data = exact_dist.rvs(nsample)\n",
    "\n",
    "# todo: avoid setting from data\n",
    "sx = np.std(data)\n",
    "mu0 = data[0]\n",
    "sigma0 = sx\n",
    "\n",
    "pars = initial_params_normal(mu=mu0, sigma=sigma0, sx=sx)\n",
    "pars = posterior_params_normal(data[1:], pars)\n",
    "\n",
    "post_mu = posterior_mu_dist(pars)\n",
    "\n",
    "npostsamp = 10000\n",
    "post_samp = posterior_rvs(pars, npostsamp)\n",
    "\n",
    "x = np.linspace(0, 10, 1000)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=exact_dist.pdf(x), line_color='black', name='Точное'))\n",
    "fig.add_trace(go.Scatter(x=x, y=post_mu.pdf(x), line_color='blue', name='$\\mbox{Оценка }\\mu$'))\n",
    "fig.add_trace(go.Scatter(x=[np.sum(data)/len(data), np.sum(data)/len(data)], y=[0, max(post_mu.pdf(x))], \n",
    "                         line_color='black', mode='lines', line_dash='dash', name='Среднее в выборке'))\n",
    "fig.add_trace(go.Scatter(x=[exact_dist.mean(), exact_dist.mean()], y=[0, max(post_mu.pdf(x))*1.05], \n",
    "                         line_color='red', mode='lines', line_dash='dash', name='Точное среднее'))\n",
    "fig.add_trace(go.Histogram(x=post_samp, histnorm='probability density', name='Апострериорное', nbinsx=100,\n",
    "                           marker_color='green', opacity=0.5))\n",
    "fig.update_layout(title='Апостериорное распределение',\n",
    "                  xaxis_title='$\\mu$',\n",
    "                  yaxis_title='Плотность вероятности',\n",
    "                  #xaxis_range=[0, 10],\n",
    "                  barmode='overlay',\n",
    "                  hovermode=\"x\",\n",
    "                  height=500)                  \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0832248a",
   "metadata": {},
   "source": [
    "ЦПТ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37578db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reshape_and_compute_means(sample, n_split):\n",
    "    n_means = len(sample) // n_split\n",
    "    samp_reshaped = np.reshape(sample[0 : n_means * n_split], (n_means, n_split))\n",
    "    means = np.array([x.mean() for x in samp_reshaped])\n",
    "    return means\n",
    "\n",
    "def exact_clt_dist(exact_dist, n_split):\n",
    "    clt_mu = exact_dist.mean()\n",
    "    clt_stdev = exact_dist.std() / np.sqrt(n_split)\n",
    "    return stats.norm(loc=clt_mu, scale=clt_stdev)\n",
    "\n",
    "def sample_clt_dist(means):\n",
    "    clt_mu = means.mean()\n",
    "    clt_std = means.std()\n",
    "    return stats.norm(loc=clt_mu, scale=clt_std)\n",
    "\n",
    "nsample = 30000\n",
    "npostsamp = 50000\n",
    "\n",
    "a = 4\n",
    "b = 2\n",
    "exact_dist = stats.gamma(a=a, scale=1/b)\n",
    "data = exact_dist.rvs(nsample)\n",
    "\n",
    "nsplit = 30\n",
    "means = reshape_and_compute_means(data, nsplit)\n",
    "clt_dist_exact = exact_clt_dist(exact_dist, nsplit)\n",
    "#clt_dist_samp = sample_clt_dist(means)\n",
    "\n",
    "\n",
    "x = np.linspace(0, 10, 1000)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=exact_dist.pdf(x), \n",
    "                         mode='lines', line_color='black', line_dash='solid', name='Исходное распределение'))\n",
    "fig.add_trace(go.Histogram(x=data, histnorm='probability density', name='Выборка', nbinsx=500,\n",
    "                           marker_color='black', opacity=0.3))\n",
    "#fig.add_vline(exact_dist.mean(), name='Точное среднее')\n",
    "fig.add_trace(go.Scatter(x=x, y=clt_dist_exact.pdf(x), \n",
    "                         mode='lines', line_color='black', line_dash='dash', name='ЦПТ-распределение'))\n",
    "fig.add_trace(go.Histogram(x=means, histnorm='probability density', name='Выборочные средние', nbinsx=50,\n",
    "                           marker_color='green', opacity=0.5))\n",
    "fig.update_layout(title='Выборочные средние',\n",
    "                  xaxis_title='x',\n",
    "                  yaxis_title='Плотность вероятности',\n",
    "                  barmode='overlay',\n",
    "                  hovermode=\"x\",\n",
    "                  height=550)\n",
    "fig.update_layout(xaxis_range=[0, 5])\n",
    "fig.show()\n",
    "\n",
    "\n",
    "\n",
    "# todo: avoid setting from data\n",
    "sx = np.std(means)\n",
    "mu0 = means[0]\n",
    "sigma0 = sx\n",
    "pars = initial_params_normal(mu=mu0, sigma=sigma0, sx=sx)\n",
    "pars = posterior_params_normal(means[1:], pars)\n",
    "post_mu = posterior_mu_dist(pars)\n",
    "post_samp = posterior_rvs(pars, npostsamp)\n",
    "\n",
    "\n",
    "x = np.linspace(0, 10, 10000)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=post_mu.pdf(x), line_color='blue', name='$\\mbox{Оценка }\\mu$'))\n",
    "fig.add_trace(go.Scatter(x=[np.sum(data)/len(data), np.sum(data)/len(data)], y=[0, max(post_mu.pdf(x))], \n",
    "                         line_color='black', mode='lines', line_dash='dash', name='Среднее в выборке'))\n",
    "fig.add_trace(go.Scatter(x=[exact_dist.mean(), exact_dist.mean()], y=[0, max(post_mu.pdf(x))*1.05], \n",
    "                         line_color='red', mode='lines', line_dash='dash', name='Точное среднее'))\n",
    "fig.update_layout(title='$\\mbox{Оценка }\\mu$',\n",
    "                  xaxis_title='$\\mu$',\n",
    "                  yaxis_title='Плотность вероятности',\n",
    "                  #xaxis_range=[0, 10],\n",
    "                  barmode='overlay',\n",
    "                  hovermode=\"x\",\n",
    "                  height=500)                  \n",
    "fig.show()\n",
    "\n",
    "\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=exact_dist.pdf(x), line_dash='solid', line_color='black', name='Точное'))\n",
    "fig.add_trace(go.Histogram(x=post_samp, histnorm='probability density', name='$\\mbox{Апострериорное, }\\mu$', nbinsx=300,\n",
    "                           marker_color='green', opacity=0.2))\n",
    "fig.add_trace(go.Scatter(x=x, y=clt_dist_exact.pdf(x), \n",
    "                         mode='lines', line_color='black', line_dash='dash', name='ЦПТ-распределение'))\n",
    "fig.add_trace(go.Histogram(x=means, histnorm='probability density', name='Выборочные средние', nbinsx=100,\n",
    "                           marker_color='green', opacity=0.5))\n",
    "fig.update_layout(title='Апостериорное распределение',\n",
    "                  xaxis_title='x',\n",
    "                  yaxis_title='Плотность вероятности',\n",
    "                  #xaxis_range=[0, 10],\n",
    "                  barmode='overlay',\n",
    "                  hovermode=\"x\",\n",
    "                  height=500)                  \n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0693f93",
   "metadata": {},
   "source": [
    "Распределение $\\mu$ уже распределения выборочных средних.  \n",
    "Это разные распределения. Распределение $\\mu$ - оценка точного среднего, выборочные средние - распределение выборочных средних исходного распределения - у них больше диспресия."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82526e6d",
   "metadata": {},
   "source": [
    "Сравнение групп"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab84338",
   "metadata": {},
   "outputs": [],
   "source": [
    "# p_A = 0.1\n",
    "# p_B = p_A * 1.05\n",
    "# nsample = 1000\n",
    "\n",
    "# exact_dist_A = stats.bernoulli(p=p_A)\n",
    "# exact_dist_B = stats.bernoulli(p=p_B)\n",
    "# data_A = exact_dist_A.rvs(nsample)\n",
    "# data_B = exact_dist_B.rvs(nsample)\n",
    "\n",
    "# post_dist_A = posterior_dist_binom(ns=np.sum(data_A), ntotal=len(data_A))\n",
    "# post_dist_B = posterior_dist_binom(ns=np.sum(data_B), ntotal=len(data_B))\n",
    "\n",
    "# x = np.linspace(0, 1, 1000)\n",
    "# fig = go.Figure()\n",
    "# #fig.add_vline(x=exact_dist.mean(), line_dash='dash', name='Exact')\n",
    "# fig.add_trace(go.Scatter(x=x, y=post_dist_A.pdf(x), line_color='black', name='A'))\n",
    "# fig.add_trace(go.Scatter(x=x, y=post_dist_B.pdf(x), line_color='black', opacity=0.2, name='B'))\n",
    "# fig.add_trace(go.Scatter(x=[exact_dist_A.mean(), exact_dist_A.mean()], y=[0, max(post_dist_A.pdf(x))*1.05], \n",
    "#                          mode='lines', line_dash='dash', line_color='black', name='Точное A'))\n",
    "# fig.add_trace(go.Scatter(x=[exact_dist_B.mean(), exact_dist_B.mean()], y=[0, max(post_dist_A.pdf(x))*1.05], \n",
    "#                          mode='lines', line_dash='dash', line_color='black', opacity=0.2, name='Точное B'))\n",
    "# fig.update_layout(title='Апостериорные распределения',\n",
    "#                   xaxis_title='p',\n",
    "#                   yaxis_title='Плотность вероятности',\n",
    "#                   xaxis_range=[p_A/2, p_A*2],\n",
    "#                   hovermode=\"x\",\n",
    "#                   height=500)\n",
    "# fig.show()\n",
    "\n",
    "# print(f'P(pB > pA): {prob_pb_gt_pa(post_dist_A, post_dist_B)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "468b9afd",
   "metadata": {},
   "source": [
    "Правильно угаданные варианты"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d89dc531",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cmp = pd.DataFrame(columns=['A', 'B', 'best_exact', 'exp_samp_size', 'A_exp', 'B_exp', 'best_exp', 'p_best'])\n",
    "\n",
    "# p = 0.1\n",
    "# nexps = 100\n",
    "# cmp['A'] = [p] * nexps\n",
    "# cmp['B'] = p * (1 + stats.uniform.rvs(loc=-0.05, scale=0.1, size=nexps))\n",
    "# cmp['best_exact'] = cmp.apply(lambda r: 'B' if r['B'] > r['A'] else 'A', axis=1)\n",
    "\n",
    "# prob_stop = 0.95\n",
    "# for i in range(nexps):\n",
    "#     pA = cmp.at[i, 'A']\n",
    "#     pB = cmp.at[i, 'B']\n",
    "#     exact_dist_A = stats.bernoulli(p=pA)\n",
    "#     exact_dist_B = stats.bernoulli(p=pB)\n",
    "#     n_samp_max = 10_000_000\n",
    "#     n_samp_total = 0\n",
    "#     n_samp_step = 10_000\n",
    "#     ns_A = 0\n",
    "#     ns_B = 0\n",
    "#     while n_samp_total < n_samp_max:\n",
    "#         dA = exact_dist_A.rvs(n_samp_step)\n",
    "#         dB = exact_dist_B.rvs(n_samp_step)\n",
    "#         n_samp_total += n_samp_step\n",
    "#         ns_A = ns_A + np.sum(dA)\n",
    "#         ns_B = ns_B + np.sum(dB)\n",
    "#         post_dist_A = posterior_dist_binom(ns=ns_A, ntotal=n_samp_total)\n",
    "#         post_dist_B = posterior_dist_binom(ns=ns_B, ntotal=n_samp_total)\n",
    "#         pb_gt_pa = prob_pb_gt_pa(post_dist_A, post_dist_B)\n",
    "#         best_gr = 'B' if pb_gt_pa >= prob_stop else 'A' if (1 - pb_gt_pa) >= prob_stop else None\n",
    "#         if best_gr:\n",
    "#             cmp.at[i, 'A_exp'] = post_dist_A.mean()\n",
    "#             cmp.at[i, 'B_exp'] = post_dist_B.mean()\n",
    "#             cmp.at[i, 'exp_samp_size'] = n_samp_total\n",
    "#             cmp.at[i, 'best_exp'] = best_gr\n",
    "#             cmp.at[i, 'p_best'] = pb_gt_pa\n",
    "#             break\n",
    "#     print(f'done {i}: {n_samp_total}, {best_gr}, {pb_gt_pa}')\n",
    "\n",
    "# cmp['correct'] = cmp['best_exact'] == cmp['best_exp']\n",
    "# display(cmp.head(10))\n",
    "# cor_guess = np.sum(cmp['correct'])\n",
    "# print(f\"Nexp: {nexps}, Correct Guesses: {cor_guess}, Accuracy: {cor_guess / nexps}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a347639",
   "metadata": {},
   "source": [
    "# Выручка на пользователя"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a908983d",
   "metadata": {},
   "source": [
    "В А/Б тестах для оценки денежного эффекта сравнивают выручку на пользователя между группами $P_{пользователи}(x)$. Для моделирования удобно выделить выручку на платящего $P_{платящие}(x)$. При конверсии в оплату $p$ распределение клиентов с ненулевой выручкой $p P_{платящие}(x)$. С вероятностью $1-p$ пользователь неплатящий, т.е. с нулевой выручкой.\n",
    "\n",
    "$$\n",
    "P_{пользователи}(x) = \n",
    "\\begin{cases}\n",
    "1-p, \\, x = 0\n",
    "\\\\\n",
    "p P_{платящие}(x), \\, x > 0\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "Оценка конверсии в оплату $p$ делалась ранее. Выручку на платящего можно моделировать логнормальным распределением [[LognormDist](https://en.wikipedia.org/wiki/Log-normal_distribution),\n",
    "[SciPyLognorm](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.lognorm.html)] или распределением Парето [[ParetoDist](https://en.wikipedia.org/wiki/Pareto_distribution)] по аналогии с распределением богатства [пример]. Для транзакционных сервисов, в частности маркетплейсов, лучше подходит логнормальное распределение."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85b73ebe",
   "metadata": {},
   "source": [
    "Случайная величина логнормальная $X \\sim Lognormal(\\mu, \\sigma^2)$, если логарифм распределен нормально $\\ln(X) \\sim Norm(\\mu, \\sigma^2)$. Плотность вероятности\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "f(x) & = \\frac{1}{x \\sigma \\sqrt{2 \\pi}} e^{-\\tfrac{(\\ln(x) - \\mu)^2}{2 \\sigma^2}} .\n",
    "\\end{split}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e88bed1",
   "metadata": {},
   "source": [
    "Примеры логнормального распределения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "943467ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 10, 2000)\n",
    "fig = go.Figure()\n",
    "for sigma, loc, scale in [(1, 0, 1), (2, 0, 1), (1, 0, 2)]:\n",
    "    fig.add_trace(go.Scatter(x=x, y=stats.lognorm.pdf(x, s=sigma, loc=loc, scale=scale), \n",
    "                             mode='lines', \n",
    "                             name=f's={sigma}, loc={loc}, scale={scale}'))\n",
    "fig.update_layout(title='Логнормальное распределение',\n",
    "                  xaxis_title='x',\n",
    "                  yaxis_title='Плотность вероятности',\n",
    "                  hovermode=\"x\",\n",
    "                  height=550)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "014435d5",
   "metadata": {},
   "source": [
    "Сопряженное априорное распределение для нормальной функции правдоподобия.  \n",
    "Один параметр: $\\mu$ меняется, $\\sigma$ фиксировано.  \n",
    "Модель с меняющимися $\\mu$ и $\\sigma$ см. отдельно.  \n",
    "Сопряженное априорное распределение - нормальное распределение.\n",
    "\n",
    "$$\n",
    "P(data | model) = Lognorm(x | \\mu, \\sigma_x^2) = \n",
    "\\frac{1}{x \\sqrt{2 \\pi \\sigma_x^2}} e^{-\\tfrac{(\\ln x - \\mu)^2}{2 \\sigma_x^2}}\n",
    "$$\n",
    "\n",
    "$$\n",
    "P(model) = Norm(\\mu | \\mu_0, \\sigma_0^2) = \n",
    "\\frac{1}{\\sqrt{2 \\pi \\sigma_{0}^2}} e^{-\\tfrac{(\\mu-\\mu_0)^2}{2 \\sigma_{0}^2}} \n",
    "$$\n",
    "\n",
    "Для $N$ точек:\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "P(model | data) \n",
    "& \\propto\n",
    "\\prod_i^N\n",
    "Lognorm(x_i | \\mu, \\sigma_x^2)\n",
    "Norm(\\mu | \\mu_0, \\sigma_0^2)\n",
    "\\\\\n",
    "& \\propto_{\\mu}\n",
    "\\prod_i^N\n",
    "e^{-\\tfrac{(\\ln x_i - \\mu)^2}{2 \\sigma_x^2}}\n",
    "e^{-\\tfrac{(\\mu-\\mu_0)^2}{2 \\sigma_0^2}} \n",
    "\\\\\n",
    "& \\propto_{\\mu}\n",
    "e^{-\\mu^2 \\left[\\tfrac{N}{2 \\sigma_x^2} + \\tfrac{1}{2 \\sigma_0^2} \\right] + \n",
    "   2\\mu \\left[\\tfrac{\\mu_0}{2 \\sigma_0^2} + \\tfrac{1}{2 \\sigma_x^2} \\sum_i^N \\ln x_i \\right]}\n",
    "\\\\\n",
    "& \\propto_{\\mu}\n",
    "e^{-\\tfrac{(\\mu - \\mu_N)^2}{2 \\sigma_N^2}}\n",
    "= Norm(\\mu | \\mu_N, \\sigma_N^2),\n",
    "\\quad\n",
    "\\sigma_N^2 = \\frac{\\sigma_0^2 \\sigma_x^2}{\\sigma_x^2 + N \\sigma_0^2},\n",
    "\\quad\n",
    "\\mu_N = \\mu_0 \\frac{\\sigma_N^2}{\\sigma_0^2} + \\frac{\\sigma_N^2}{\\sigma_x^2} \\sum_i^N \\ln x_i\n",
    "\\end{split}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0789d8c8",
   "metadata": {},
   "source": [
    "Оценка параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3239f35b",
   "metadata": {},
   "outputs": [],
   "source": [
    "ConjugateLognormalParams = namedtuple('ConjugateLognormalParams', 'mu sigma sx')\n",
    "\n",
    "def initial_params_lognormal(mu, sigma, sx):\n",
    "    return ConjugateLognormalParams(mu=mu, sigma=sigma, sx=sx)\n",
    "\n",
    "def posterior_params_lognormal(data, initial_pars):\n",
    "    N = len(data)\n",
    "    lnx = np.log(data)\n",
    "    sigma_n_2 = (initial_pars.sigma**2 * initial_pars.sx**2) / (initial_pars.sx**2 + N * initial_pars.sigma**2)\n",
    "    mu_n = initial_pars.mu * sigma_n_2 / initial_pars.sigma**2 + np.sum(lnx) * sigma_n_2 / initial_pars.sx**2    \n",
    "    return ConjugateLognormalParams(mu=mu_n, sigma=np.sqrt(sigma_n_2), sx=initial_pars.sx)\n",
    "\n",
    "def posterior_mu_dist_lognormal(params):\n",
    "    return stats.norm(loc=params.mu, scale=params.sigma)\n",
    "\n",
    "def posterior_lognormal_rvs(params, nsamp):\n",
    "    mus = stats.norm.rvs(loc=params.mu, scale=params.sigma, size=nsamp)\n",
    "    return stats.lognorm.rvs(s=params.sx, loc=0, scale=np.exp(mus), size=nsamp)\n",
    "    \n",
    "s = 1\n",
    "loc = 0\n",
    "scale = 2.5\n",
    "nsample = 10000\n",
    "\n",
    "exact_dist = stats.lognorm(s=s, loc=loc, scale=scale)\n",
    "data = exact_dist.rvs(nsample)\n",
    "\n",
    "# todo: avoid setting from data\n",
    "lnx = np.log(data)\n",
    "sx = np.std(lnx)\n",
    "mu0 = lnx[0]\n",
    "sigma0 = sx\n",
    "\n",
    "pars = initial_params_lognormal(mu=mu0, sigma=sigma0, sx=sx)\n",
    "pars = posterior_params_lognormal(data[1:], pars)\n",
    "\n",
    "print(pars)\n",
    "\n",
    "post_mu = posterior_mu_dist_lognormal(pars)\n",
    "\n",
    "npostsamp = 10000\n",
    "post_samp = posterior_lognormal_rvs(pars, npostsamp)\n",
    "\n",
    "xaxis_max=20\n",
    "x = np.linspace(0, xaxis_max, 10000)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=exact_dist.pdf(x), line_color='black', name='Точное'))\n",
    "fig.add_trace(go.Scatter(x=[np.sum(data)/len(data), np.sum(data)/len(data)], y=[0, max(exact_dist.pdf(x))], \n",
    "                        line_color='black', mode='lines', line_dash='dash', name='Среднее в выборке'))\n",
    "fig.add_trace(go.Scatter(x=[exact_dist.mean(), exact_dist.mean()], y=[0, max(exact_dist.pdf(x))*1.05], \n",
    "                        line_color='red', mode='lines', line_dash='dash', name='Точное среднее'))\n",
    "fig.add_trace(go.Histogram(x=post_samp[post_samp < xaxis_max], histnorm='probability density', name='Апострериорное', nbinsx=100,\n",
    "                          marker_color='green', opacity=0.5))\n",
    "fig.update_layout(title='Апостериорное распределение',\n",
    "                  xaxis_title='$x$',\n",
    "                  yaxis_title='Плотность вероятности',\n",
    "                  #xaxis_range=[0, 10],\n",
    "                  barmode='overlay',\n",
    "                  hovermode=\"x\",\n",
    "                  height=500)                  \n",
    "fig.show()\n",
    "\n",
    "\n",
    "# xaxis_min=0\n",
    "# xaxis_max=2\n",
    "# x = np.linspace(xaxis_min, xaxis_max, 10000)\n",
    "# fig = go.Figure()\n",
    "# fig.add_trace(go.Scatter(x=x, y=post_mu.pdf(x), line_color='blue', name='$\\mbox{Оценка }\\mu$'))\n",
    "# # fig.add_trace(go.Scatter(x=[np.sum(data)/len(data), np.sum(data)/len(data)], y=[0, max(post_mu.pdf(x))], \n",
    "# #                         line_color='black', mode='lines', line_dash='dash', name='Среднее в выборке'))\n",
    "# # fig.add_trace(go.Scatter(x=[exact_dist.mean(), exact_dist.mean()], y=[0, max(post_mu.pdf(x))*1.05], \n",
    "# #                         line_color='red', mode='lines', line_dash='dash', name='Точное среднее'))\n",
    "# fig.update_layout(title='Апостериорное распределение',\n",
    "#                   xaxis_title='$x$',\n",
    "#                   yaxis_title='Плотность вероятности',\n",
    "#                   #xaxis_range=[0, 10],\n",
    "#                   barmode='overlay',\n",
    "#                   hovermode=\"x\",\n",
    "#                   height=500)                  \n",
    "# fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4dcfa8c",
   "metadata": {},
   "source": [
    "Сравнение 2 групп"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2411f12e",
   "metadata": {},
   "source": [
    "Доля правильно угаданных вариантов"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a346681e",
   "metadata": {},
   "source": [
    "# Заказы на платящего"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e16c3c5a",
   "metadata": {},
   "source": [
    "Заказы пользователя дискретная величина $P_{заказы}(n)$, $n \\in 1, 2, \\dots$. Можно ожидать лог-нормальное или степенное распределение - Парето, распределение Ципфа [[ZipfDist](https://en.wikipedia.org/wiki/Zipf%27s_law#Formal_definition)] $P(n) \\propto n^{-s}$. Модель с меньшими ограничениями - свои вероятности $p_i$ под каждое количество заказов. Пусть масимальное количество заказов $N$ ограничено, $n_i$ - количество пользователей с $i=1, 2, \\dots, N$ заказами, $p_i$ - вероятность сделать $i$ заказов. Функция правдоподобия задается мультиномиальным распределением [[MultiDist](https://en.wikipedia.org/wiki/Multinomial_distribution)]\n",
    "\n",
    "$$\n",
    "P(data|model) = P(n_1, \\dots, n_N) = \\frac{(n_1 + \\dots + n_N)!}{n_{1}! \\dots n_{N}!} p_{1}^{n_{1}} \\dots p_{N}^{n_{N}} .\n",
    "$$\n",
    "\n",
    "Распределение Дирихле [[DrDist](https://en.wikipedia.org/wiki/Dirichlet_distribution)] будет сопряженным априорным распределением\n",
    "\n",
    "$$\n",
    "P(model) = \n",
    "Dir \\left( p_{1}, \\dots, p_{N}; \\alpha_{1}, \\dots, \\alpha_{N} \\right) = \n",
    "\\dfrac{1}{B( \\alpha_{1}, \\dots, \\alpha_{N} )} \\prod_{i=1}^{N} p_{i}^{\\alpha_{i}-1},\n",
    "\\qquad\n",
    "\\sum_{i=1}^{N} p_i = 1,\n",
    "\\qquad\n",
    "p_i \\in [0, 1], \n",
    "\\qquad\n",
    "B(\\alpha_{1}, \\dots, \\alpha_{N}) = \n",
    "\\frac{\\prod \\limits_{i=1}^{N} \\Gamma( \\alpha_{i} )}\n",
    "{\\Gamma \\left( \\sum \\limits_{i=1}^{N} \\alpha_{i} \\right)} .\n",
    "$$\n",
    "\n",
    "Апостериорное распределение \n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "P(model | data) \n",
    "& \\propto\n",
    "\\frac{(n_1 + \\dots + n_N)!}{n_{1}! \\dots n_{N}!} p_{1}^{n_{1}} \\dots p_{N}^{n_{N}}\n",
    "\\dfrac{1}{B(\\alpha_{1}, \\dots ,\\alpha_{N})} \\prod _{i=1}^{N} p_{i}^{\\alpha_{i}-1}\n",
    "\\\\\n",
    "& \\propto\n",
    "\\prod_{i=1}^{N} p_{i}^{n_{i} + \\alpha_{i} - 1}\n",
    "\\\\\n",
    "& =\n",
    "Dir \\left( p_{1}, \\dots, p_{N}; n_1 + \\alpha_{1}, \\dots, n_N + \\alpha_{N} \\right)\n",
    "\\end{split}\n",
    "$$\n",
    "\n",
    "Маржинальными распределениями для каждого $p_i$ будут бета-распределения\n",
    "\n",
    "$$\n",
    "\\begin{split}\n",
    "f(p_i) = \n",
    "Beta( p_i; \\alpha_i, \\alpha_0 - \\alpha_i ),\n",
    "\\quad\n",
    "\\alpha_0 = \\sum_{i=1}^{N} \\alpha_i .\n",
    "\\end{split}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b73e2ef",
   "metadata": {},
   "source": [
    "Оценка параметров"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5714d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def initial_params_dr(N):\n",
    "    return np.ones(N)\n",
    "\n",
    "def posterior_params_dr(data, initial_pars):\n",
    "    u, c = np.unique(data, return_counts=True)\n",
    "    post_pars = np.copy(initial_pars)\n",
    "    for k, v in zip(u, c):\n",
    "        post_pars[k - 1] = post_pars[k - 1] + v\n",
    "    return post_pars\n",
    "\n",
    "def posterior_nords_rvs(params, nsamp):\n",
    "    nords = np.empty(nsamp)\n",
    "    probs = stats.dirichlet.rvs(alpha=params, size=nsamp)\n",
    "    for i, p in enumerate(probs):\n",
    "        nords[i] = np.argmax(stats.multinomial.rvs(n=1, p=p)) + 1\n",
    "    return nords\n",
    "\n",
    "def posterior_marginal_dist_pi(i, params):\n",
    "    imin = 1\n",
    "    p_i = stats.beta(a=params[i - imin], b=np.sum(params) - params[i - imin])\n",
    "    return p_i\n",
    "\n",
    "def posterior_pi_mean_95pdi(i, params):\n",
    "    p = posterior_marginal_dist_pi(i, params)\n",
    "    m = p.mean()\n",
    "    lower = p.ppf(0.025)\n",
    "    upper = p.ppf(0.975)\n",
    "    return m, lower, upper\n",
    "\n",
    "def posterior_nords_mean(params):\n",
    "    ex = 0\n",
    "    for i in range(1, len(params)+1):\n",
    "        m = posterior_marginal_dist_pi(i, params).mean()\n",
    "        ex += i * m\n",
    "    return ex\n",
    "\n",
    "Nmax = 30\n",
    "s = 1.5\n",
    "nsample = 1000\n",
    "\n",
    "exact_dist = stats.zipfian(a=s, n=Nmax)\n",
    "data = exact_dist.rvs(nsample)\n",
    "\n",
    "pars = initial_params_dr(Nmax)\n",
    "pars = posterior_params_dr(data, pars)\n",
    "\n",
    "post_samp = posterior_nords_rvs(pars, 100000)\n",
    "\n",
    "pi = [posterior_pi_mean_95pdi(i, pars) for i in range(1, Nmax+1)]\n",
    "\n",
    "x = np.arange(1, Nmax+1)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=exact_dist.pmf(x), name='Точное распределение Ципфа'))\n",
    "fig.add_trace(go.Histogram(x=data, histnorm='probability', name='Сэмпл', nbinsx=round(Nmax*2)))\n",
    "fig.add_trace(go.Histogram(x=post_samp, histnorm='probability', name='Апостериорное распределение', opacity=0.5, nbinsx=round(Nmax*2)))\n",
    "fig.add_trace(go.Scatter(x=x, \n",
    "                         y=[p[0] for p in pi],\n",
    "                         error_y=dict(type='data', symmetric=False, array=[p[2] - p[0] for p in pi], arrayminus=[p[0] - p[1] for p in pi]), \n",
    "                         name='$\\mbox{Оценки } p_i$',\n",
    "                         mode='markers'))\n",
    "fig.update_layout(title='Заказы на платящего',\n",
    "                  xaxis_title='$x$',\n",
    "                  yaxis_title='Вероятность',\n",
    "                  xaxis_range=[0, Nmax+1],\n",
    "                  hovermode=\"x\",\n",
    "                  barmode=\"group\",\n",
    "                  height=550)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8502fe",
   "metadata": {},
   "source": [
    "Сравнение двух групп"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6b5738",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prob_pb_gt_pa_postsamp(post_samp_a, post_samp_b):\n",
    "    if len(post_samp_a) != len(post_samp_b):\n",
    "        return None\n",
    "    b_gt_a = np.sum(post_samp_b > post_samp_a)\n",
    "    return b_gt_a / len(post_samp_a)\n",
    "\n",
    "Nmax = 30\n",
    "s_a = 2.7\n",
    "s_b = s_a * 1.03\n",
    "nsample = 3000\n",
    "\n",
    "exact_dist_a = stats.zipfian(a=s_a, n=Nmax)\n",
    "exact_dist_b = stats.zipfian(a=s_b, n=Nmax)\n",
    "data_a = exact_dist_a.rvs(nsample)\n",
    "data_b = exact_dist_b.rvs(nsample)\n",
    "\n",
    "pars_a = initial_params_dr(Nmax)\n",
    "pars_a = posterior_params_dr(data_a, pars_a)\n",
    "pars_b = initial_params_dr(Nmax)\n",
    "pars_b = posterior_params_dr(data_b, pars_b)\n",
    "\n",
    "post_samp_len = 100000\n",
    "post_samp_a = posterior_nords_rvs(pars_a, post_samp_len)\n",
    "post_samp_b = posterior_nords_rvs(pars_b, post_samp_len)\n",
    "\n",
    "pi_a = [posterior_pi_mean_95pdi(i, pars) for i in range(1, Nmax+1)]\n",
    "\n",
    "x = np.arange(1, Nmax+1)\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=x, y=exact_dist_a.pmf(x), name='Точное распределение A'))\n",
    "fig.add_trace(go.Scatter(x=x, y=exact_dist_b.pmf(x), name='Точное распределение A'))\n",
    "fig.add_vline(x=exact_dist_a.mean())\n",
    "fig.add_vline(x=exact_dist_b.mean())\n",
    "fig.add_trace(go.Histogram(x=post_samp_a, histnorm='probability', name='Апостериорное A', opacity=0.5, nbinsx=round(Nmax*2)))\n",
    "fig.add_trace(go.Histogram(x=post_samp_b, histnorm='probability', name='Апостериорное B', opacity=0.5, nbinsx=round(Nmax*2)))\n",
    "# fig.add_trace(go.Scatter(x=x, \n",
    "#                          y=[p[0] for p in pi],\n",
    "#                          error_y=dict(type='data', symmetric=False, array=[p[2] - p[0] for p in pi], arrayminus=[p[0] - p[1] for p in pi]), \n",
    "#                          name='$\\mbox{Оценки } p_i$',\n",
    "#                          mode='markers'))\n",
    "fig.update_layout(title='Заказы на платящего',\n",
    "                  xaxis_title='$x$',\n",
    "                  yaxis_title='Вероятность',\n",
    "                  xaxis_range=[0, Nmax+1],\n",
    "                  hovermode=\"x\",\n",
    "                  barmode=\"group\",\n",
    "                  height=550)\n",
    "fig.show()\n",
    "\n",
    "print(f'E[n_ords] A:, {posterior_nords_mean(pars_a)}, B: {posterior_nords_mean(pars_b)}')\n",
    "print(f'P(pB > pA): {prob_pb_gt_pa_postsamp(post_samp_a, post_samp_b)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e72371d",
   "metadata": {},
   "source": [
    "Доля правильно угаданных вариантов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec4fbc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmp = pd.DataFrame(columns=['A', 'B', 'best_exact', 'exp_samp_size', 'A_exp', 'B_exp', 'best_exp', 'p_best'])\n",
    "\n",
    "s = 2.7\n",
    "Nmax=30\n",
    "nexps = 100\n",
    "cmp['A'] = [s] * nexps\n",
    "cmp['B'] = s * (1 + stats.uniform.rvs(loc=-0.05, scale=0.1, size=nexps))\n",
    "cmp['best_exact'] = cmp.apply(lambda r: 'B' if r['B'] < r['A'] else 'A', axis=1)\n",
    "\n",
    "prob_stop = 0.90\n",
    "for i in range(nexps):\n",
    "    s_a = cmp.at[i, 'A']\n",
    "    s_b = cmp.at[i, 'B']\n",
    "    exact_dist_a = stats.zipfian(a=s_a, n=Nmax)\n",
    "    exact_dist_b = stats.zipfian(a=s_b, n=Nmax)\n",
    "    n_samp_max = 200000\n",
    "    n_samp_total = 0\n",
    "    n_samp_step = 10000\n",
    "    pars_a = initial_params_dr(Nmax)\n",
    "    pars_b = initial_params_dr(Nmax)\n",
    "    while n_samp_total < n_samp_max:\n",
    "        data_a = exact_dist_a.rvs(n_samp_step)\n",
    "        data_b = exact_dist_b.rvs(n_samp_step)\n",
    "        n_samp_total += n_samp_step\n",
    "        pars_a = posterior_params_dr(data_a, pars_a)\n",
    "        pars_b = posterior_params_dr(data_b, pars_b)\n",
    "        post_samp_len = 10000\n",
    "        post_samp_a = posterior_nords_rvs(pars_a, post_samp_len)\n",
    "        post_samp_b = posterior_nords_rvs(pars_b, post_samp_len)\n",
    "        pb_gt_pa = prob_pb_gt_pa_postsamp(post_samp_a, post_samp_b)\n",
    "        best_gr = 'B' if pb_gt_pa >= prob_stop else 'A' if (1 - pb_gt_pa) >= prob_stop else None\n",
    "        if best_gr:\n",
    "            cmp.at[i, 'A_exp'] = post_dist_A.mean()\n",
    "            cmp.at[i, 'B_exp'] = post_dist_B.mean()\n",
    "            cmp.at[i, 'exp_samp_size'] = n_samp_total\n",
    "            cmp.at[i, 'best_exp'] = best_gr\n",
    "            cmp.at[i, 'p_best'] = pb_gt_pa\n",
    "            break\n",
    "    print(f'done {i}: {n_samp_total}, {best_gr}, {pb_gt_pa}')\n",
    "\n",
    "cmp['correct'] = cmp['best_exact'] == cmp['best_exp']\n",
    "display(cmp.head(10))\n",
    "cor_guess = np.sum(cmp['correct'])\n",
    "print(f\"Nexp: {nexps}, Correct Guesses: {cor_guess}, Accuracy: {cor_guess / nexps}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00dfd8bb",
   "metadata": {},
   "source": [
    "# Средний чек"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03324297",
   "metadata": {},
   "source": [
    "# Заключение"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e2b3dfc",
   "metadata": {},
   "source": [
    "# Ссылки\n",
    "\n",
    "[BinomDist] - [Binomial Distribution](https://en.wikipedia.org/wiki/Binomial_distribution), *Wikipedia.*  \n",
    "[SciPyBinom] - [scipy.stats.binom](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.binom.html), *SciPy Reference.*   \n",
    "[BetaDist] - [Beta Distribution](https://en.wikipedia.org/wiki/Beta_distribution), *Wikipedia.*     \n",
    "[SciPyBeta] - [scipy.stats.beta](https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.beta.html), *SciPy Reference.*   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "543017df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51bd976",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f85f74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f59967f8",
   "metadata": {},
   "source": [
    "Пациент приходит ко врачу. Симптомы - температура.   \n",
    "Врач делает предположения на счет болезней - простуда, пневмония и т.д.  \n",
    "Врач прикидывает, при каких болезнях эти симптомы вероятны.  \n",
    "Дальше с учетом своего опыта и распространенности болезней ставит диагноз.  \n",
    "\n",
    "Можно записать рассуждения количественно.\n",
    "Для диагноза интересует $P(болезнь | симптомы)$.  \n",
    "Вначале выбирается список возможных болезней и для каждой вычисляется $P(симптомы | болезнь)$.  \n",
    "Распространенность болезней в регионе и опыт врача учитывает $P(болезнь)$.  \n",
    "\n",
    "$$\n",
    "P(болезнь | симптомы) \\approx P(симптомы | болезнь) P(болезнь)\n",
    "$$\n",
    "\n",
    "На этом примере видны компоненты байесовского моделирования.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed70ecf7",
   "metadata": {},
   "source": [
    "Let’s walk through an example of using the **Bayesian approach** to guess what’s inside a present based on the **size of the box**.\n",
    "\n",
    "### Setting:\n",
    "You receive a box as a gift, but you don’t know what’s inside. Based on the **size of the box**, you want to update your belief about what the present might be. You have a few reasonable guesses, and you’ll use **Bayes’ Theorem** to compute the posterior probabilities of each possible item given the size of the box.\n",
    "\n",
    "### Hypotheses (Possible Contents of the Box):\n",
    "You consider three possible items that could be inside the box:\n",
    "\n",
    "- \\( H_1 \\): A **book**.\n",
    "- \\( H_2 \\): A **pair of shoes**.\n",
    "- \\( H_3 \\): A **laptop**.\n",
    "\n",
    "### Prior Probabilities:\n",
    "Before looking at the size of the box, you have some prior beliefs about what the gift could be based on your knowledge of the person who gave you the gift. For example:\n",
    "\n",
    "- \\( P(H_1) = 0.3 \\) (They often give books as gifts).\n",
    "- \\( P(H_2) = 0.5 \\) (They’ve given shoes before).\n",
    "- \\( P(H_3) = 0.2 \\) (They once mentioned buying you a laptop).\n",
    "\n",
    "### Likelihoods (Based on the Size of the Box):\n",
    "Now, you observe the **size of the box**, and you know how likely it is for each possible item to fit into a box of this size. Suppose the box is medium-sized. Based on that, you assign the following likelihoods:\n",
    "\n",
    "- \\( P(\\text{Medium box} \\mid H_1) = 0.8 \\) (Books often come in medium-sized boxes).\n",
    "- \\( P(\\text{Medium box} \\mid H_2) = 0.6 \\) (Shoes could fit in a medium-sized box, but not always).\n",
    "- \\( P(\\text{Medium box} \\mid H_3) = 0.3 \\) (Laptops usually come in larger boxes, so this is less likely).\n",
    "\n",
    "### Evidence (Total Probability of Observing the Box Size):\n",
    "The total probability of receiving a **medium-sized box** is calculated by summing over all the possible contents:\n",
    "\\[\n",
    "P(\\text{Medium box}) = P(\\text{Medium box} \\mid H_1)P(H_1) + P(\\text{Medium box} \\mid H_2)P(H_2) + P(\\text{Medium box} \\mid H_3)P(H_3)\n",
    "\\]\n",
    "\\[\n",
    "P(\\text{Medium box}) = (0.8 \\times 0.3) + (0.6 \\times 0.5) + (0.3 \\times 0.2) = 0.24 + 0.3 + 0.06 = 0.6\n",
    "\\]\n",
    "\n",
    "### Applying Bayes’ Theorem:\n",
    "Now, you can compute the **posterior probability** for each possible item using **Bayes’ Theorem**:\n",
    "\n",
    "1. **Posterior for a Book**:\n",
    "   \\[\n",
    "   P(H_1 \\mid \\text{Medium box}) = \\frac{P(\\text{Medium box} \\mid H_1) P(H_1)}{P(\\text{Medium box})} = \\frac{0.8 \\times 0.3}{0.6} = \\frac{0.24}{0.6} = 0.4\n",
    "   \\]\n",
    "\n",
    "2. **Posterior for Shoes**:\n",
    "   \\[\n",
    "   P(H_2 \\mid \\text{Medium box}) = \\frac{P(\\text{Medium box} \\mid H_2) P(H_2)}{P(\\text{Medium box})} = \\frac{0.6 \\times 0.5}{0.6} = \\frac{0.3}{0.6} = 0.5\n",
    "   \\]\n",
    "\n",
    "3. **Posterior for a Laptop**:\n",
    "   \\[\n",
    "   P(H_3 \\mid \\text{Medium box}) = \\frac{P(\\text{Medium box} \\mid H_3) P(H_3)}{P(\\text{Medium box})} = \\frac{0.3 \\times 0.2}{0.6} = \\frac{0.06}{0.6} = 0.1\n",
    "   \\]\n",
    "\n",
    "### Conclusion:\n",
    "Based on the size of the box and your priors, you now have updated probabilities for what might be inside the box:\n",
    "- \\( P(\\text{Book} \\mid \\text{Medium box}) = 0.4 \\),\n",
    "- \\( P(\\text{Shoes} \\mid \\text{Medium box}) = 0.5 \\),\n",
    "- \\( P(\\text{Laptop} \\mid \\text{Medium box}) = 0.1 \\).\n",
    "\n",
    "The most likely item is a **pair of shoes** (50% chance), followed by a **book** (40% chance). A **laptop** is the least likely (10% chance)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad140172",
   "metadata": {},
   "source": [
    "Аномалия в дашборде. Как выглядит процесс расследования причин?  \n",
    "Вначале нужно сформулировать возможные предположения: баг в недавнем релизе, не отработали ETL-скрипты, ... .\n",
    "С учетом прошлого опыта выбрать наиболее вероятное.  \n",
    "Проверить.  \n",
    "\n",
    "Можно записать рассуждения количественно.\n",
    "Интересует $P(изменения | аномалия)$.  \n",
    "Вначале выбирается список возможных причин и для каждой вычисляется $P(аномалия | изменения)$.  \n",
    "Прошлый опыт учитывает $P(изменения)$.  \n",
    "\n",
    "$$\n",
    "P(изменения | аномалия) \\approx P(аномалия | изменения) P(изменения)\n",
    "$$\n",
    "\n",
    "На этом примере видны компоненты байесовского моделирования. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50e1627c",
   "metadata": {},
   "source": [
    "* В мешке лежат черные и белые шары, всего 1000 штук. Для оценки количества черных шаров вынимают шар, записывают цвет, возвращают обратно. За 20 повторов вынули 5 черных шаров. Сколько может быть черных шаров в мешке и каковы вероятности этих значений?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8366fca7",
   "metadata": {},
   "source": [
    "1)\n",
    "\n",
    "При количестве черных шаров $N_B$ вероятность достать черный шар $p_B = N_B / N$.  \n",
    "Вероятность вынуть 5 черных шаров в 20 экспериментах задается биномиальным распределением.\n",
    "\n",
    "$$\n",
    "P(5, 20 | N_B) = Binom(5, 20) = C^5_{20} p_B^5 p_W^{15}\n",
    "$$\n",
    "\n",
    "Возможные значения $N_B$ от 1 (мог попадаться один и тот же черный шар) до 999 (есть как минимум 1 белый).\n",
    "\n",
    "Интересует\n",
    "\n",
    "$$\n",
    "P(N_B | 5, 20) = \\frac{ P(5,20 | N_B) P(N_B)}{P(5,20)} = \\frac{ P(5,20 | N_B) P(N_B)}{\\sum \\limits_{N_B=1}^{999} P(5,20 | N_B) P(N_B)}\n",
    "$$\n",
    "\n",
    "В знаменателе нормировочный коэффициент.\n",
    "\n",
    "Значения $P(N_B)$ равновероятны $P(N_B) = 1/999$.\n",
    "\n",
    "$$\n",
    "P(N_B | 5, 20) \n",
    "= \\frac{ P(5,20 | N_B)}{\\sum \\limits_{N_B=1}^{999} P(5,20 | N_B)} \n",
    "= \\frac{C^5_{20} p_B^5 p_W^{15}}{\\sum \\limits_{N_B=1}^{999} C^5_{20} p_B^5 p_W^{15}}\n",
    "= \\frac{C^5_{20} N_B^5 (N - N_B)^{15}}{\\sum \\limits_{N_B=1}^{999} C^5_{20} N_B^5 (N-N_B)^{15}}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7506514b",
   "metadata": {},
   "source": [
    "Лучше так:\n",
    "1000 шаров, достали-вернули 5, все 5 черные. Сколько всего черных?\n",
    "\n",
    "\n",
    "$$\n",
    "P(5 | N_B) = Binom(5, 5) = C^5_{5} p_B^5 p_W^{0} = p_B^5\n",
    "$$\n",
    "\n",
    "$$\n",
    "P(N_B | 5) = \\frac{ P(5 | N_B) P(N_B)}{\\sum \\limits_{N_B=1}^{1000} P(5 | N_B) P(N_B)}\n",
    "$$\n",
    "\n",
    "Значения $P(N_B)$ равновероятны $P(N_B) = 1/1000$.\n",
    "\n",
    "$$\n",
    "P(N_B | 5) \n",
    "= \\frac{ P(5 | N_B)}{\\sum \\limits_{N_B=1}^{1000} P(5 | N_B)} \n",
    "= \\frac{p_B^5}{\\sum \\limits_{N_B=1}^{1000} p_B^5}\n",
    "= \\frac{N_B^5}{\\sum \\limits_{N_B=1}^{1000} N_B^5}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c36bf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0b953d11",
   "metadata": {},
   "source": [
    "$$\n",
    "\\mbox{Beta}(1, 1) = \n",
    "\\mbox{Uniform}(p) = \n",
    "\\begin{cases}\n",
    "1, p \\in [0, 1]\n",
    "\\\\\n",
    "0, p \\not\\in [0, 1]\n",
    "\\end{cases}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35d03cd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c62d8b5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1261ab6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0c856063",
   "metadata": {},
   "source": [
    "По закону больших чисел [[LargeNums](https://en.wikipedia.org/wiki/Law_of_large_numbers#Borel's_law_of_large_numbers)] по мере набора данных выборка приближается к точному распределению."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45346a1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edc1d56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9743b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# размер выборки до достижения prob_stop\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Histogram(x=cmp['exp_samp_size'], histnorm='probability', name='Groups Sample Size', \n",
    "                           marker_color='black', nbinsx=100))\n",
    "fig.update_layout(title='Размер выборки',\n",
    "                  xaxis_title='Точек в группе',\n",
    "                  yaxis_title='Доля экспериментов',\n",
    "                  hovermode=\"x\",\n",
    "                  height=500)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7e18ff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b2d52eae",
   "metadata": {},
   "source": [
    "# Кликабельность\n",
    "\n",
    "Кликабельность - отношение кликов к показам.\n",
    "Используется для баннеров.\n",
    "\n",
    "Таблица вида id-показы-клики\n",
    "\n",
    "\n",
    "|id| показы | клики\n",
    "|- | ------ | -\n",
    "|a | 10     | 2\n",
    "|b | 5      | 0\n",
    "|...|...|...\n",
    "\n",
    "\n",
    "Показы на пользователя распределены по степенному закону (Ципфа, дискретизация Парето).  \n",
    "Маржинальное распределение кликов близко экспоненциальному.  \n",
    "Для каждого количества показов $N$ распределение кликов $P(c|N)$ близко экспоненциальному.  \n",
    "\n",
    "\n",
    "Для моделирования удобнее произведение мультиномиальных распределений.\n",
    "\n",
    "$$\n",
    "P(c, N | p_{N,c}) = Mult(N | p_1, \\dots, p_{maxN}) Mult(c | p_{1,N}, \\dots, p_{maxC,N})\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8740313",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import stats\n",
    "\n",
    "pa = 7.1\n",
    "sa = 0.1\n",
    "print(pa, '±', 2*sa)\n",
    "pb = 7.4\n",
    "sb = 0.15\n",
    "print(pb, '±', 2*sb)\n",
    "\n",
    "prel = (pb - pa) / pa\n",
    "srel = prel * np.sqrt((sa/pa)**2 + (sb/pb)**2)\n",
    "\n",
    "prel, srel, 2 * srel\n",
    "print(f'{prel*100:.1f} ± {2*srel*100:.1f}')\n",
    "\n",
    "pd = pb - pa\n",
    "sd = np.sqrt(sa**2 + sb**2)\n",
    "print(f'{pd:.2f} ± {2*sd:.2f}')\n",
    "stats.norm(loc=pd, scale=sd).cdf(0), 1 - stats.norm(loc=pd, scale=sd).cdf(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "local-venv-kernel",
   "language": "python",
   "name": "local-venv-kernel"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
